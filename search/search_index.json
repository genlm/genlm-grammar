{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GenLM Grammar Documentation","text":"<p>This is a Python library for working with weighted context-free grammars (WCFGs) and finite state machines (FSAs). It provides implementations of various parsing algorithms and language model capabilities.</p>"},{"location":"#core-components","title":"Core Components","text":""},{"location":"#grammar-types","title":"Grammar Types","text":"<ul> <li>CFG: Context-free grammar implementation with support for:<ul> <li>Grammar normalization and transformation</li> <li>Conversion to a character-level grammar</li> </ul> </li> </ul>"},{"location":"#language-models","title":"Language Models","text":"<ul> <li>LM: Base language model class</li> <li>BoolCFGLM: Boolean-weighted CFG language model using Earley or CKY parsing</li> <li>CKYLM: CKY-based parsing for weighted CFGs</li> <li>EarleyLM: Earley-based parsing implementation for weighted CFGs</li> </ul>"},{"location":"#parsing-algorithms","title":"Parsing Algorithms","text":"<ul> <li>Earley Parser: Earley parsing algorithm with rescaling for numerical stability</li> <li>IncrementalCKY: Incremental version of CKY with chart caching</li> </ul>"},{"location":"#finite-state-machines","title":"Finite State Machines","text":"<ul> <li>FST: Weighted finite-state transducer implementation</li> <li>WFSA: Weighted finite-state automaton base class</li> </ul>"},{"location":"#mathematical-components","title":"Mathematical Components","text":"<ul> <li>Semiring: Abstract semiring implementations including:<ul> <li>Boolean</li> <li>Float</li> <li>Log</li> <li>Expectation</li> </ul> </li> <li>Chart: Weighted chart data structure with semiring operations</li> <li>WeightedGraph: Graph implementation for solving algebraic path problems</li> </ul>"},{"location":"#utilities","title":"Utilities","text":"<ul> <li>LarkStuff: Interface for converting Lark grammars to genlm-cfg format</li> <li>format_table: Utility functions for formatting and displaying tables</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Support for various weighted grammar formalisms</li> <li>Multiple parsing algorithm implementations</li> <li>Efficient chart caching and incremental parsing</li> <li>Composition operations between FSTs and CFGs</li> <li>Semiring abstractions for different weight types</li> <li>Visualization capabilities for debugging and analysis</li> </ul>"},{"location":"#common-operations","title":"Common Operations","text":""},{"location":"#creating-a-grammar","title":"Creating a Grammar","text":"<pre><code>from genlm.grammar.cfg import CFG\nfrom genlm.grammar.semiring import Float\n\n# Create from string representation\ncfg = CFG.from_string(grammar_string, semiring=Float)\n</code></pre>"},{"location":"#using-a-language-model","title":"Using a Language Model","text":"<pre><code>from genlm.grammar.cfglm import BoolCFGLM\n\n# Create language model from genlm.grammar\nlm = BoolCFGLM(cfg, alg='earley')  # or alg='cky'\n\n# Get next token weights\nprobs = lm.p_next(context)\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>genlm<ul> <li>grammar<ul> <li>cfg</li> <li>cfglm</li> <li>chart</li> <li>fst</li> <li>lark_interface</li> <li>linear</li> <li>lm</li> <li>parse<ul> <li>cky</li> <li>earley</li> <li>earley_rescaled</li> </ul> </li> <li>semiring</li> <li>util</li> <li>wfsa<ul> <li>base</li> <li>field_wfsa</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/genlm/grammar/__init__/","title":"grammar","text":""},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.BoolCFGLM","title":"<code>BoolCFGLM</code>","text":"<p>               Bases: <code>LM</code></p> <p>Language model interface for Boolean-weighted CFGs.</p> <p>Uses Earley's algorithm or CKY for inference. The grammar is converted to use Boolean weights if needed, where positive weights become True and zero/negative weights become False.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use</p> required <code>alg</code> <code>str</code> <p>Parsing algorithm to use - either 'earley' or 'cky'</p> <code>'earley'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alg is not 'earley' or 'cky'</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>class BoolCFGLM(LM):\n    \"\"\"Language model interface for Boolean-weighted CFGs.\n\n    Uses Earley's algorithm or CKY for inference. The grammar is converted to use\n    Boolean weights if needed, where positive weights become True and zero/negative\n    weights become False.\n\n    Args:\n        cfg (CFG): The context-free grammar to use\n        alg (str): Parsing algorithm to use - either 'earley' or 'cky'\n\n    Raises:\n        ValueError: If alg is not 'earley' or 'cky'\n    \"\"\"\n\n    def __init__(self, cfg, alg=\"earley\"):\n        \"\"\"Initialize a BoolCFGLM.\n\n        Args:\n            cfg (CFG): The context-free grammar to use as the language model\n            alg (str): Parsing algorithm to use - either 'earley' or 'cky'\n\n        Raises:\n            ValueError: If alg is not 'earley' or 'cky'\n        \"\"\"\n        if EOS not in cfg.V:\n            cfg = add_EOS(cfg, eos=EOS)\n        if cfg.R != Boolean:\n            cfg = cfg.map_values(lambda x: Boolean(x &gt; 0), Boolean)\n        if alg == \"earley\":\n            from genlm.grammar.parse.earley import Earley\n\n            self.model = Earley(cfg.prefix_grammar)\n        elif alg == \"cky\":\n            from genlm.grammar.parse.cky import CKYLM\n\n            self.model = CKYLM(cfg)\n        else:\n            raise ValueError(f\"unrecognized option {alg}\")\n        super().__init__(eos=EOS, V=cfg.V)\n\n    def p_next(self, context):\n        \"\"\"Compute next token probabilities given a context.\n\n        Args:\n            context (sequence): The conditioning context\n\n        Returns:\n            (Float.chart): The next token weights\n\n        Raises:\n            AssertionError: If context contains out-of-vocabulary tokens\n        \"\"\"\n        assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n        p = self.model.next_token_weights(self.model.chart(context)).trim()\n        return Float.chart({w: 1 for w in p})\n\n    def __call__(self, context):\n        \"\"\"Check if a context is possible under this grammar.\n\n        Args:\n            context (sequence): The context to check\n\n        Returns:\n            (bool): True if the context has non-zero weight\n        \"\"\"\n        return float(super().__call__(context) &gt; 0)\n\n    def clear_cache(self):\n        \"\"\"Clear any cached computations.\"\"\"\n        self.model.clear_cache()\n\n    @classmethod\n    def from_string(cls, x, semiring=Boolean, **kwargs):\n        \"\"\"Create a BoolCFGLM from a string representation of a grammar.\n\n        Args:\n            x (str): The grammar string\n            semiring: The semiring for weights (default: Boolean)\n            **kwargs: Additional arguments passed to __init__\n\n        Returns:\n            (BoolCFGLM): A new language model\n        \"\"\"\n        return cls(CFG.from_string(x, semiring), **kwargs)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.BoolCFGLM.__call__","title":"<code>__call__(context)</code>","text":"<p>Check if a context is possible under this grammar.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>sequence</code> <p>The context to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the context has non-zero weight</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def __call__(self, context):\n    \"\"\"Check if a context is possible under this grammar.\n\n    Args:\n        context (sequence): The context to check\n\n    Returns:\n        (bool): True if the context has non-zero weight\n    \"\"\"\n    return float(super().__call__(context) &gt; 0)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.BoolCFGLM.__init__","title":"<code>__init__(cfg, alg='earley')</code>","text":"<p>Initialize a BoolCFGLM.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use as the language model</p> required <code>alg</code> <code>str</code> <p>Parsing algorithm to use - either 'earley' or 'cky'</p> <code>'earley'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alg is not 'earley' or 'cky'</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def __init__(self, cfg, alg=\"earley\"):\n    \"\"\"Initialize a BoolCFGLM.\n\n    Args:\n        cfg (CFG): The context-free grammar to use as the language model\n        alg (str): Parsing algorithm to use - either 'earley' or 'cky'\n\n    Raises:\n        ValueError: If alg is not 'earley' or 'cky'\n    \"\"\"\n    if EOS not in cfg.V:\n        cfg = add_EOS(cfg, eos=EOS)\n    if cfg.R != Boolean:\n        cfg = cfg.map_values(lambda x: Boolean(x &gt; 0), Boolean)\n    if alg == \"earley\":\n        from genlm.grammar.parse.earley import Earley\n\n        self.model = Earley(cfg.prefix_grammar)\n    elif alg == \"cky\":\n        from genlm.grammar.parse.cky import CKYLM\n\n        self.model = CKYLM(cfg)\n    else:\n        raise ValueError(f\"unrecognized option {alg}\")\n    super().__init__(eos=EOS, V=cfg.V)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.BoolCFGLM.clear_cache","title":"<code>clear_cache()</code>","text":"<p>Clear any cached computations.</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def clear_cache(self):\n    \"\"\"Clear any cached computations.\"\"\"\n    self.model.clear_cache()\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.BoolCFGLM.from_string","title":"<code>from_string(x, semiring=Boolean, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a BoolCFGLM from a string representation of a grammar.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The grammar string</p> required <code>semiring</code> <p>The semiring for weights (default: Boolean)</p> <code>Boolean</code> <code>**kwargs</code> <p>Additional arguments passed to init</p> <code>{}</code> <p>Returns:</p> Type Description <code>BoolCFGLM</code> <p>A new language model</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>@classmethod\ndef from_string(cls, x, semiring=Boolean, **kwargs):\n    \"\"\"Create a BoolCFGLM from a string representation of a grammar.\n\n    Args:\n        x (str): The grammar string\n        semiring: The semiring for weights (default: Boolean)\n        **kwargs: Additional arguments passed to __init__\n\n    Returns:\n        (BoolCFGLM): A new language model\n    \"\"\"\n    return cls(CFG.from_string(x, semiring), **kwargs)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.BoolCFGLM.p_next","title":"<code>p_next(context)</code>","text":"<p>Compute next token probabilities given a context.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>sequence</code> <p>The conditioning context</p> required <p>Returns:</p> Type Description <code>chart</code> <p>The next token weights</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If context contains out-of-vocabulary tokens</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def p_next(self, context):\n    \"\"\"Compute next token probabilities given a context.\n\n    Args:\n        context (sequence): The conditioning context\n\n    Returns:\n        (Float.chart): The next token weights\n\n    Raises:\n        AssertionError: If context contains out-of-vocabulary tokens\n    \"\"\"\n    assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n    p = self.model.next_token_weights(self.model.chart(context)).trim()\n    return Float.chart({w: 1 for w in p})\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG","title":"<code>CFG</code>","text":"<p>Weighted Context-free Grammar</p> <p>A weighted context-free grammar consists of:</p> <ul> <li> <p><code>R</code>: A semiring that defines the weights</p> </li> <li> <p><code>S</code>: A start symbol (nonterminal)</p> </li> <li> <p><code>V</code>: A set of terminal symbols (vocabulary)</p> </li> <li> <p><code>N</code>: A set of nonterminal symbols</p> </li> <li> <p><code>rules</code>: A list of weighted production rules</p> </li> </ul> <p>Each rule has the form: w: X -&gt; Y1 Y2 ... Yn where:</p> <ul> <li> <p>w is a weight from the semiring R</p> </li> <li> <p>X is a nonterminal symbol</p> </li> <li> <p>Y1...Yn are terminal or nonterminal symbols</p> </li> </ul> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>class CFG:\n    \"\"\"\n    Weighted Context-free Grammar\n\n    A weighted context-free grammar consists of:\\n\n    - `R`: A semiring that defines the weights\\n\n    - `S`: A start symbol (nonterminal)\\n\n    - `V`: A set of terminal symbols (vocabulary)\\n\n    - `N`: A set of nonterminal symbols\\n\n    - `rules`: A list of weighted production rules\\n\n\n    Each rule has the form: w: X -&gt; Y1 Y2 ... Yn where:\\n\n    - w is a weight from the semiring R\\n\n    - X is a nonterminal symbol\\n\n    - Y1...Yn are terminal or nonterminal symbols\\n\n    \"\"\"\n\n    def __init__(self, R, S, V):\n        \"\"\"\n        Initialize a weighted CFG.\n\n        Args:\n            R: The semiring for rule weights\n            S: The start symbol (nonterminal)\n            V: The set of terminal symbols (vocabulary)\n        \"\"\"\n        self.R = R  # semiring\n        self.V = V  # alphabet\n        self.N = {S}  # nonterminals\n        self.S = S  # unique start symbol\n        self.rules = []  # rules\n        self._trim_cache = [None, None]\n\n    def __repr__(self):\n        \"\"\"Return string representation of the grammar.\"\"\"\n        return \"Grammar {\\n%s\\n}\" % \"\\n\".join(f\"  {r}\" for r in self)\n\n    def _repr_html_(self):\n        \"\"\"Return HTML representation of the grammar for Jupyter notebooks.\"\"\"\n        return f'&lt;pre style=\"width: fit-content; text-align: left; border: thin solid black; padding: 0.5em;\"&gt;{self}&lt;/pre&gt;'\n\n    @classmethod\n    def from_string(\n        cls,\n        string,\n        semiring,\n        comment=\"#\",\n        start=\"S\",\n        is_terminal=lambda x: not x[0].isupper(),\n    ):\n        \"\"\"\n        Create a CFG from a string representation.\n\n        Args:\n            string: The grammar rules as a string\n            semiring: The semiring for rule weights\n            comment: Comment character to ignore lines (default: '#')\n            start: Start symbol (default: 'S')\n            is_terminal: Function to identify terminal symbols (default: lowercase first letter)\n\n        Returns:\n            A new CFG instance\n        \"\"\"\n        V = set()\n        cfg = cls(R=semiring, S=start, V=V)\n        string = string.replace(\"-&gt;\", \"\u2192\")  # synonym for the arrow\n        for line in string.split(\"\\n\"):\n            line = line.strip()\n            if not line or line.startswith(comment):\n                continue\n            try:\n                [(w, lhs, rhs)] = re.findall(r\"(.*):\\s*(\\S+)\\s*\u2192\\s*(.*)$\", line)\n                lhs = lhs.strip()\n                rhs = rhs.strip().split()\n                for x in rhs:\n                    if is_terminal(x):\n                        V.add(x)\n                cfg.add(semiring.from_string(w), lhs, *rhs)\n            except ValueError:\n                raise ValueError(f\"bad input line:\\n{line}\")  # pylint: disable=W0707\n        return cfg\n\n    def __getitem__(self, root):\n        \"\"\"\n        Return a grammar that denotes the sublanguage of the nonterminal `root`.\n\n        Args:\n            root: The nonterminal to use as the new start symbol\n\n        Returns:\n            A new CFG with root as the start symbol\n        \"\"\"\n        new = self.spawn(S=root)\n        for r in self:\n            new.add(r.w, r.head, *r.body)\n        return new\n\n    def __len__(self):\n        \"\"\"Return number of rules in the grammar.\"\"\"\n        return len(self.rules)\n\n    def __call__(self, xs):\n        \"\"\"\n        Compute the total weight of the sequence xs.\n\n        Args:\n            xs: A sequence of terminal symbols\n\n        Returns:\n            The total weight of all derivations of xs\n        \"\"\"\n        self = self.cnf  # need to do this here because the start symbol might change\n        return self._parse_chart(xs)[0, self.S, len(xs)]\n\n    def _parse_chart(self, xs):\n        \"\"\"\n        Implements CKY algorithm for evaluating the total weight of the xs sequence.\n\n        Args:\n            xs: A sequence of terminal symbols\n\n        Returns:\n            A chart containing the weights of all subderivations\n        \"\"\"\n        (nullary, terminal, binary) = self._cnf  # will convert to CNF\n        N = len(xs)\n        # nullary rule\n        c = self.R.chart()\n        for i in range(N + 1):\n            c[i, self.S, i] += nullary\n        # preterminal rules\n        for i in range(N):\n            for r in terminal[xs[i]]:\n                c[i, r.head, i + 1] += r.w\n        # binary rules\n        for span in range(2, N + 1):\n            for i in range(N - span + 1):\n                k = i + span\n                for j in range(i + 1, k):\n                    for r in binary:\n                        X, [Y, Z] = r.head, r.body\n                        c[i, X, k] += r.w * c[i, Y, j] * c[j, Z, k]\n        return c\n\n    def language(self, depth):\n        \"\"\"\n        Enumerate strings generated by this cfg by derivations up to the given depth.\n\n        Args:\n            depth: Maximum derivation depth to consider\n\n        Returns:\n            A chart containing the weighted language up to the given depth\n        \"\"\"\n        lang = self.R.chart()\n        for d in self.derivations(self.S, depth):\n            lang[d.Yield()] += d.weight()\n        return lang\n\n    @cached_property\n    def rhs(self):\n        \"\"\"\n        Map from each nonterminal to the list of rules with it as their left-hand side.\n\n        Returns:\n            A dict mapping nonterminals to lists of rules\n        \"\"\"\n        rhs = defaultdict(list)\n        for r in self:\n            rhs[r.head].append(r)\n        return rhs\n\n    def is_terminal(self, x):\n        \"\"\"Return True if x is a terminal symbol.\"\"\"\n        return x in self.V\n\n    def is_nonterminal(self, X):\n        \"\"\"Return True if X is a nonterminal symbol.\"\"\"\n        return not self.is_terminal(X)\n\n    def __iter__(self):\n        \"\"\"Iterate over the rules in the grammar.\"\"\"\n        return iter(self.rules)\n\n    @property\n    def size(self):\n        \"\"\"Return total size of the grammar (sum of rule lengths).\"\"\"\n        return sum(1 + len(r.body) for r in self)\n\n    @property\n    def num_rules(self):\n        \"\"\"Return number of rules in the grammar.\"\"\"\n        return len(self.rules)\n\n    @property\n    def expected_length(self):\n        \"\"\"\n        Compute the expected length of a string using the Expectation semiring.\n\n        Returns:\n            The expected length of strings generated by this grammar\n\n        Raises:\n            AssertionError: If grammar is not over the Float semiring\n        \"\"\"\n        assert self.R == Float, (\n            \"This method only supports grammars over the Float semiring\"\n        )\n        new_cfg = self.__class__(R=Expectation, S=self.S, V=self.V)\n        for r in self:\n            new_cfg.add(\n                Expectation(r.w, r.w * sum(self.is_terminal(y) for y in r.body)),\n                r.head,\n                *r.body,\n            )\n        return new_cfg.treesum().score[1]\n\n    def spawn(self, *, R=None, S=None, V=None):\n        \"\"\"\n        Create an empty grammar with the same R, S, and V.\n\n        Args:\n            R: Optional new semiring\n            S: Optional new start symbol\n            V: Optional new vocabulary\n\n        Returns:\n            A new empty CFG with specified parameters\n        \"\"\"\n        return self.__class__(\n            R=self.R if R is None else R,\n            S=self.S if S is None else S,\n            V=set(self.V) if V is None else V,\n        )\n\n    def add(self, w, head, *body):\n        \"\"\"\n        Add a rule of the form w: head -&gt; body1, body2, ... body_k.\n\n        Args:\n            w: The rule weight\n            head: The left-hand side nonterminal\n            *body: The right-hand side symbols\n\n        Returns:\n            The added rule, or None if weight is zero\n        \"\"\"\n        if w == self.R.zero:\n            return  # skip rules with weight zero\n        self.N.add(head)\n        r = Rule(w, head, body)\n        self.rules.append(r)\n        return r\n\n    def renumber(self):\n        \"\"\"\n        Rename nonterminals to integers.\n\n        Returns:\n            A new CFG with integer nonterminals\n        \"\"\"\n        i = Integerizer()\n        max_v = max((x for x in self.V if isinstance(x, int)), default=0)\n        return self.rename(lambda x: i(x) + max_v + 1)\n\n    def rename(self, f):\n        \"\"\"\n        Return a new grammar that is the result of applying f to each nonterminal.\n\n        Args:\n            f: Function to rename nonterminals\n\n        Returns:\n            A new CFG with renamed nonterminals\n        \"\"\"\n        new = self.spawn(S=f(self.S))\n        for r in self:\n            new.add(\n                r.w, f(r.head), *((y if self.is_terminal(y) else f(y) for y in r.body))\n            )\n        return new\n\n    def map_values(self, f, R):\n        \"\"\"\n        Return a new grammar that is the result of applying f: self.R -&gt; R to each rule's weight.\n\n        Args:\n            f: Function to map weights\n            R: New semiring for weights\n\n        Returns:\n            A new CFG with mapped weights\n        \"\"\"\n        new = self.spawn(R=R)\n        for r in self:\n            new.add(f(r.w), r.head, *r.body)\n        return new\n\n    def assert_equal(self, other, verbose=False, throw=True):\n        \"\"\"\n        Assertion for the equality of self and other modulo rule reordering.\n\n        Args:\n            other: The grammar to compare against\n            verbose: If True, print differences\n            throw: If True, raise AssertionError on inequality\n\n        Raises:\n            AssertionError: If grammars are not equal and throw=True\n        \"\"\"\n        assert verbose or throw\n        if isinstance(other, str):\n            other = self.__class__.from_string(other, self.R)\n        if verbose:\n            # TODO: need to check the weights in the print out; we do it in the assertion\n            S = set(self.rules)\n            G = set(other.rules)\n            for r in sorted(S | G, key=str):\n                if r in S and r in G:\n                    continue\n                # if r in S and r not in G: continue\n                # if r not in S and r in G: continue\n                print(\n                    colors.mark(r in S),\n                    # colors.mark(r in S and r in G),\n                    colors.mark(r in G),\n                    r,\n                )\n        assert not throw or Counter(self.rules) == Counter(other.rules), (\n            f\"\\n\\nhave=\\n{str(self)}\\nwant=\\n{str(other)}\"\n        )\n\n    def treesum(self, **kwargs):\n        \"\"\"\n        Total weight of the start symbol.\n\n        Returns:\n            The total weight of all derivations from the start symbol\n        \"\"\"\n        return self.agenda(**kwargs)[self.S]\n\n    def trim(self, bottomup_only=False):\n        \"\"\"\n        Return an equivalent grammar with no dead or useless nonterminals or rules.\n\n        Args:\n            bottomup_only: If True, only remove non-generating nonterminals\n\n        Returns:\n            A new trimmed CFG\n        \"\"\"\n        if self._trim_cache[bottomup_only] is not None:\n            return self._trim_cache[bottomup_only]\n\n        C = set(self.V)\n        C.update(e.head for e in self.rules if len(e.body) == 0)\n\n        incoming = defaultdict(list)\n        outgoing = defaultdict(list)\n        for e in self:\n            incoming[e.head].append(e)\n            for b in e.body:\n                outgoing[b].append(e)\n\n        agenda = set(C)\n        while agenda:\n            x = agenda.pop()\n            for e in outgoing[x]:\n                if all((b in C) for b in e.body):\n                    if e.head not in C:\n                        C.add(e.head)\n                        agenda.add(e.head)\n\n        if bottomup_only:\n            val = self._trim(C)\n            self._trim_cache[bottomup_only] = val\n            val._trim_cache[bottomup_only] = val\n            return val\n\n        T = {self.S}\n        agenda.update(T)\n        while agenda:\n            x = agenda.pop()\n            for e in incoming[x]:\n                # assert e.head in T\n                for b in e.body:\n                    if b not in T and b in C:\n                        T.add(b)\n                        agenda.add(b)\n\n        val = self._trim(T)\n        self._trim_cache[bottomup_only] = val\n        val._trim_cache[bottomup_only] = val\n        return val\n\n    def cotrim(self):\n        \"\"\"\n        Trim the grammar so that all nonterminals are generating.\n\n        Returns:\n            A new CFG with only generating nonterminals\n        \"\"\"\n        return self.trim(bottomup_only=True)\n\n    def _trim(self, symbols):\n        \"\"\"\n        Helper method for trim() - creates new grammar with only given symbols.\n\n        Args:\n            symbols: Set of symbols to keep\n\n        Returns:\n            A new CFG with only rules using the given symbols\n        \"\"\"\n        new = self.spawn()\n        for p in self:\n            if p.head in symbols and p.w != self.R.zero and set(p.body) &lt;= symbols:\n                new.add(p.w, p.head, *p.body)\n        return new\n\n    # ___________________________________________________________________________\n    # Derivation enumeration\n\n    def derivations(self, X, H):\n        \"\"\"\n        Enumerate derivations of symbol X with height &lt;= H.\n\n        Args:\n            X: The symbol to derive from (default: start symbol)\n            H: Maximum derivation height\n\n        Yields:\n            Derivation objects representing derivation trees\n        \"\"\"\n        if X is None:\n            X = self.S\n        if self.is_terminal(X):\n            yield X\n        elif H &lt;= 0:\n            return\n        else:\n            for r in self.rhs[X]:\n                for ys in self._derivations_list(r.body, H - 1):\n                    yield Derivation(r, X, *ys)\n\n    def _derivations_list(self, Xs, H):\n        \"\"\"\n        Helper method for derivations; expands any list of symbols X up to depth H.\n\n        Args:\n            Xs: List of symbols to derive\n            H: Maximum derivation height\n\n        Yields:\n            Tuples of derivations\n        \"\"\"\n        if len(Xs) == 0:\n            yield ()\n        else:\n            for x in self.derivations(Xs[0], H):\n                for xs in self._derivations_list(Xs[1:], H):\n                    yield (x, *xs)\n\n    # ___________________________________________________________________________\n    # Transformations\n\n    def _unary_graph(self):\n        \"\"\"\n        Compute the matrix closure of unary rules.\n\n        Returns:\n            A WeightedGraph representing unary rule closure\n        \"\"\"\n        A = WeightedGraph(self.R)\n        for r in self:\n            if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n                A[r.head, r.body[0]] += r.w\n        A.N |= self.N\n        return A\n\n    def _unary_graph_transpose(self):\n        \"\"\"\n        Compute the matrix closure of unary rules (transposed).\n\n        Returns:\n            A WeightedGraph representing transposed unary rule closure\n        \"\"\"\n        A = WeightedGraph(self.R)\n        for r in self:\n            if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n                A[r.body[0], r.head] += r.w\n        A.N |= self.N\n        return A\n\n    def unaryremove(self):\n        \"\"\"\n        Return an equivalent grammar with no unary rules.\n\n        Returns:\n            A new CFG without unary rules\n        \"\"\"\n        W = self._unary_graph().closure_scc_based()\n        # W = self._unary_graph().closure_reference()\n\n        new = self.spawn()\n        for r in self:\n            if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n                continue\n            for Y in self.N:\n                new.add(W[Y, r.head] * r.w, Y, *r.body)\n\n        return new\n\n    def has_unary_cycle(self):\n        \"\"\"\n        Check if the grammar has unary cycles.\n\n        Returns:\n            True if the grammar contains unary cycles\n        \"\"\"\n        f = self._unary_graph().buckets\n        return any(\n            True for r in self if len(r.body) == 1 and f.get(r.head) == f.get(r.body[0])\n        )\n\n    def unarycycleremove(self, trim=True):\n        \"\"\"\n        Return an equivalent grammar with no unary cycles.\n\n        Args:\n            trim: If True, trim the resulting grammar\n\n        Returns:\n            A new CFG without unary cycles\n        \"\"\"\n\n        def bot(x):\n            return x if x in acyclic else (x, \"bot\")\n\n        G = self._unary_graph()\n\n        new = self.spawn(S=self.S)\n\n        bucket = G.buckets\n\n        acyclic = set()\n        for nodes, _ in G.Blocks:\n            if len(nodes) == 1:\n                [X] = nodes\n                if G[X, X] == self.R.zero:\n                    acyclic.add(X)\n\n        # run Lehmann's on each cylical SCC\n        for nodes, W in G.Blocks:\n            if len(nodes) == 1:\n                [X] = nodes\n                if X in acyclic:\n                    continue\n\n            for X1, X2 in W:\n                new.add(W[X1, X2], X1, bot(X2))\n\n        for r in self:\n            if len(r.body) == 1 and bucket.get(r.body[0]) == bucket[r.head]:\n                continue\n            new.add(r.w, bot(r.head), *r.body)\n\n        # TODO: figure out how to ensure that the new grammar is trimmed by\n        # construction (assuming the input grammar was trim).\n        if trim:\n            new = new.trim()\n\n        return new\n\n    def nullaryremove(self, binarize=True, trim=True, **kwargs):\n        \"\"\"\n        Return an equivalent grammar with no nullary rules except for one at the start symbol.\n\n        Args:\n            binarize: If True, binarize the grammar first\n            trim: If True, trim the resulting grammar\n            **kwargs: Additional arguments passed to _push_null_weights\n\n        Returns:\n            A new CFG without nullary rules (except at start)\n        \"\"\"\n        # A really wide rule can take a very long time because of the power set\n        # in this rule so it is really important to binarize.\n        if binarize:\n            self = self.binarize()  # pragma: no cover\n        self = self.separate_start()\n        tmp = self._push_null_weights(self.null_weight(), **kwargs)\n        return tmp.trim() if trim else tmp\n\n    def null_weight(self):\n        \"\"\"\n        Compute the map from nonterminal to total weight of generating the empty string.\n\n        Returns:\n            A dict mapping nonterminals to their null weights\n        \"\"\"\n        ecfg = self.spawn(V=set())\n        for p in self:\n            if not any(self.is_terminal(y) for y in p.body):\n                ecfg.add(p.w, p.head, *p.body)\n        return ecfg.agenda()\n\n    def null_weight_start(self):\n        \"\"\"\n        Compute the null weight of the start symbol.\n\n        Returns:\n            The total weight of generating the empty string from the start symbol\n        \"\"\"\n        return self.null_weight()[self.S]\n\n    def _push_null_weights(self, null_weight, rename=NotNull):\n        \"\"\"\n        Returns a grammar that generates the same weighted language but is nullary-free\n        at all nonterminals except its start symbol.\n\n        Args:\n            null_weight: Dict mapping nonterminals to their null weights\n            rename: Function to rename nonterminals (default: NotNull)\n\n        Returns:\n            A new CFG without nullary rules (except at start)\n        \"\"\"\n        # Warning: this method might have issues when `separate_start` hasn't\n        # been run before.  So we run it rather than leaving it up to chance.\n        assert self.S not in {y for r in self for y in r.body}\n\n        def f(x):\n            \"Rename nonterminal if necessary\"\n            if (\n                null_weight[x] == self.R.zero or x == self.S\n            ):  # not necessary; keep old name\n                return x\n            else:\n                return rename(x)\n\n        rcfg = self.spawn()\n        rcfg.add(null_weight[self.S], self.S)\n\n        for r in self:\n            if len(r.body) == 0:\n                continue  # drop nullary rule\n\n            for B in product([0, 1], repeat=len(r.body)):\n                v, new_body = r.w, []\n\n                for i, b in enumerate(B):\n                    if b:\n                        v *= null_weight[r.body[i]]\n                    else:\n                        new_body.append(f(r.body[i]))\n\n                # exclude the cases that would be new nullary rules!\n                if len(new_body) &gt; 0:\n                    rcfg.add(v, f(r.head), *new_body)\n\n        return rcfg\n\n    def separate_start(self):\n        \"\"\"\n        Ensure that the start symbol does not appear on the RHS of any rule.\n\n        Returns:\n            A new CFG with start symbol only on LHS\n        \"\"\"\n        # create a new start symbol if the current one appears on the rhs of any existing rule\n        if self.S in {y for r in self for y in r.body}:\n            S = _gen_nt(self.S)\n            new = self.spawn(S=S)\n            # preterminal rules\n            new.add(self.R.one, S, self.S)\n            for r in self:\n                new.add(r.w, r.head, *r.body)\n            return new\n        else:\n            return self\n\n    def separate_terminals(self):\n        \"\"\"\n        Ensure that each terminal is produced by a preterminal rule.\n\n        Returns:\n            A new CFG with terminals only in preterminal rules\n        \"\"\"\n        one = self.R.one\n        new = self.spawn()\n\n        _preterminal = {}\n\n        def preterminal(x):\n            y = _preterminal.get(x)\n            if y is None:\n                y = new.add(one, _gen_nt(), x)\n                _preterminal[x] = y\n            return y\n\n        for r in self:\n            if len(r.body) == 1 and self.is_terminal(r.body[0]):\n                new.add(r.w, r.head, *r.body)\n            else:\n                new.add(\n                    r.w,\n                    r.head,\n                    *(\n                        (preterminal(y).head if self.is_terminal(y) else y)\n                        for y in r.body\n                    ),\n                )\n\n        return new\n\n    def binarize(self):\n        \"\"\"\n        Return an equivalent grammar with arity \u2264 2.\n\n        Returns:\n            A new CFG with binary rules\n        \"\"\"\n        new = self.spawn()\n\n        stack = list(self)\n        while stack:\n            p = stack.pop()\n            if len(p.body) &lt;= 2:\n                new.add(p.w, p.head, *p.body)\n            else:\n                stack.extend(self._fold(p, [(0, 1)]))\n\n        return new\n\n    def _fold(self, p, I):\n        \"\"\"\n        Helper method for binarization - folds a rule into binary rules.\n\n        Args:\n            p: The rule to fold\n            I: List of (start,end) indices for folding\n\n        Returns:\n            List of new binary rules\n        \"\"\"\n        # new productions\n        P, heads = [], []\n        for i, j in I:\n            head = _gen_nt()\n            heads.append(head)\n            body = p.body[i : j + 1]\n            P.append(Rule(self.R.one, head, body))\n\n        # new \"head\" production\n        body = tuple()\n        start = 0\n        for (end, n), head in zip(I, heads):\n            body += p.body[start:end] + (head,)\n            start = n + 1\n        body += p.body[start:]\n        P.append(Rule(p.w, p.head, body))\n\n        return P\n\n    @cached_property\n    def cnf(self):\n        \"\"\"\n        Transform this grammar into Chomsky Normal Form (CNF).\n\n        Returns:\n            A new CFG in CNF\n        \"\"\"\n        new = (\n            self.separate_terminals()\n            .nullaryremove(binarize=True)\n            .trim()\n            .unaryremove()\n            .trim()\n        )\n        assert new.in_cnf(), \"\\n\".join(\n            str(r) for r in new._find_invalid_cnf_rule()\n        )  # pragma: no cover\n        return new\n\n    # TODO: make CNF grammars a speciazed subclass of CFG.\n    @cached_property\n    def _cnf(self):\n        \"\"\"\n        Note: Throws an exception if the grammar is not in CNF.\n\n        Returns:\n            Tuple of (nullary weight, terminal rules dict, binary rules list)\n        \"\"\"\n        nullary = self.R.zero\n        terminal = defaultdict(list)\n        binary = []\n        for r in self:\n            if len(r.body) == 0:\n                nullary += r.w\n                assert r.head == self.S, [self.S, r]\n            elif len(r.body) == 1:\n                terminal[r.body[0]].append(r)\n                assert self.is_terminal(r.body[0])\n            else:\n                assert len(r.body) == 2\n                binary.append(r)\n                assert self.is_nonterminal(r.body[0])\n                assert self.is_nonterminal(r.body[1])\n        return (nullary, terminal, binary)\n\n    def in_cnf(self):\n        \"\"\"\n        Return true if the grammar is in CNF.\n\n        Returns:\n            True if grammar is in Chomsky Normal Form\n        \"\"\"\n        return len(list(self._find_invalid_cnf_rule())) == 0\n\n    def _find_invalid_cnf_rule(self):\n        \"\"\"\n        Return true if the grammar is in CNF.\n\n        Yields:\n            Rules that violate CNF\n        \"\"\"\n        for r in self:\n            assert r.head in self.N\n            if len(r.body) == 0 and r.head == self.S:\n                continue\n            elif len(r.body) == 1 and self.is_terminal(r.body[0]):\n                continue\n            elif len(r.body) == 2 and all(\n                self.is_nonterminal(y) and y != self.S for y in r.body\n            ):\n                continue\n            else:\n                yield r\n\n    #    def has_nullary(self):\n    #        return any((len(p.body) == 0) for p in self if p.head != self.S)\n\n    def unfold(self, i, k):\n        \"\"\"\n        Apply the unfolding transformation to rule i and subgoal k.\n\n        Args:\n            i: Index of rule to unfold\n            k: Index of subgoal in rule body\n\n        Returns:\n            A new CFG with the rule unfolded\n        \"\"\"\n        assert isinstance(i, int) and isinstance(k, int)\n        s = self.rules[i]\n        assert self.is_nonterminal(s.body[k])\n\n        new = self.spawn()\n        for j, r in enumerate(self):\n            if j != i:\n                new.add(r.w, r.head, *r.body)\n\n        for r in self.rhs[s.body[k]]:\n            new.add(s.w * r.w, s.head, *s.body[:k], *r.body, *s.body[k + 1 :])\n\n        return new\n\n    def dependency_graph(self):\n        \"\"\"\n        Head-to-body dependency graph of the rules of the grammar.\n\n        Returns:\n            A WeightedGraph representing dependencies between symbols\n        \"\"\"\n        deps = WeightedGraph(Boolean)\n        for r in self:\n            for y in r.body:\n                deps[r.head, y] += Boolean.one\n        deps.N |= self.N\n        deps.N |= self.V\n        return deps\n\n    # TODO: the default treesum algorithm should probably be SCC-decomposed newton's method\n    # def agenda(self, tol=1e-12, maxiter=float('inf')):\n    def agenda(self, tol=1e-12, maxiter=100_000):\n        \"\"\"\n        Agenda-based semi-naive evaluation for treesums.\n\n        Args:\n            tol: Convergence tolerance\n            maxiter: Maximum iterations\n\n        Returns:\n            A chart containing the treesum weights\n        \"\"\"\n        old = self.R.chart()\n\n        # precompute the mapping from updates to where they need to go\n        routing = defaultdict(list)\n        for r in self:\n            for k in range(len(r.body)):\n                routing[r.body[k]].append((r, k))\n\n        deps = self.dependency_graph()\n        blocks = deps.blocks\n        bucket = deps.buckets\n\n        # helper function\n        def update(x, W):\n            change[bucket[x]][x] += W\n\n        change = defaultdict(self.R.chart)\n        for a in self.V:\n            update(a, self.R.one)\n\n        for r in self:\n            if len(r.body) == 0:\n                update(r.head, r.w)\n\n        b = len(blocks)\n        iteration = 0\n        while b &gt;= 0:\n            iteration += 1\n\n            # Move on to the next block\n            if len(change[b]) == 0 or iteration &gt; maxiter:\n                b -= 1\n                iteration = 0  # reset iteration number for the next bucket\n                continue\n\n            u, v = change[b].popitem()\n\n            new = old[u] + v\n\n            if self.R.metric(old[u], new) &lt;= tol:\n                continue\n\n            for r, k in routing[u]:\n                W = r.w\n                for j in range(len(r.body)):\n                    if u == r.body[j]:\n                        if j &lt; k:\n                            W *= new\n                        elif j == k:\n                            W *= v\n                        else:\n                            W *= old[u]\n                    else:\n                        W *= old[r.body[j]]\n\n                update(r.head, W)\n\n            old[u] = new\n\n        return old\n\n    def naive_bottom_up(self, *, tol=1e-12, timeout=100_000):\n        \"Naive bottom-up evaluation for treesums; better to use `agenda`.\"\n\n        def _approx_equal(U, V):\n            return all((self.R.metric(U[X], V[X]) &lt;= tol) for X in self.N)\n\n        R = self.R\n        V = R.chart()\n        counter = 0\n        while counter &lt; timeout:\n            U = self._bottom_up_step(V)\n            if _approx_equal(U, V):\n                break\n            V = U\n            counter += 1\n        return V\n\n    def _bottom_up_step(self, V):\n        R = self.R\n        one = R.one\n        U = R.chart()\n        for a in self.V:\n            U[a] = one\n        for p in self:\n            update = p.w\n            for X in p.body:\n                if self.is_nonterminal(X):\n                    update *= V[X]\n            U[p.head] += update\n        return U\n\n    def prefix_weight(self, xs):\n        \"Total weight of all derivations that have `xs` as a prefix.\"\n        return self.prefix_grammar(xs)\n\n    @cached_property\n    def prefix_grammar(self):\n        \"Grammar that generates prefixing of this grammar's language.\"\n        return self @ prefix_transducer(self.R, self.V)\n\n    def derivatives(self, s):\n        \"Return the sequence of derivatives for each prefix of `s`.\"\n        M = len(s)\n        D = [self]\n        for m in range(M):\n            D.append(D[m].derivative(s[m]))\n        return D\n\n    # Implementation note: This implementation of the derivative grammar\n    # performs nullary elimination at the same time.\n    def derivative(self, a, i=0):\n        \"Return a grammar that generates the derivative with respect to `a`.\"\n\n        def slash(x, y):\n            return Slash(x, y, i=i)\n\n        D = self.spawn(S=slash(self.S, a))\n        U = self.null_weight()\n        for r in self:\n            D.add(r.w, r.head, *r.body)\n            delta = self.R.one\n            for k, y in enumerate(r.body):\n                if slash(r.head, a) in self.N:\n                    continue  # SKIP!\n                if self.is_terminal(y):\n                    if y == a:\n                        D.add(delta * r.w, slash(r.head, a), *r.body[k + 1 :])\n                else:\n                    D.add(\n                        delta * r.w,\n                        slash(r.head, a),\n                        slash(r.body[k], a),\n                        *r.body[k + 1 :],\n                    )\n                delta *= U[y]\n        return D\n\n    def _compose_bottom_up_epsilon(self, fst):\n        \"Determine which items of the composition grammar are supported\"\n\n        A = set()\n\n        I = defaultdict(set)  # incomplete items\n        C = defaultdict(set)  # complete items\n        R = defaultdict(set)  # rules indexed by first subgoal; non-nullary\n\n        special_rules = [Rule(self.R.one, a, (EPSILON, a)) for a in self.V] + [\n            Rule(self.R.one, Other(self.S), (self.S,)),\n            Rule(self.R.one, Other(self.S), (Other(self.S), EPSILON)),\n        ]\n\n        for r in itertools.chain(self, special_rules):\n            if len(r.body) &gt; 0:\n                R[r.body[0]].add(r)\n\n        # we have two base cases:\n        #\n        # base case 1: arcs\n        for i, (a, _), j, _ in fst.arcs():\n            A.add((i, a, (), j))  # empty tuple -&gt; the rule 'complete'\n\n        # base case 2: nullary rules\n        for r in self:\n            if len(r.body) == 0:\n                for i in fst.states:\n                    A.add((i, r.head, (), i))\n\n        # drain the agenda\n        while A:\n            (i, X, Ys, j) = A.pop()\n\n            # No pending items ==&gt; the item is complete\n            if not Ys:\n                if j in C[i, X]:\n                    continue\n                C[i, X].add(j)\n\n                # combine the newly completed item with incomplete rules that are\n                # looking for an item like this one\n                for h, X1, Zs in I[i, X]:\n                    A.add((h, X1, Zs[1:], j))\n\n                # initialize rules that can start with an item like this one\n                for r in R[X]:\n                    A.add((i, r.head, r.body[1:], j))\n\n            # Still have pending items ==&gt; advanced the pending items\n            else:\n                if (i, X, Ys) in I[j, Ys[0]]:\n                    continue\n                I[j, Ys[0]].add((i, X, Ys))\n\n                for k in C[j, Ys[0]]:\n                    A.add((i, X, Ys[1:], k))\n\n        return C\n\n    def __matmul__(self, fst):\n        \"Return a CFG denoting the pointwise product or composition of `self` and `fs`.\"\n\n        # coerce something sequence like into a diagonal FST\n        if isinstance(fst, (str, tuple)):\n            fst = FST.from_string(fst, self.R)\n        # coerce something FSA-like into an FST, might throw an error\n        if not isinstance(fst, FST):\n            fst = fst.to_fst()\n\n        # Initialize the new CFG:\n        # - its start symbol is chosen arbitrarily to be `self.S`\n        # - its the alphabet changes - it is now 'output' alphabet of the transducer\n        new_start = self.S\n        new = self.spawn(S=new_start, V=fst.B - {EPSILON})\n\n        # The bottom-up intersection algorithm is a two-pass algorithm\n        #\n        # Pass 1: Determine the set of items that are possiblly nonzero-valued\n        C = self._compose_bottom_up_epsilon(fst)\n\n        special_rules = [Rule(self.R.one, a, (EPSILON, a)) for a in self.V] + [\n            Rule(self.R.one, Other(self.S), (self.S,)),\n            Rule(self.R.one, Other(self.S), (Other(self.S), EPSILON)),\n        ]\n\n        def join(start, Ys):\n            \"\"\"\n            Helper method; expands the rule body\n\n            Given Ys = [Y_1, ... Y_K], we will enumerate expansion of the form\n\n            (s_0, Y_1, s_1), (s_1, Y_2, s_2), ..., (s_{k-1}, Y_K, s_K)\n\n            where each (s_k, Y_k, s_k) in the expansion is a completed items\n            (i.e., \\forall k: (s_k, Y_k, s_k) in C).\n            \"\"\"\n            if not Ys:\n                yield []\n            else:\n                for K in C[start, Ys[0]]:\n                    for rest in join(K, Ys[1:]):\n                        yield [(start, Ys[0], K)] + rest\n\n        start = {I for (I, _) in C}\n\n        for r in itertools.chain(self, special_rules):\n            if len(r.body) == 0:\n                for s in fst.states:\n                    new.add(r.w, (s, r.head, s))\n            else:\n                for I in start:\n                    for rhs in join(I, r.body):\n                        K = rhs[-1][-1]\n                        new.add(r.w, (I, r.head, K), *rhs)\n\n        for i, wi in fst.start.items():\n            for k, wf in fst.stop.items():\n                new.add(wi * wf, new_start, (i, Other(self.S), k))\n\n        for i, (a, b), j, w in fst.arcs():\n            if b == EPSILON:\n                new.add(w, (i, a, j))\n            else:\n                new.add(w, (i, a, j), b)\n        return new\n\n    def truncate_length(self, max_length):\n        \"Transform this grammar so that it only generates strings with length \u2264 `max_length`.\"\n        from genlm.grammar import WFSA\n\n        m = WFSA(self.R)\n        m.add_I(0, self.R.one)\n        m.add_F(0, self.R.one)\n        for t in range(max_length):\n            for x in self.V:\n                m.add_arc(t, x, t + 1, self.R.one)\n            m.add_F(t + 1, self.R.one)\n        return self @ m\n\n    def materialize(self, max_length):\n        \"Return a `Chart` with this grammar's weighted language for strings \u2264 `max_length`.\"\n        return self.cnf.language(max_length).filter(lambda x: len(x) &lt;= max_length)\n\n    def to_bytes(self):\n        \"\"\"Convert terminal symbols from strings to bytes representation.\n\n        This method creates a new grammar where all terminal string symbols are\n        converted to their UTF-8 byte representation. Non-terminal symbols are\n        preserved as-is.\n\n        Returns:\n            CFG: A new grammar with byte terminal symbols\n\n        Raises:\n            ValueError: If a terminal symbol is not a string\n        \"\"\"\n        new = self.spawn(S=self.S, R=self.R, V=set())\n\n        for r in self:\n            new_body = []\n            for x in r.body:\n                if self.is_terminal(x):\n                    if not isinstance(x, str):\n                        raise ValueError(f\"unsupported terminal type: {type(x)}\")\n                    bs = list(x.encode(\"utf-8\"))\n                    for b in bs:\n                        new.V.add(b)\n                    new_body.extend(bs)\n                else:\n                    new_body.append(x)\n            new.add(r.w, r.head, *new_body)\n\n        return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.cnf","title":"<code>cnf</code>  <code>cached</code> <code>property</code>","text":"<p>Transform this grammar into Chomsky Normal Form (CNF).</p> <p>Returns:</p> Type Description <p>A new CFG in CNF</p>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.expected_length","title":"<code>expected_length</code>  <code>property</code>","text":"<p>Compute the expected length of a string using the Expectation semiring.</p> <p>Returns:</p> Type Description <p>The expected length of strings generated by this grammar</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If grammar is not over the Float semiring</p>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.num_rules","title":"<code>num_rules</code>  <code>property</code>","text":"<p>Return number of rules in the grammar.</p>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.prefix_grammar","title":"<code>prefix_grammar</code>  <code>cached</code> <code>property</code>","text":"<p>Grammar that generates prefixing of this grammar's language.</p>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.rhs","title":"<code>rhs</code>  <code>cached</code> <code>property</code>","text":"<p>Map from each nonterminal to the list of rules with it as their left-hand side.</p> <p>Returns:</p> Type Description <p>A dict mapping nonterminals to lists of rules</p>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.size","title":"<code>size</code>  <code>property</code>","text":"<p>Return total size of the grammar (sum of rule lengths).</p>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.__call__","title":"<code>__call__(xs)</code>","text":"<p>Compute the total weight of the sequence xs.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <p>A sequence of terminal symbols</p> required <p>Returns:</p> Type Description <p>The total weight of all derivations of xs</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __call__(self, xs):\n    \"\"\"\n    Compute the total weight of the sequence xs.\n\n    Args:\n        xs: A sequence of terminal symbols\n\n    Returns:\n        The total weight of all derivations of xs\n    \"\"\"\n    self = self.cnf  # need to do this here because the start symbol might change\n    return self._parse_chart(xs)[0, self.S, len(xs)]\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.__getitem__","title":"<code>__getitem__(root)</code>","text":"<p>Return a grammar that denotes the sublanguage of the nonterminal <code>root</code>.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <p>The nonterminal to use as the new start symbol</p> required <p>Returns:</p> Type Description <p>A new CFG with root as the start symbol</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __getitem__(self, root):\n    \"\"\"\n    Return a grammar that denotes the sublanguage of the nonterminal `root`.\n\n    Args:\n        root: The nonterminal to use as the new start symbol\n\n    Returns:\n        A new CFG with root as the start symbol\n    \"\"\"\n    new = self.spawn(S=root)\n    for r in self:\n        new.add(r.w, r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.__init__","title":"<code>__init__(R, S, V)</code>","text":"<p>Initialize a weighted CFG.</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <p>The semiring for rule weights</p> required <code>S</code> <p>The start symbol (nonterminal)</p> required <code>V</code> <p>The set of terminal symbols (vocabulary)</p> required Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __init__(self, R, S, V):\n    \"\"\"\n    Initialize a weighted CFG.\n\n    Args:\n        R: The semiring for rule weights\n        S: The start symbol (nonterminal)\n        V: The set of terminal symbols (vocabulary)\n    \"\"\"\n    self.R = R  # semiring\n    self.V = V  # alphabet\n    self.N = {S}  # nonterminals\n    self.S = S  # unique start symbol\n    self.rules = []  # rules\n    self._trim_cache = [None, None]\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the rules in the grammar.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the rules in the grammar.\"\"\"\n    return iter(self.rules)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.__len__","title":"<code>__len__()</code>","text":"<p>Return number of rules in the grammar.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __len__(self):\n    \"\"\"Return number of rules in the grammar.\"\"\"\n    return len(self.rules)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.__matmul__","title":"<code>__matmul__(fst)</code>","text":"<p>Return a CFG denoting the pointwise product or composition of <code>self</code> and <code>fs</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __matmul__(self, fst):\n    \"Return a CFG denoting the pointwise product or composition of `self` and `fs`.\"\n\n    # coerce something sequence like into a diagonal FST\n    if isinstance(fst, (str, tuple)):\n        fst = FST.from_string(fst, self.R)\n    # coerce something FSA-like into an FST, might throw an error\n    if not isinstance(fst, FST):\n        fst = fst.to_fst()\n\n    # Initialize the new CFG:\n    # - its start symbol is chosen arbitrarily to be `self.S`\n    # - its the alphabet changes - it is now 'output' alphabet of the transducer\n    new_start = self.S\n    new = self.spawn(S=new_start, V=fst.B - {EPSILON})\n\n    # The bottom-up intersection algorithm is a two-pass algorithm\n    #\n    # Pass 1: Determine the set of items that are possiblly nonzero-valued\n    C = self._compose_bottom_up_epsilon(fst)\n\n    special_rules = [Rule(self.R.one, a, (EPSILON, a)) for a in self.V] + [\n        Rule(self.R.one, Other(self.S), (self.S,)),\n        Rule(self.R.one, Other(self.S), (Other(self.S), EPSILON)),\n    ]\n\n    def join(start, Ys):\n        \"\"\"\n        Helper method; expands the rule body\n\n        Given Ys = [Y_1, ... Y_K], we will enumerate expansion of the form\n\n        (s_0, Y_1, s_1), (s_1, Y_2, s_2), ..., (s_{k-1}, Y_K, s_K)\n\n        where each (s_k, Y_k, s_k) in the expansion is a completed items\n        (i.e., \\forall k: (s_k, Y_k, s_k) in C).\n        \"\"\"\n        if not Ys:\n            yield []\n        else:\n            for K in C[start, Ys[0]]:\n                for rest in join(K, Ys[1:]):\n                    yield [(start, Ys[0], K)] + rest\n\n    start = {I for (I, _) in C}\n\n    for r in itertools.chain(self, special_rules):\n        if len(r.body) == 0:\n            for s in fst.states:\n                new.add(r.w, (s, r.head, s))\n        else:\n            for I in start:\n                for rhs in join(I, r.body):\n                    K = rhs[-1][-1]\n                    new.add(r.w, (I, r.head, K), *rhs)\n\n    for i, wi in fst.start.items():\n        for k, wf in fst.stop.items():\n            new.add(wi * wf, new_start, (i, Other(self.S), k))\n\n    for i, (a, b), j, w in fst.arcs():\n        if b == EPSILON:\n            new.add(w, (i, a, j))\n        else:\n            new.add(w, (i, a, j), b)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation of the grammar.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return string representation of the grammar.\"\"\"\n    return \"Grammar {\\n%s\\n}\" % \"\\n\".join(f\"  {r}\" for r in self)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.add","title":"<code>add(w, head, *body)</code>","text":"<p>Add a rule of the form w: head -&gt; body1, body2, ... body_k.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <p>The rule weight</p> required <code>head</code> <p>The left-hand side nonterminal</p> required <code>*body</code> <p>The right-hand side symbols</p> <code>()</code> <p>Returns:</p> Type Description <p>The added rule, or None if weight is zero</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def add(self, w, head, *body):\n    \"\"\"\n    Add a rule of the form w: head -&gt; body1, body2, ... body_k.\n\n    Args:\n        w: The rule weight\n        head: The left-hand side nonterminal\n        *body: The right-hand side symbols\n\n    Returns:\n        The added rule, or None if weight is zero\n    \"\"\"\n    if w == self.R.zero:\n        return  # skip rules with weight zero\n    self.N.add(head)\n    r = Rule(w, head, body)\n    self.rules.append(r)\n    return r\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.agenda","title":"<code>agenda(tol=1e-12, maxiter=100000)</code>","text":"<p>Agenda-based semi-naive evaluation for treesums.</p> <p>Parameters:</p> Name Type Description Default <code>tol</code> <p>Convergence tolerance</p> <code>1e-12</code> <code>maxiter</code> <p>Maximum iterations</p> <code>100000</code> <p>Returns:</p> Type Description <p>A chart containing the treesum weights</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def agenda(self, tol=1e-12, maxiter=100_000):\n    \"\"\"\n    Agenda-based semi-naive evaluation for treesums.\n\n    Args:\n        tol: Convergence tolerance\n        maxiter: Maximum iterations\n\n    Returns:\n        A chart containing the treesum weights\n    \"\"\"\n    old = self.R.chart()\n\n    # precompute the mapping from updates to where they need to go\n    routing = defaultdict(list)\n    for r in self:\n        for k in range(len(r.body)):\n            routing[r.body[k]].append((r, k))\n\n    deps = self.dependency_graph()\n    blocks = deps.blocks\n    bucket = deps.buckets\n\n    # helper function\n    def update(x, W):\n        change[bucket[x]][x] += W\n\n    change = defaultdict(self.R.chart)\n    for a in self.V:\n        update(a, self.R.one)\n\n    for r in self:\n        if len(r.body) == 0:\n            update(r.head, r.w)\n\n    b = len(blocks)\n    iteration = 0\n    while b &gt;= 0:\n        iteration += 1\n\n        # Move on to the next block\n        if len(change[b]) == 0 or iteration &gt; maxiter:\n            b -= 1\n            iteration = 0  # reset iteration number for the next bucket\n            continue\n\n        u, v = change[b].popitem()\n\n        new = old[u] + v\n\n        if self.R.metric(old[u], new) &lt;= tol:\n            continue\n\n        for r, k in routing[u]:\n            W = r.w\n            for j in range(len(r.body)):\n                if u == r.body[j]:\n                    if j &lt; k:\n                        W *= new\n                    elif j == k:\n                        W *= v\n                    else:\n                        W *= old[u]\n                else:\n                    W *= old[r.body[j]]\n\n            update(r.head, W)\n\n        old[u] = new\n\n    return old\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.assert_equal","title":"<code>assert_equal(other, verbose=False, throw=True)</code>","text":"<p>Assertion for the equality of self and other modulo rule reordering.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>The grammar to compare against</p> required <code>verbose</code> <p>If True, print differences</p> <code>False</code> <code>throw</code> <p>If True, raise AssertionError on inequality</p> <code>True</code> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If grammars are not equal and throw=True</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def assert_equal(self, other, verbose=False, throw=True):\n    \"\"\"\n    Assertion for the equality of self and other modulo rule reordering.\n\n    Args:\n        other: The grammar to compare against\n        verbose: If True, print differences\n        throw: If True, raise AssertionError on inequality\n\n    Raises:\n        AssertionError: If grammars are not equal and throw=True\n    \"\"\"\n    assert verbose or throw\n    if isinstance(other, str):\n        other = self.__class__.from_string(other, self.R)\n    if verbose:\n        # TODO: need to check the weights in the print out; we do it in the assertion\n        S = set(self.rules)\n        G = set(other.rules)\n        for r in sorted(S | G, key=str):\n            if r in S and r in G:\n                continue\n            # if r in S and r not in G: continue\n            # if r not in S and r in G: continue\n            print(\n                colors.mark(r in S),\n                # colors.mark(r in S and r in G),\n                colors.mark(r in G),\n                r,\n            )\n    assert not throw or Counter(self.rules) == Counter(other.rules), (\n        f\"\\n\\nhave=\\n{str(self)}\\nwant=\\n{str(other)}\"\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.binarize","title":"<code>binarize()</code>","text":"<p>Return an equivalent grammar with arity \u2264 2.</p> <p>Returns:</p> Type Description <p>A new CFG with binary rules</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def binarize(self):\n    \"\"\"\n    Return an equivalent grammar with arity \u2264 2.\n\n    Returns:\n        A new CFG with binary rules\n    \"\"\"\n    new = self.spawn()\n\n    stack = list(self)\n    while stack:\n        p = stack.pop()\n        if len(p.body) &lt;= 2:\n            new.add(p.w, p.head, *p.body)\n        else:\n            stack.extend(self._fold(p, [(0, 1)]))\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.cotrim","title":"<code>cotrim()</code>","text":"<p>Trim the grammar so that all nonterminals are generating.</p> <p>Returns:</p> Type Description <p>A new CFG with only generating nonterminals</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def cotrim(self):\n    \"\"\"\n    Trim the grammar so that all nonterminals are generating.\n\n    Returns:\n        A new CFG with only generating nonterminals\n    \"\"\"\n    return self.trim(bottomup_only=True)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.dependency_graph","title":"<code>dependency_graph()</code>","text":"<p>Head-to-body dependency graph of the rules of the grammar.</p> <p>Returns:</p> Type Description <p>A WeightedGraph representing dependencies between symbols</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def dependency_graph(self):\n    \"\"\"\n    Head-to-body dependency graph of the rules of the grammar.\n\n    Returns:\n        A WeightedGraph representing dependencies between symbols\n    \"\"\"\n    deps = WeightedGraph(Boolean)\n    for r in self:\n        for y in r.body:\n            deps[r.head, y] += Boolean.one\n    deps.N |= self.N\n    deps.N |= self.V\n    return deps\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.derivations","title":"<code>derivations(X, H)</code>","text":"<p>Enumerate derivations of symbol X with height &lt;= H.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The symbol to derive from (default: start symbol)</p> required <code>H</code> <p>Maximum derivation height</p> required <p>Yields:</p> Type Description <p>Derivation objects representing derivation trees</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def derivations(self, X, H):\n    \"\"\"\n    Enumerate derivations of symbol X with height &lt;= H.\n\n    Args:\n        X: The symbol to derive from (default: start symbol)\n        H: Maximum derivation height\n\n    Yields:\n        Derivation objects representing derivation trees\n    \"\"\"\n    if X is None:\n        X = self.S\n    if self.is_terminal(X):\n        yield X\n    elif H &lt;= 0:\n        return\n    else:\n        for r in self.rhs[X]:\n            for ys in self._derivations_list(r.body, H - 1):\n                yield Derivation(r, X, *ys)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.derivative","title":"<code>derivative(a, i=0)</code>","text":"<p>Return a grammar that generates the derivative with respect to <code>a</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def derivative(self, a, i=0):\n    \"Return a grammar that generates the derivative with respect to `a`.\"\n\n    def slash(x, y):\n        return Slash(x, y, i=i)\n\n    D = self.spawn(S=slash(self.S, a))\n    U = self.null_weight()\n    for r in self:\n        D.add(r.w, r.head, *r.body)\n        delta = self.R.one\n        for k, y in enumerate(r.body):\n            if slash(r.head, a) in self.N:\n                continue  # SKIP!\n            if self.is_terminal(y):\n                if y == a:\n                    D.add(delta * r.w, slash(r.head, a), *r.body[k + 1 :])\n            else:\n                D.add(\n                    delta * r.w,\n                    slash(r.head, a),\n                    slash(r.body[k], a),\n                    *r.body[k + 1 :],\n                )\n            delta *= U[y]\n    return D\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.derivatives","title":"<code>derivatives(s)</code>","text":"<p>Return the sequence of derivatives for each prefix of <code>s</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def derivatives(self, s):\n    \"Return the sequence of derivatives for each prefix of `s`.\"\n    M = len(s)\n    D = [self]\n    for m in range(M):\n        D.append(D[m].derivative(s[m]))\n    return D\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.from_string","title":"<code>from_string(string, semiring, comment='#', start='S', is_terminal=lambda x: not x[0].isupper())</code>  <code>classmethod</code>","text":"<p>Create a CFG from a string representation.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <p>The grammar rules as a string</p> required <code>semiring</code> <p>The semiring for rule weights</p> required <code>comment</code> <p>Comment character to ignore lines (default: '#')</p> <code>'#'</code> <code>start</code> <p>Start symbol (default: 'S')</p> <code>'S'</code> <code>is_terminal</code> <p>Function to identify terminal symbols (default: lowercase first letter)</p> <code>lambda x: not isupper()</code> <p>Returns:</p> Type Description <p>A new CFG instance</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>@classmethod\ndef from_string(\n    cls,\n    string,\n    semiring,\n    comment=\"#\",\n    start=\"S\",\n    is_terminal=lambda x: not x[0].isupper(),\n):\n    \"\"\"\n    Create a CFG from a string representation.\n\n    Args:\n        string: The grammar rules as a string\n        semiring: The semiring for rule weights\n        comment: Comment character to ignore lines (default: '#')\n        start: Start symbol (default: 'S')\n        is_terminal: Function to identify terminal symbols (default: lowercase first letter)\n\n    Returns:\n        A new CFG instance\n    \"\"\"\n    V = set()\n    cfg = cls(R=semiring, S=start, V=V)\n    string = string.replace(\"-&gt;\", \"\u2192\")  # synonym for the arrow\n    for line in string.split(\"\\n\"):\n        line = line.strip()\n        if not line or line.startswith(comment):\n            continue\n        try:\n            [(w, lhs, rhs)] = re.findall(r\"(.*):\\s*(\\S+)\\s*\u2192\\s*(.*)$\", line)\n            lhs = lhs.strip()\n            rhs = rhs.strip().split()\n            for x in rhs:\n                if is_terminal(x):\n                    V.add(x)\n            cfg.add(semiring.from_string(w), lhs, *rhs)\n        except ValueError:\n            raise ValueError(f\"bad input line:\\n{line}\")  # pylint: disable=W0707\n    return cfg\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.has_unary_cycle","title":"<code>has_unary_cycle()</code>","text":"<p>Check if the grammar has unary cycles.</p> <p>Returns:</p> Type Description <p>True if the grammar contains unary cycles</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def has_unary_cycle(self):\n    \"\"\"\n    Check if the grammar has unary cycles.\n\n    Returns:\n        True if the grammar contains unary cycles\n    \"\"\"\n    f = self._unary_graph().buckets\n    return any(\n        True for r in self if len(r.body) == 1 and f.get(r.head) == f.get(r.body[0])\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.in_cnf","title":"<code>in_cnf()</code>","text":"<p>Return true if the grammar is in CNF.</p> <p>Returns:</p> Type Description <p>True if grammar is in Chomsky Normal Form</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def in_cnf(self):\n    \"\"\"\n    Return true if the grammar is in CNF.\n\n    Returns:\n        True if grammar is in Chomsky Normal Form\n    \"\"\"\n    return len(list(self._find_invalid_cnf_rule())) == 0\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.is_nonterminal","title":"<code>is_nonterminal(X)</code>","text":"<p>Return True if X is a nonterminal symbol.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def is_nonterminal(self, X):\n    \"\"\"Return True if X is a nonterminal symbol.\"\"\"\n    return not self.is_terminal(X)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.is_terminal","title":"<code>is_terminal(x)</code>","text":"<p>Return True if x is a terminal symbol.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def is_terminal(self, x):\n    \"\"\"Return True if x is a terminal symbol.\"\"\"\n    return x in self.V\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.language","title":"<code>language(depth)</code>","text":"<p>Enumerate strings generated by this cfg by derivations up to the given depth.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <p>Maximum derivation depth to consider</p> required <p>Returns:</p> Type Description <p>A chart containing the weighted language up to the given depth</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def language(self, depth):\n    \"\"\"\n    Enumerate strings generated by this cfg by derivations up to the given depth.\n\n    Args:\n        depth: Maximum derivation depth to consider\n\n    Returns:\n        A chart containing the weighted language up to the given depth\n    \"\"\"\n    lang = self.R.chart()\n    for d in self.derivations(self.S, depth):\n        lang[d.Yield()] += d.weight()\n    return lang\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.map_values","title":"<code>map_values(f, R)</code>","text":"<p>Return a new grammar that is the result of applying f: self.R -&gt; R to each rule's weight.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Function to map weights</p> required <code>R</code> <p>New semiring for weights</p> required <p>Returns:</p> Type Description <p>A new CFG with mapped weights</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def map_values(self, f, R):\n    \"\"\"\n    Return a new grammar that is the result of applying f: self.R -&gt; R to each rule's weight.\n\n    Args:\n        f: Function to map weights\n        R: New semiring for weights\n\n    Returns:\n        A new CFG with mapped weights\n    \"\"\"\n    new = self.spawn(R=R)\n    for r in self:\n        new.add(f(r.w), r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.materialize","title":"<code>materialize(max_length)</code>","text":"<p>Return a <code>Chart</code> with this grammar's weighted language for strings \u2264 <code>max_length</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def materialize(self, max_length):\n    \"Return a `Chart` with this grammar's weighted language for strings \u2264 `max_length`.\"\n    return self.cnf.language(max_length).filter(lambda x: len(x) &lt;= max_length)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.naive_bottom_up","title":"<code>naive_bottom_up(*, tol=1e-12, timeout=100000)</code>","text":"<p>Naive bottom-up evaluation for treesums; better to use <code>agenda</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def naive_bottom_up(self, *, tol=1e-12, timeout=100_000):\n    \"Naive bottom-up evaluation for treesums; better to use `agenda`.\"\n\n    def _approx_equal(U, V):\n        return all((self.R.metric(U[X], V[X]) &lt;= tol) for X in self.N)\n\n    R = self.R\n    V = R.chart()\n    counter = 0\n    while counter &lt; timeout:\n        U = self._bottom_up_step(V)\n        if _approx_equal(U, V):\n            break\n        V = U\n        counter += 1\n    return V\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.null_weight","title":"<code>null_weight()</code>","text":"<p>Compute the map from nonterminal to total weight of generating the empty string.</p> <p>Returns:</p> Type Description <p>A dict mapping nonterminals to their null weights</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def null_weight(self):\n    \"\"\"\n    Compute the map from nonterminal to total weight of generating the empty string.\n\n    Returns:\n        A dict mapping nonterminals to their null weights\n    \"\"\"\n    ecfg = self.spawn(V=set())\n    for p in self:\n        if not any(self.is_terminal(y) for y in p.body):\n            ecfg.add(p.w, p.head, *p.body)\n    return ecfg.agenda()\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.null_weight_start","title":"<code>null_weight_start()</code>","text":"<p>Compute the null weight of the start symbol.</p> <p>Returns:</p> Type Description <p>The total weight of generating the empty string from the start symbol</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def null_weight_start(self):\n    \"\"\"\n    Compute the null weight of the start symbol.\n\n    Returns:\n        The total weight of generating the empty string from the start symbol\n    \"\"\"\n    return self.null_weight()[self.S]\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.nullaryremove","title":"<code>nullaryremove(binarize=True, trim=True, **kwargs)</code>","text":"<p>Return an equivalent grammar with no nullary rules except for one at the start symbol.</p> <p>Parameters:</p> Name Type Description Default <code>binarize</code> <p>If True, binarize the grammar first</p> <code>True</code> <code>trim</code> <p>If True, trim the resulting grammar</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to _push_null_weights</p> <code>{}</code> <p>Returns:</p> Type Description <p>A new CFG without nullary rules (except at start)</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def nullaryremove(self, binarize=True, trim=True, **kwargs):\n    \"\"\"\n    Return an equivalent grammar with no nullary rules except for one at the start symbol.\n\n    Args:\n        binarize: If True, binarize the grammar first\n        trim: If True, trim the resulting grammar\n        **kwargs: Additional arguments passed to _push_null_weights\n\n    Returns:\n        A new CFG without nullary rules (except at start)\n    \"\"\"\n    # A really wide rule can take a very long time because of the power set\n    # in this rule so it is really important to binarize.\n    if binarize:\n        self = self.binarize()  # pragma: no cover\n    self = self.separate_start()\n    tmp = self._push_null_weights(self.null_weight(), **kwargs)\n    return tmp.trim() if trim else tmp\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.prefix_weight","title":"<code>prefix_weight(xs)</code>","text":"<p>Total weight of all derivations that have <code>xs</code> as a prefix.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def prefix_weight(self, xs):\n    \"Total weight of all derivations that have `xs` as a prefix.\"\n    return self.prefix_grammar(xs)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.rename","title":"<code>rename(f)</code>","text":"<p>Return a new grammar that is the result of applying f to each nonterminal.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Function to rename nonterminals</p> required <p>Returns:</p> Type Description <p>A new CFG with renamed nonterminals</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def rename(self, f):\n    \"\"\"\n    Return a new grammar that is the result of applying f to each nonterminal.\n\n    Args:\n        f: Function to rename nonterminals\n\n    Returns:\n        A new CFG with renamed nonterminals\n    \"\"\"\n    new = self.spawn(S=f(self.S))\n    for r in self:\n        new.add(\n            r.w, f(r.head), *((y if self.is_terminal(y) else f(y) for y in r.body))\n        )\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.renumber","title":"<code>renumber()</code>","text":"<p>Rename nonterminals to integers.</p> <p>Returns:</p> Type Description <p>A new CFG with integer nonterminals</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def renumber(self):\n    \"\"\"\n    Rename nonterminals to integers.\n\n    Returns:\n        A new CFG with integer nonterminals\n    \"\"\"\n    i = Integerizer()\n    max_v = max((x for x in self.V if isinstance(x, int)), default=0)\n    return self.rename(lambda x: i(x) + max_v + 1)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.separate_start","title":"<code>separate_start()</code>","text":"<p>Ensure that the start symbol does not appear on the RHS of any rule.</p> <p>Returns:</p> Type Description <p>A new CFG with start symbol only on LHS</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def separate_start(self):\n    \"\"\"\n    Ensure that the start symbol does not appear on the RHS of any rule.\n\n    Returns:\n        A new CFG with start symbol only on LHS\n    \"\"\"\n    # create a new start symbol if the current one appears on the rhs of any existing rule\n    if self.S in {y for r in self for y in r.body}:\n        S = _gen_nt(self.S)\n        new = self.spawn(S=S)\n        # preterminal rules\n        new.add(self.R.one, S, self.S)\n        for r in self:\n            new.add(r.w, r.head, *r.body)\n        return new\n    else:\n        return self\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.separate_terminals","title":"<code>separate_terminals()</code>","text":"<p>Ensure that each terminal is produced by a preterminal rule.</p> <p>Returns:</p> Type Description <p>A new CFG with terminals only in preterminal rules</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def separate_terminals(self):\n    \"\"\"\n    Ensure that each terminal is produced by a preterminal rule.\n\n    Returns:\n        A new CFG with terminals only in preterminal rules\n    \"\"\"\n    one = self.R.one\n    new = self.spawn()\n\n    _preterminal = {}\n\n    def preterminal(x):\n        y = _preterminal.get(x)\n        if y is None:\n            y = new.add(one, _gen_nt(), x)\n            _preterminal[x] = y\n        return y\n\n    for r in self:\n        if len(r.body) == 1 and self.is_terminal(r.body[0]):\n            new.add(r.w, r.head, *r.body)\n        else:\n            new.add(\n                r.w,\n                r.head,\n                *(\n                    (preterminal(y).head if self.is_terminal(y) else y)\n                    for y in r.body\n                ),\n            )\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.spawn","title":"<code>spawn(*, R=None, S=None, V=None)</code>","text":"<p>Create an empty grammar with the same R, S, and V.</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <p>Optional new semiring</p> <code>None</code> <code>S</code> <p>Optional new start symbol</p> <code>None</code> <code>V</code> <p>Optional new vocabulary</p> <code>None</code> <p>Returns:</p> Type Description <p>A new empty CFG with specified parameters</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def spawn(self, *, R=None, S=None, V=None):\n    \"\"\"\n    Create an empty grammar with the same R, S, and V.\n\n    Args:\n        R: Optional new semiring\n        S: Optional new start symbol\n        V: Optional new vocabulary\n\n    Returns:\n        A new empty CFG with specified parameters\n    \"\"\"\n    return self.__class__(\n        R=self.R if R is None else R,\n        S=self.S if S is None else S,\n        V=set(self.V) if V is None else V,\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.to_bytes","title":"<code>to_bytes()</code>","text":"<p>Convert terminal symbols from strings to bytes representation.</p> <p>This method creates a new grammar where all terminal string symbols are converted to their UTF-8 byte representation. Non-terminal symbols are preserved as-is.</p> <p>Returns:</p> Name Type Description <code>CFG</code> <p>A new grammar with byte terminal symbols</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a terminal symbol is not a string</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def to_bytes(self):\n    \"\"\"Convert terminal symbols from strings to bytes representation.\n\n    This method creates a new grammar where all terminal string symbols are\n    converted to their UTF-8 byte representation. Non-terminal symbols are\n    preserved as-is.\n\n    Returns:\n        CFG: A new grammar with byte terminal symbols\n\n    Raises:\n        ValueError: If a terminal symbol is not a string\n    \"\"\"\n    new = self.spawn(S=self.S, R=self.R, V=set())\n\n    for r in self:\n        new_body = []\n        for x in r.body:\n            if self.is_terminal(x):\n                if not isinstance(x, str):\n                    raise ValueError(f\"unsupported terminal type: {type(x)}\")\n                bs = list(x.encode(\"utf-8\"))\n                for b in bs:\n                    new.V.add(b)\n                new_body.extend(bs)\n            else:\n                new_body.append(x)\n        new.add(r.w, r.head, *new_body)\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.treesum","title":"<code>treesum(**kwargs)</code>","text":"<p>Total weight of the start symbol.</p> <p>Returns:</p> Type Description <p>The total weight of all derivations from the start symbol</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def treesum(self, **kwargs):\n    \"\"\"\n    Total weight of the start symbol.\n\n    Returns:\n        The total weight of all derivations from the start symbol\n    \"\"\"\n    return self.agenda(**kwargs)[self.S]\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.trim","title":"<code>trim(bottomup_only=False)</code>","text":"<p>Return an equivalent grammar with no dead or useless nonterminals or rules.</p> <p>Parameters:</p> Name Type Description Default <code>bottomup_only</code> <p>If True, only remove non-generating nonterminals</p> <code>False</code> <p>Returns:</p> Type Description <p>A new trimmed CFG</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def trim(self, bottomup_only=False):\n    \"\"\"\n    Return an equivalent grammar with no dead or useless nonterminals or rules.\n\n    Args:\n        bottomup_only: If True, only remove non-generating nonterminals\n\n    Returns:\n        A new trimmed CFG\n    \"\"\"\n    if self._trim_cache[bottomup_only] is not None:\n        return self._trim_cache[bottomup_only]\n\n    C = set(self.V)\n    C.update(e.head for e in self.rules if len(e.body) == 0)\n\n    incoming = defaultdict(list)\n    outgoing = defaultdict(list)\n    for e in self:\n        incoming[e.head].append(e)\n        for b in e.body:\n            outgoing[b].append(e)\n\n    agenda = set(C)\n    while agenda:\n        x = agenda.pop()\n        for e in outgoing[x]:\n            if all((b in C) for b in e.body):\n                if e.head not in C:\n                    C.add(e.head)\n                    agenda.add(e.head)\n\n    if bottomup_only:\n        val = self._trim(C)\n        self._trim_cache[bottomup_only] = val\n        val._trim_cache[bottomup_only] = val\n        return val\n\n    T = {self.S}\n    agenda.update(T)\n    while agenda:\n        x = agenda.pop()\n        for e in incoming[x]:\n            # assert e.head in T\n            for b in e.body:\n                if b not in T and b in C:\n                    T.add(b)\n                    agenda.add(b)\n\n    val = self._trim(T)\n    self._trim_cache[bottomup_only] = val\n    val._trim_cache[bottomup_only] = val\n    return val\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.truncate_length","title":"<code>truncate_length(max_length)</code>","text":"<p>Transform this grammar so that it only generates strings with length \u2264 <code>max_length</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def truncate_length(self, max_length):\n    \"Transform this grammar so that it only generates strings with length \u2264 `max_length`.\"\n    from genlm.grammar import WFSA\n\n    m = WFSA(self.R)\n    m.add_I(0, self.R.one)\n    m.add_F(0, self.R.one)\n    for t in range(max_length):\n        for x in self.V:\n            m.add_arc(t, x, t + 1, self.R.one)\n        m.add_F(t + 1, self.R.one)\n    return self @ m\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.unarycycleremove","title":"<code>unarycycleremove(trim=True)</code>","text":"<p>Return an equivalent grammar with no unary cycles.</p> <p>Parameters:</p> Name Type Description Default <code>trim</code> <p>If True, trim the resulting grammar</p> <code>True</code> <p>Returns:</p> Type Description <p>A new CFG without unary cycles</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def unarycycleremove(self, trim=True):\n    \"\"\"\n    Return an equivalent grammar with no unary cycles.\n\n    Args:\n        trim: If True, trim the resulting grammar\n\n    Returns:\n        A new CFG without unary cycles\n    \"\"\"\n\n    def bot(x):\n        return x if x in acyclic else (x, \"bot\")\n\n    G = self._unary_graph()\n\n    new = self.spawn(S=self.S)\n\n    bucket = G.buckets\n\n    acyclic = set()\n    for nodes, _ in G.Blocks:\n        if len(nodes) == 1:\n            [X] = nodes\n            if G[X, X] == self.R.zero:\n                acyclic.add(X)\n\n    # run Lehmann's on each cylical SCC\n    for nodes, W in G.Blocks:\n        if len(nodes) == 1:\n            [X] = nodes\n            if X in acyclic:\n                continue\n\n        for X1, X2 in W:\n            new.add(W[X1, X2], X1, bot(X2))\n\n    for r in self:\n        if len(r.body) == 1 and bucket.get(r.body[0]) == bucket[r.head]:\n            continue\n        new.add(r.w, bot(r.head), *r.body)\n\n    # TODO: figure out how to ensure that the new grammar is trimmed by\n    # construction (assuming the input grammar was trim).\n    if trim:\n        new = new.trim()\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.unaryremove","title":"<code>unaryremove()</code>","text":"<p>Return an equivalent grammar with no unary rules.</p> <p>Returns:</p> Type Description <p>A new CFG without unary rules</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def unaryremove(self):\n    \"\"\"\n    Return an equivalent grammar with no unary rules.\n\n    Returns:\n        A new CFG without unary rules\n    \"\"\"\n    W = self._unary_graph().closure_scc_based()\n    # W = self._unary_graph().closure_reference()\n\n    new = self.spawn()\n    for r in self:\n        if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n            continue\n        for Y in self.N:\n            new.add(W[Y, r.head] * r.w, Y, *r.body)\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.CFG.unfold","title":"<code>unfold(i, k)</code>","text":"<p>Apply the unfolding transformation to rule i and subgoal k.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <p>Index of rule to unfold</p> required <code>k</code> <p>Index of subgoal in rule body</p> required <p>Returns:</p> Type Description <p>A new CFG with the rule unfolded</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def unfold(self, i, k):\n    \"\"\"\n    Apply the unfolding transformation to rule i and subgoal k.\n\n    Args:\n        i: Index of rule to unfold\n        k: Index of subgoal in rule body\n\n    Returns:\n        A new CFG with the rule unfolded\n    \"\"\"\n    assert isinstance(i, int) and isinstance(k, int)\n    s = self.rules[i]\n    assert self.is_nonterminal(s.body[k])\n\n    new = self.spawn()\n    for j, r in enumerate(self):\n        if j != i:\n            new.add(r.w, r.head, *r.body)\n\n    for r in self.rhs[s.body[k]]:\n        new.add(s.w * r.w, s.head, *s.body[:k], *r.body, *s.body[k + 1 :])\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart","title":"<code>Chart</code>","text":"<p>               Bases: <code>dict</code></p> <p>A weighted chart data structure that extends dict with semiring operations.</p> <p>The Chart class provides methods for semiring operations like addition and multiplication, as well as utilities for filtering, comparing, and manipulating weighted values.</p> <p>Attributes:</p> Name Type Description <code>semiring</code> <p>The semiring that defines the weight operations</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>class Chart(dict):\n    \"\"\"A weighted chart data structure that extends dict with semiring operations.\n\n    The Chart class provides methods for semiring operations like addition and multiplication,\n    as well as utilities for filtering, comparing, and manipulating weighted values.\n\n    Attributes:\n        semiring: The semiring that defines the weight operations\n    \"\"\"\n\n    def __init__(self, semiring, vals=()):\n        \"\"\"Initialize a Chart.\n\n        Args:\n            semiring: The semiring for weight operations\n            vals: Optional initial values for the chart\n        \"\"\"\n        self.semiring = semiring\n        super().__init__(vals)\n\n    def __missing__(self, k):\n        \"\"\"Return zero weight for missing keys.\"\"\"\n        return self.semiring.zero\n\n    def spawn(self):\n        \"\"\"Create a new empty Chart with the same semiring.\"\"\"\n        return Chart(self.semiring)\n\n    def __add__(self, other):\n        \"\"\"Add two charts element-wise.\n\n        Args:\n            other: Another Chart to add to this one\n\n        Returns:\n            A new Chart containing the element-wise sum\n        \"\"\"\n        new = self.spawn()\n        for k, v in self.items():\n            new[k] += v\n        for k, v in other.items():\n            new[k] += v\n        return new\n\n    def __mul__(self, other):\n        \"\"\"Multiply two charts element-wise.\n\n        Args:\n            other: Another Chart to multiply with this one\n\n        Returns:\n            A new Chart containing the element-wise product\n        \"\"\"\n        new = self.spawn()\n        for k in self:\n            v = self[k] * other[k]\n            if v == self.semiring.zero:\n                continue\n            new[k] += v\n        return new\n\n    def product(self, ks):\n        \"\"\"Compute the product of values for the given keys.\n\n        Args:\n            ks: Sequence of keys to multiply values for\n\n        Returns:\n            The product of values for the given keys\n        \"\"\"\n        v = self.semiring.one\n        for k in ks:\n            v *= self[k]\n        return v\n\n    def copy(self):\n        \"\"\"Create a shallow copy of this Chart.\"\"\"\n        return Chart(self.semiring, self)\n\n    def trim(self):\n        \"\"\"Return a new Chart with zero-weight entries removed.\"\"\"\n        return Chart(\n            self.semiring, {k: v for k, v in self.items() if v != self.semiring.zero}\n        )\n\n    def metric(self, other):\n        \"\"\"Compute the maximum distance between this Chart and another.\n\n        Args:\n            other: Another Chart to compare against\n\n        Returns:\n            The maximum semiring metric between corresponding values\n        \"\"\"\n        assert isinstance(other, Chart)\n        err = 0\n        for x in self.keys() | other.keys():\n            err = max(err, self.semiring.metric(self[x], other[x]))\n        return err\n\n    def _repr_html_(self):\n        \"\"\"Return HTML representation for Jupyter notebooks.\"\"\"\n        return (\n            '&lt;div style=\"font-family: Monospace;\"&gt;'\n            + format_table(self.trim().items(), headings=[\"key\", \"value\"])\n            + \"&lt;/div&gt;\"\n        )\n\n    def __repr__(self):\n        \"\"\"Return string representation, excluding zero weights.\"\"\"\n        return repr({k: v for k, v in self.items() if v != self.semiring.zero})\n\n    def __str__(self, style_value=lambda k, v: str(v)):\n        \"\"\"Return formatted string representation.\n\n        Args:\n            style_value: Optional function to format values\n\n        Returns:\n            Formatted string showing non-zero entries\n        \"\"\"\n\n        def key(k):\n            return -self.semiring.metric(self[k], self.semiring.zero)\n\n        return (\n            \"Chart {\\n\"\n            + \"\\n\".join(\n                f\"  {k!r}: {style_value(k, self[k])},\"\n                for k in sorted(self, key=key)\n                if self[k] != self.semiring.zero\n            )\n            + \"\\n}\"\n        )\n\n    def assert_equal(self, want, *, domain=None, tol=1e-5, verbose=False, throw=True):\n        \"\"\"Assert that this Chart equals another within tolerance.\n\n        Args:\n            want: The expected Chart or dict of values\n            domain: Optional set of keys to check\n            tol: Tolerance for floating point comparisons\n            verbose: Whether to print detailed comparison\n            throw: Whether to raise AssertionError on mismatch\n        \"\"\"\n        if not isinstance(want, Chart):\n            want = self.semiring.chart(want)\n        if domain is None:\n            domain = self.keys() | want.keys()\n        assert verbose or throw\n        errors = []\n        for x in domain:\n            if self.semiring.metric(self[x], want[x]) &lt;= tol:\n                if verbose:\n                    print(colors.mark(True), x, self[x])\n            else:\n                if verbose:\n                    print(colors.mark(False), x, self[x], want[x])\n                errors.append(x)\n        if throw:\n            for x in errors:\n                raise AssertionError(f\"{x}: {self[x]} {want[x]}\")\n\n    def argmax(self):\n        \"\"\"Return the key with maximum value.\"\"\"\n        return max(self, key=self.__getitem__)\n\n    def argmin(self):\n        \"\"\"Return the key with minimum value.\"\"\"\n        return min(self, key=self.__getitem__)\n\n    def top(self, k):\n        \"\"\"Return a new Chart with the k largest values.\n\n        Args:\n            k: Number of top values to keep\n\n        Returns:\n            A new Chart containing only the k largest values\n        \"\"\"\n        return Chart(\n            self.semiring,\n            {k: self[k] for k in sorted(self, key=self.__getitem__, reverse=True)[:k]},\n        )\n\n    def max(self):\n        \"\"\"Return the maximum value in the Chart.\"\"\"\n        return max(self.values())\n\n    def min(self):\n        \"\"\"Return the minimum value in the Chart.\"\"\"\n        return min(self.values())\n\n    def sum(self):\n        \"\"\"Return the sum of all values in the Chart.\"\"\"\n        return sum(self.values())\n\n    def sort(self, **kwargs):\n        \"\"\"Return a new Chart with entries sorted by key.\n\n        Args:\n            **kwargs: Arguments passed to sorted()\n\n        Returns:\n            A new Chart with sorted entries\n        \"\"\"\n        return self.semiring.chart((k, self[k]) for k in sorted(self, **kwargs))\n\n    def sort_descending(self):\n        \"\"\"Return a new Chart with entries sorted by decreasing value.\"\"\"\n        return self.semiring.chart(\n            (k, self[k]) for k in sorted(self, key=lambda k: -self[k])\n        )\n\n    def normalize(self):\n        \"\"\"Return a new Chart with values normalized to sum to 1.\"\"\"\n        Z = self.sum()\n        if Z == 0:\n            return self\n        return self.semiring.chart((k, v / Z) for k, v in self.items())\n\n    def filter(self, f):\n        \"\"\"Return a new Chart keeping only entries where f(key) is True.\n\n        Args:\n            f: Predicate function that takes a key and returns bool\n\n        Returns:\n            A new Chart containing only entries where f(key) is True\n        \"\"\"\n        return self.semiring.chart((k, v) for k, v in self.items() if f(k))\n\n    def project(self, f):\n        \"\"\"Apply a function to keys, summing weights when transformed keys overlap.\n\n        Args:\n            f: Function to transform keys\n\n        Returns:\n            A new Chart with transformed keys and summed weights\n        \"\"\"\n        out = self.semiring.chart()\n        for k, v in self.items():\n            out[f(k)] += v\n        return out\n\n    # TODO: the more general version of this method is join\n    def compare(self, other, *, domain=None):\n        \"\"\"Compare this Chart to another using pandas DataFrame.\n\n        Args:\n            other: Another Chart or dict to compare against\n            domain: Optional set of keys to compare\n\n        Returns:\n            pandas DataFrame showing key-by-key comparison\n        \"\"\"\n        import pandas as pd\n\n        if not isinstance(other, Chart):\n            other = self.semiring.chart(other)\n        if domain is None:\n            domain = self.keys() | other.keys()\n        rows = []\n        for x in domain:\n            m = self.semiring.metric(self[x], other[x])\n            rows.append(dict(key=x, self=self[x], other=other[x], metric=m))\n        return pd.DataFrame(rows)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.__add__","title":"<code>__add__(other)</code>","text":"<p>Add two charts element-wise.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart to add to this one</p> required <p>Returns:</p> Type Description <p>A new Chart containing the element-wise sum</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __add__(self, other):\n    \"\"\"Add two charts element-wise.\n\n    Args:\n        other: Another Chart to add to this one\n\n    Returns:\n        A new Chart containing the element-wise sum\n    \"\"\"\n    new = self.spawn()\n    for k, v in self.items():\n        new[k] += v\n    for k, v in other.items():\n        new[k] += v\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.__init__","title":"<code>__init__(semiring, vals=())</code>","text":"<p>Initialize a Chart.</p> <p>Parameters:</p> Name Type Description Default <code>semiring</code> <p>The semiring for weight operations</p> required <code>vals</code> <p>Optional initial values for the chart</p> <code>()</code> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __init__(self, semiring, vals=()):\n    \"\"\"Initialize a Chart.\n\n    Args:\n        semiring: The semiring for weight operations\n        vals: Optional initial values for the chart\n    \"\"\"\n    self.semiring = semiring\n    super().__init__(vals)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.__missing__","title":"<code>__missing__(k)</code>","text":"<p>Return zero weight for missing keys.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __missing__(self, k):\n    \"\"\"Return zero weight for missing keys.\"\"\"\n    return self.semiring.zero\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiply two charts element-wise.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart to multiply with this one</p> required <p>Returns:</p> Type Description <p>A new Chart containing the element-wise product</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __mul__(self, other):\n    \"\"\"Multiply two charts element-wise.\n\n    Args:\n        other: Another Chart to multiply with this one\n\n    Returns:\n        A new Chart containing the element-wise product\n    \"\"\"\n    new = self.spawn()\n    for k in self:\n        v = self[k] * other[k]\n        if v == self.semiring.zero:\n            continue\n        new[k] += v\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation, excluding zero weights.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return string representation, excluding zero weights.\"\"\"\n    return repr({k: v for k, v in self.items() if v != self.semiring.zero})\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.__str__","title":"<code>__str__(style_value=lambda k, v: str(v))</code>","text":"<p>Return formatted string representation.</p> <p>Parameters:</p> Name Type Description Default <code>style_value</code> <p>Optional function to format values</p> <code>lambda k, v: str(v)</code> <p>Returns:</p> Type Description <p>Formatted string showing non-zero entries</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __str__(self, style_value=lambda k, v: str(v)):\n    \"\"\"Return formatted string representation.\n\n    Args:\n        style_value: Optional function to format values\n\n    Returns:\n        Formatted string showing non-zero entries\n    \"\"\"\n\n    def key(k):\n        return -self.semiring.metric(self[k], self.semiring.zero)\n\n    return (\n        \"Chart {\\n\"\n        + \"\\n\".join(\n            f\"  {k!r}: {style_value(k, self[k])},\"\n            for k in sorted(self, key=key)\n            if self[k] != self.semiring.zero\n        )\n        + \"\\n}\"\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.argmax","title":"<code>argmax()</code>","text":"<p>Return the key with maximum value.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def argmax(self):\n    \"\"\"Return the key with maximum value.\"\"\"\n    return max(self, key=self.__getitem__)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.argmin","title":"<code>argmin()</code>","text":"<p>Return the key with minimum value.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def argmin(self):\n    \"\"\"Return the key with minimum value.\"\"\"\n    return min(self, key=self.__getitem__)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.assert_equal","title":"<code>assert_equal(want, *, domain=None, tol=1e-05, verbose=False, throw=True)</code>","text":"<p>Assert that this Chart equals another within tolerance.</p> <p>Parameters:</p> Name Type Description Default <code>want</code> <p>The expected Chart or dict of values</p> required <code>domain</code> <p>Optional set of keys to check</p> <code>None</code> <code>tol</code> <p>Tolerance for floating point comparisons</p> <code>1e-05</code> <code>verbose</code> <p>Whether to print detailed comparison</p> <code>False</code> <code>throw</code> <p>Whether to raise AssertionError on mismatch</p> <code>True</code> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def assert_equal(self, want, *, domain=None, tol=1e-5, verbose=False, throw=True):\n    \"\"\"Assert that this Chart equals another within tolerance.\n\n    Args:\n        want: The expected Chart or dict of values\n        domain: Optional set of keys to check\n        tol: Tolerance for floating point comparisons\n        verbose: Whether to print detailed comparison\n        throw: Whether to raise AssertionError on mismatch\n    \"\"\"\n    if not isinstance(want, Chart):\n        want = self.semiring.chart(want)\n    if domain is None:\n        domain = self.keys() | want.keys()\n    assert verbose or throw\n    errors = []\n    for x in domain:\n        if self.semiring.metric(self[x], want[x]) &lt;= tol:\n            if verbose:\n                print(colors.mark(True), x, self[x])\n        else:\n            if verbose:\n                print(colors.mark(False), x, self[x], want[x])\n            errors.append(x)\n    if throw:\n        for x in errors:\n            raise AssertionError(f\"{x}: {self[x]} {want[x]}\")\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.compare","title":"<code>compare(other, *, domain=None)</code>","text":"<p>Compare this Chart to another using pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart or dict to compare against</p> required <code>domain</code> <p>Optional set of keys to compare</p> <code>None</code> <p>Returns:</p> Type Description <p>pandas DataFrame showing key-by-key comparison</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def compare(self, other, *, domain=None):\n    \"\"\"Compare this Chart to another using pandas DataFrame.\n\n    Args:\n        other: Another Chart or dict to compare against\n        domain: Optional set of keys to compare\n\n    Returns:\n        pandas DataFrame showing key-by-key comparison\n    \"\"\"\n    import pandas as pd\n\n    if not isinstance(other, Chart):\n        other = self.semiring.chart(other)\n    if domain is None:\n        domain = self.keys() | other.keys()\n    rows = []\n    for x in domain:\n        m = self.semiring.metric(self[x], other[x])\n        rows.append(dict(key=x, self=self[x], other=other[x], metric=m))\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.copy","title":"<code>copy()</code>","text":"<p>Create a shallow copy of this Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def copy(self):\n    \"\"\"Create a shallow copy of this Chart.\"\"\"\n    return Chart(self.semiring, self)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.filter","title":"<code>filter(f)</code>","text":"<p>Return a new Chart keeping only entries where f(key) is True.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Predicate function that takes a key and returns bool</p> required <p>Returns:</p> Type Description <p>A new Chart containing only entries where f(key) is True</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def filter(self, f):\n    \"\"\"Return a new Chart keeping only entries where f(key) is True.\n\n    Args:\n        f: Predicate function that takes a key and returns bool\n\n    Returns:\n        A new Chart containing only entries where f(key) is True\n    \"\"\"\n    return self.semiring.chart((k, v) for k, v in self.items() if f(k))\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.max","title":"<code>max()</code>","text":"<p>Return the maximum value in the Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def max(self):\n    \"\"\"Return the maximum value in the Chart.\"\"\"\n    return max(self.values())\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.metric","title":"<code>metric(other)</code>","text":"<p>Compute the maximum distance between this Chart and another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart to compare against</p> required <p>Returns:</p> Type Description <p>The maximum semiring metric between corresponding values</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def metric(self, other):\n    \"\"\"Compute the maximum distance between this Chart and another.\n\n    Args:\n        other: Another Chart to compare against\n\n    Returns:\n        The maximum semiring metric between corresponding values\n    \"\"\"\n    assert isinstance(other, Chart)\n    err = 0\n    for x in self.keys() | other.keys():\n        err = max(err, self.semiring.metric(self[x], other[x]))\n    return err\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.min","title":"<code>min()</code>","text":"<p>Return the minimum value in the Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def min(self):\n    \"\"\"Return the minimum value in the Chart.\"\"\"\n    return min(self.values())\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.normalize","title":"<code>normalize()</code>","text":"<p>Return a new Chart with values normalized to sum to 1.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def normalize(self):\n    \"\"\"Return a new Chart with values normalized to sum to 1.\"\"\"\n    Z = self.sum()\n    if Z == 0:\n        return self\n    return self.semiring.chart((k, v / Z) for k, v in self.items())\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.product","title":"<code>product(ks)</code>","text":"<p>Compute the product of values for the given keys.</p> <p>Parameters:</p> Name Type Description Default <code>ks</code> <p>Sequence of keys to multiply values for</p> required <p>Returns:</p> Type Description <p>The product of values for the given keys</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def product(self, ks):\n    \"\"\"Compute the product of values for the given keys.\n\n    Args:\n        ks: Sequence of keys to multiply values for\n\n    Returns:\n        The product of values for the given keys\n    \"\"\"\n    v = self.semiring.one\n    for k in ks:\n        v *= self[k]\n    return v\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.project","title":"<code>project(f)</code>","text":"<p>Apply a function to keys, summing weights when transformed keys overlap.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Function to transform keys</p> required <p>Returns:</p> Type Description <p>A new Chart with transformed keys and summed weights</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def project(self, f):\n    \"\"\"Apply a function to keys, summing weights when transformed keys overlap.\n\n    Args:\n        f: Function to transform keys\n\n    Returns:\n        A new Chart with transformed keys and summed weights\n    \"\"\"\n    out = self.semiring.chart()\n    for k, v in self.items():\n        out[f(k)] += v\n    return out\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.sort","title":"<code>sort(**kwargs)</code>","text":"<p>Return a new Chart with entries sorted by key.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arguments passed to sorted()</p> <code>{}</code> <p>Returns:</p> Type Description <p>A new Chart with sorted entries</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def sort(self, **kwargs):\n    \"\"\"Return a new Chart with entries sorted by key.\n\n    Args:\n        **kwargs: Arguments passed to sorted()\n\n    Returns:\n        A new Chart with sorted entries\n    \"\"\"\n    return self.semiring.chart((k, self[k]) for k in sorted(self, **kwargs))\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.sort_descending","title":"<code>sort_descending()</code>","text":"<p>Return a new Chart with entries sorted by decreasing value.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def sort_descending(self):\n    \"\"\"Return a new Chart with entries sorted by decreasing value.\"\"\"\n    return self.semiring.chart(\n        (k, self[k]) for k in sorted(self, key=lambda k: -self[k])\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.spawn","title":"<code>spawn()</code>","text":"<p>Create a new empty Chart with the same semiring.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def spawn(self):\n    \"\"\"Create a new empty Chart with the same semiring.\"\"\"\n    return Chart(self.semiring)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.sum","title":"<code>sum()</code>","text":"<p>Return the sum of all values in the Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def sum(self):\n    \"\"\"Return the sum of all values in the Chart.\"\"\"\n    return sum(self.values())\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.top","title":"<code>top(k)</code>","text":"<p>Return a new Chart with the k largest values.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <p>Number of top values to keep</p> required <p>Returns:</p> Type Description <p>A new Chart containing only the k largest values</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def top(self, k):\n    \"\"\"Return a new Chart with the k largest values.\n\n    Args:\n        k: Number of top values to keep\n\n    Returns:\n        A new Chart containing only the k largest values\n    \"\"\"\n    return Chart(\n        self.semiring,\n        {k: self[k] for k in sorted(self, key=self.__getitem__, reverse=True)[:k]},\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Chart.trim","title":"<code>trim()</code>","text":"<p>Return a new Chart with zero-weight entries removed.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def trim(self):\n    \"\"\"Return a new Chart with zero-weight entries removed.\"\"\"\n    return Chart(\n        self.semiring, {k: v for k, v in self.items() if v != self.semiring.zero}\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.Earley","title":"<code>Earley</code>","text":"<p>Implements a semiring-weighted version Earley's algorithm that runs in $\\mathcal{O}(N^3|G|)$ time. Note that nullary rules and unary chain cycles will be been removed, altering the set of derivation trees.</p> Source code in <code>genlm/grammar/parse/earley.py</code> <pre><code>class Earley:\n    \"\"\"\n    Implements a semiring-weighted version Earley's algorithm that runs in $\\mathcal{O}(N^3|G|)$ time.\n    Note that nullary rules and unary chain cycles will be been removed, altering the\n    set of derivation trees.\n    \"\"\"\n\n    __slots__ = (\n        \"cfg\",\n        \"order\",\n        \"_chart\",\n        \"V\",\n        \"eos\",\n        \"_initial_column\",\n        \"R_outgoing\",\n        \"rhs\",\n        \"ORDER_MAX\",\n        \"intern_Ys\",\n        \"unit_Ys\",\n        \"first_Ys\",\n        \"rest_Ys\",\n    )\n\n    def __init__(self, cfg):\n        cfg = cfg.nullaryremove(binarize=True).unarycycleremove().renumber()\n        self.cfg = cfg\n\n        # cache of chart columns\n        self._chart = {}\n\n        # Topological ordering on the grammar symbols so that we process unary\n        # rules in a topological order.\n        self.order = cfg._unary_graph_transpose().buckets\n\n        self.ORDER_MAX = 1 + max(self.order.values())\n\n        # left-corner graph\n        R_outgoing = defaultdict(set)\n        for r in cfg:\n            if len(r.body) == 0:\n                continue\n            A = r.head\n            B = r.body[0]\n            if cfg.is_terminal(B):\n                continue\n            R_outgoing[A].add(B)\n        self.R_outgoing = R_outgoing\n\n        # Integerize rule right-hand side states\n        intern_Ys = Integerizer()\n        assert intern_Ys(()) == 0\n\n        for r in self.cfg:\n            for p in range(len(r.body) + 1):\n                intern_Ys.add(r.body[p:])\n\n        self.intern_Ys = intern_Ys\n\n        self.rhs = {}\n        for X in self.cfg.N:\n            self.rhs[X] = []\n            for r in self.cfg.rhs[X]:\n                if r.body == ():\n                    continue\n                self.rhs[X].append((r.w, intern_Ys(r.body)))\n\n        self.first_Ys = np.zeros(len(intern_Ys), dtype=object)\n        self.rest_Ys = np.zeros(len(intern_Ys), dtype=int)\n        self.unit_Ys = np.zeros(len(intern_Ys), dtype=int)\n\n        for Ys, code in list(self.intern_Ys.items()):\n            self.unit_Ys[code] = len(Ys) == 1\n            if len(Ys) &gt; 0:\n                self.first_Ys[code] = Ys[0]\n                self.rest_Ys[code] = intern_Ys(Ys[1:])\n\n        # self.generate_rust_test_case()\n\n        col = Column(0)\n        self.PREDICT(col)\n        self._initial_column = col\n\n    def clear_cache(self):\n        self._chart.clear()\n\n    def __call__(self, x):\n        N = len(x)\n\n        # return if empty string\n        if N == 0:\n            return sum(r.w for r in self.cfg.rhs[self.cfg.S] if r.body == ())\n\n        # initialize bookkeeping structures\n        self._chart[()] = [self._initial_column]\n\n        cols = self.chart(x)\n\n        value = cols[N].c_chart.get((0, self.cfg.S))\n        return value if value is not None else self.cfg.R.zero\n\n    def chart(self, x):\n        x = tuple(x)\n        c = self._chart.get(x)\n        if c is None:\n            self._chart[x] = c = self._compute_chart(x)\n        return c\n\n    def _compute_chart(self, x):\n        if len(x) == 0:\n            return [self._initial_column]\n        else:\n            chart = self.chart(x[:-1])\n            last_chart = self.next_column(chart, x[-1])\n            return chart + [\n                last_chart\n            ]  # TODO: avoid list addition here as it is not constant time!\n\n    def next_column(self, prev_cols, token):\n        prev_col = prev_cols[-1]\n        next_col = Column(prev_cols[-1].k + 1)\n        next_col_c_chart = next_col.c_chart\n        prev_col_i_chart = prev_col.i_chart\n\n        rest_Ys = self.rest_Ys\n        _update = self._update\n\n        Q = LocatorMaxHeap()\n\n        # SCAN: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * word(J, Y, K)\n        for item in prev_col.waiting_for[token]:\n            (I, X, Ys) = item\n            _update(next_col, Q, I, X, rest_Ys[Ys], prev_col_i_chart[item])\n\n        # ATTACH: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * phrase(J, Y/[], K)\n        while Q:\n            jy = Q.pop()[0]\n            (J, Y) = jy\n\n            col_J = prev_cols[J]\n            col_J_i_chart = col_J.i_chart\n            y = next_col_c_chart[jy]\n            for customer in col_J.waiting_for[Y]:\n                (I, X, Ys) = customer\n                _update(next_col, Q, I, X, rest_Ys[Ys], col_J_i_chart[customer] * y)\n\n        self.PREDICT(next_col)\n\n        return next_col\n\n    def PREDICT(self, col):\n        # PREDICT: phrase(K, X/Ys, K) += rule(X -&gt; Ys) with some filtering heuristics\n        k = col.k\n\n        # Filtering heuristic: Don't create the predicted item (K, X, [...], K)\n        # unless there exists an item that wants the X item that it may\n        # eventually provide.  In other words, for predicting this item to be\n        # useful there must be an item of the form (I, X', [X, ...], K) in this\n        # column for which lc(X', X) is true.\n        if col.k == 0:\n            agenda = [self.cfg.S]\n        else:\n            agenda = list(col.waiting_for)\n\n        outgoing = self.R_outgoing\n\n        reachable = set(agenda)\n\n        while agenda:\n            X = agenda.pop()\n            for Y in outgoing[X]:\n                if Y not in reachable:\n                    reachable.add(Y)\n                    agenda.append(Y)\n\n        rhs = self.rhs\n        _update = self._update\n        for X in reachable:\n            for w, Ys in rhs.get(X, ()):\n                _update(col, None, k, X, Ys, w)\n\n    def _update(self, col, Q, I, X, Ys, value):\n        K = col.k\n        if Ys == 0:\n            # Items of the form phrase(I, X/[], K)\n            item = (I, X)\n            was = col.c_chart.get(item)\n            if was is None:\n                Q[item] = -((K - I) * self.ORDER_MAX + self.order[X])\n                col.c_chart[item] = value\n            else:\n                col.c_chart[item] = was + value\n\n        else:\n            # Items of the form phrase(I, X/[Y|Ys], K)\n            item = (I, X, Ys)\n            was = col.i_chart.get(item)\n            if was is None:\n                col.waiting_for[self.first_Ys[Ys]].append(item)\n                col.i_chart[item] = value\n            else:\n                col.i_chart[item] = was + value\n\n    # We have derived the `next_token_weights` algorithm by backpropagation on\n    # the program with respect to the item `phrase(0, s, K)`.\n    #\n    # ATTACH: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * phrase(J, Y/[], K)\n    #\n    # Directly applying the gradient transformation, we get\n    #\n    # \u2207phrase(0, s/[], K) += 1\n    # \u2207phrase(J, Y/[], K) += phrase(I, X/[Y|Ys], J) * \u2207phrase(I, X/Ys, K)\n    #\n    # Some quick analysis reveals that the `Ys` list must always be [], and\n    # that K is always equal to the final column.  We specialize the program\n    # below:\n    #\n    # \u2207phrase(0, s/[], K) += 1\n    # \u2207phrase(J, Y/[], K) += phrase(I, X/[Y], J) * \u2207phrase(I, X/[], K)\n    #\n    # We can abbreviate the names:\n    #\n    # q(0, s) += 1\n    # q(J, Y) += phrase(I, X/[Y], J) * q(I, X)\n    #\n    # These items satisfy (I &gt; J) and (X &gt; Y) where the latter is the\n    # nonterminal ordering.  Thus, we can efficiently evaluate these equations\n    # by backward chaining.\n    #\n    # The final output is the vector\n    #\n    # p(W) += q(I, X) * phrase(I, X/[W], J)  where len(J) * terminal(W).\n    #\n    def next_token_weights(self, cols):\n        is_terminal = self.cfg.is_terminal\n        zero = self.cfg.R.zero\n\n        q = {}\n        q[0, self.cfg.S] = self.cfg.R.one\n\n        col = cols[-1]\n        col_waiting_for = col.waiting_for\n        col_i_chart = col.i_chart\n\n        # SCAN: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * word(J, Y, K)\n        p = self.cfg.R.chart()\n\n        for Y in col_waiting_for:\n            if is_terminal(Y):\n                total = zero\n                for I, X, Ys in col_waiting_for[Y]:\n                    if self.unit_Ys[Ys]:\n                        node = (I, X)\n                        value = self._helper(node, cols, q)\n                        total += col_i_chart[I, X, Ys] * value\n                p[Y] = total\n\n        return p\n\n    def _helper(self, top, cols, q):\n        value = q.get(top)\n        if value is not None:\n            return value\n\n        zero = self.cfg.R.zero\n        stack = [Node(top, None, zero)]\n\n        while stack:\n            node = stack[-1]  # \ud83d\udc40\n\n            # place neighbors above the node on the stack\n            (J, Y) = node.node\n\n            t = node.cursor\n\n            if node.edges is None:\n                node.edges = [x for x in cols[J].waiting_for[Y] if self.unit_Ys[x[2]]]\n\n            # cursor is at the end, all neighbors are done\n            elif t == len(node.edges):\n                # clear the node from the stack\n                stack.pop()\n                # promote the incomplete value node.value to a complete value (q)\n                q[node.node] = node.value\n\n            else:\n                (I, X, _) = arc = node.edges[t]\n                neighbor = (I, X)\n                neighbor_value = q.get(neighbor)\n                if neighbor_value is None:\n                    stack.append(Node(neighbor, None, zero))\n                else:\n                    # neighbor value is ready, advance the cursor, add the\n                    # neighbors contribution to the nodes value\n                    node.cursor += 1\n                    node.value += cols[J].i_chart[arc] * neighbor_value\n\n        return q[top]\n\n    def generate_rust_test_case(self):\n        # generates a test case in Rust code by exporting the parser state variables\n        # Copy-paste the printout to `mod tests { ... }` in lib.rs to debug.\n\n        print(\n            \"\"\"\n    #[test]\n    fn test_earley() {{\n\n        let rhs: HashMap&lt;u32, Vec&lt;RHS&gt;&gt; = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\n                \", \".join(\n                    f\"({x}, \"\n                    + \"vec![{}])\".format(\", \".join(f\"({float(u)}, {v})\" for u, v in y))\n                    for x, y in self.rhs.items()\n                )\n            )\n        )\n\n        print(\n            \"\"\"\n        let order: HashMap&lt;u32, u32&gt; = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\", \".join(f\"({u}, {v})\" for u, v in self.order.items()))\n        )\n\n        print(\n            \"\"\"\n        let outgoing: HashMap&lt;u32, Vec&lt;u32&gt;&gt; = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\n                \", \".join(\n                    \"({}, vec![{}])\".format(i, \", \".join(map(str, s)))\n                    for i, s in self.R_outgoing.items()\n                )\n            )\n        )\n\n        print(\n            \"\"\"\n        let first_ys = vec![\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\n                \", \".join(\n                    f'Terminal(String::from(\"{y}\"))'\n                    if isinstance(y, str)\n                    else f\"Nonterminal({y})\"\n                    for y in self.first_Ys\n                )\n            )\n        )\n\n        print(\n            \"\"\"\n        let rest_ys = vec![\n            {}\n        ];\n        \"\"\".format(\", \".join(map(str, self.rest_Ys)))\n        )\n\n        print(\n            \"\"\"\n        let unit_ys = vec![\n            {}\n        ];\n        \"\"\".format(\", \".join(map(lambda x: str(bool(x)).lower(), self.unit_Ys)))\n        )\n\n        print(\n            \"\"\"\n        let vocab = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\", \".join(f'String::from(\"{v}\")' for v in self.cfg.V))\n        )\n\n        print(\n            \"\"\"\n        let empty_weight = {};\n        let start = {};\n        let order_max = {};\n        \"\"\".format(\n                sum(r.w for r in self.cfg.rhs[self.cfg.S] if r.body == ()),\n                self.cfg.S,\n                self.ORDER_MAX,\n            )\n        )\n\n        print(\"\"\"\n        let mut earley = Earley::new(\n            rhs, start, order, order_max, outgoing, first_ys,\n            rest_ys, unit_ys, vocab, empty_weight,\n        );\n        let chart = earley.p_next(vec![]);\n        dbg!(&amp;chart);\n\n    }}\n        \"\"\")\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST","title":"<code>FST</code>","text":"<p>               Bases: <code>WFSA</code></p> <p>A weighted finite-state transducer that maps between two alphabets.</p> <p>A finite-state transducer (FST) extends a weighted finite-state automaton (WFSA) by having two alphabets - an input alphabet A and an output alphabet B. Each transition is labeled with a pair (a,b) where a is from A and b is from B.</p> <p>The FST defines a weighted relation between strings over A and strings over B.</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>class FST(WFSA):\n    \"\"\"A weighted finite-state transducer that maps between two alphabets.\n\n    A finite-state transducer (FST) extends a weighted finite-state automaton (WFSA)\n    by having two alphabets - an input alphabet A and an output alphabet B. Each transition\n    is labeled with a pair (a,b) where a is from A and b is from B.\n\n    The FST defines a weighted relation between strings over A and strings over B.\n    \"\"\"\n\n    def __init__(self, R):\n        \"\"\"Initialize an empty FST.\n\n        Args:\n            R: The semiring for transition weights\n        \"\"\"\n        super().__init__(R=R)\n\n        # alphabets\n        self.A = set()  # input alphabet\n        self.B = set()  # output alphabet\n\n    def add_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n        \"\"\"Add a weighted transition between states.\n\n        Args:\n            i: Source state\n            ab: Tuple (a,b) of input/output symbols, or EPSILON\n            j: Target state\n            w: Weight of the transition\n\n        Returns:\n            self\n        \"\"\"\n        if ab != EPSILON:\n            (a, b) = ab\n            self.A.add(a)\n            self.B.add(b)\n        return super().add_arc(i, ab, j, w)\n\n    def set_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n        \"\"\"Set the weight of a transition between states.\n\n        Args:\n            i: Source state\n            ab: Tuple (a,b) of input/output symbols, or EPSILON\n            j: Target state\n            w: New weight for the transition\n\n        Returns:\n            self\n        \"\"\"\n        if ab != EPSILON:\n            (a, b) = ab\n            self.A.add(a)\n            self.B.add(b)\n        return super().set_arc(i, ab, j, w)\n\n    def __call__(self, x, y):\n        \"\"\"Compute the weight of mapping input x to output y.\n\n        If x or y is None, returns a weighted language representing the cross section.\n\n        Args:\n            x: Input string or None\n            y: Output string or None\n\n        Returns:\n            Weight of mapping x to y, or a WFSA representing the cross section if x or y is None\n        \"\"\"\n        if x is not None and y is not None:\n            x = FST.from_string(x, self.R)\n            y = FST.from_string(y, self.R)\n            return (x @ self @ y).total_weight()\n\n        elif x is not None and y is None:\n            x = FST.from_string(x, self.R)\n            return (x @ self).project(1)\n\n        elif x is None and y is not None:\n            y = FST.from_string(y, self.R)\n            return (self @ y).project(0)\n\n        else:\n            return self\n\n    @classmethod\n    def from_string(cls, xs, R, w=None):\n        \"\"\"Create an FST that accepts only the given string with optional weight.\n\n        Args:\n            xs: Input string\n            R: Semiring for weights\n            w: Optional weight for the string\n\n        Returns:\n            An FST accepting only xs with weight w\n        \"\"\"\n        return cls.diag(WFSA.from_string(xs=xs, R=R, w=w))\n\n    @staticmethod\n    def from_pairs(pairs, R):\n        \"\"\"Create an FST accepting the given input-output string pairs.\n\n        Args:\n            pairs: List of (input_string, output_string) tuples\n            R: Semiring for weights\n\n        Returns:\n            An FST accepting the given string pairs with weight one\n        \"\"\"\n        p = FST(R)\n        p.add_I(0, R.one)\n        p.add_F(1, R.one)\n        for i, (xs, ys) in enumerate(pairs):\n            p.add_arc(0, EPSILON, (i, 0), R.one)\n            for j, (x, y) in enumerate(zip_longest(xs, ys, fillvalue=EPSILON)):\n                p.add_arc((i, j), (x, y), (i, j + 1), R.one)\n            p.add_arc((i, max(len(xs), len(ys))), EPSILON, 1, R.one)\n        return p\n\n    def project(self, axis):\n        \"\"\"Project the FST onto one of its components to create a WFSA.\n\n        Args:\n            axis: 0 for input projection, 1 for output projection\n\n        Returns:\n            A WFSA over the projected alphabet\n        \"\"\"\n        assert axis in [0, 1]\n        A = WFSA(R=self.R)\n        for i, (a, b), j, w in self.arcs():\n            if axis == 0:\n                A.add_arc(i, a, j, w)\n            else:\n                A.add_arc(i, b, j, w)\n        for i, w in self.I:\n            A.add_I(i, w)\n        for i, w in self.F:\n            A.add_F(i, w)\n        return A\n\n    @cached_property\n    def T(self):\n        \"\"\"Return the transpose of this FST by swapping input/output labels.\n\n        Returns:\n            A new FST with input/output labels swapped\n        \"\"\"\n        T = self.spawn()\n        for i, (a, b), j, w in self.arcs():\n            T.add_arc(i, (b, a), j, w)  # (a,b) -&gt; (b,a)\n        for q, w in self.I:\n            T.add_I(q, w)\n        for q, w in self.F:\n            T.add_F(q, w)\n        return T\n\n    def prune_to_alphabet(self, A, B):\n        \"\"\"Remove transitions with labels not in the given alphabets.\n\n        Args:\n            A: Set of allowed input symbols, or None to allow all\n            B: Set of allowed output symbols, or None to allow all\n\n        Returns:\n            A new FST with invalid transitions removed\n        \"\"\"\n        T = self.spawn()\n        for i, (a, b), j, w in self.arcs():\n            if (A is None or a in A) and (B is None or b in B):\n                T.add_arc(i, (a, b), j, w)\n        for q, w in self.I:\n            T.add_I(q, w)\n        for q, w in self.F:\n            T.add_F(q, w)\n        return T.trim\n\n    def __matmul__(self, other):\n        \"\"\"Compose this FST with another FST or automaton.\n\n        Args:\n            other: Another FST, CFG or automaton to compose with\n\n        Returns:\n            The composed FST\n        \"\"\"\n        if not isinstance(other, FST):\n            from genlm.grammar.cfg import CFG\n\n            if isinstance(other, CFG):\n                return other @ self.T\n            else:\n                other = FST.diag(other)\n\n        # minor efficiency trick: it's slightly more efficient to associate the composition as follows\n        if len(self.states) &lt; len(other.states):\n            return (\n                self._augment_epsilon_transitions(0)  # rename epsilons on the right\n                ._compose(\n                    epsilon_filter_fst(self.R, self.B), coarsen=False\n                )  # this FST carefully combines the special epsilons\n                ._compose(\n                    other._augment_epsilon_transitions(1)\n                )  # rename epsilons on th left\n            )\n\n        else:\n            return self._augment_epsilon_transitions(\n                0\n            )._compose(  # rename epsilons on the right\n                epsilon_filter_fst(\n                    self.R, self.B\n                )._compose(  # this FST carefully combines the special epsilons\n                    other._augment_epsilon_transitions(1), coarsen=False\n                )\n            )  # rename epsilons on th left\n\n    def _compose(self, other, coarsen=True):\n        \"\"\"Internal composition implementation with optional coarsening.\n\n        Args:\n            other: FST to compose with\n            coarsen: Whether to apply pruning/coarsening\n\n        Returns:\n            The composed FST\n        \"\"\"\n        if coarsen and FST.PRUNING is not None:\n            keep = FST.PRUNING(self, other)  # pylint: disable=E1102\n            result = self._pruned_compose(other, keep, keep.keep_arc)\n\n        else:\n            result = self._pruned_compose(\n                other, lambda x: True, lambda i, label, j: True\n            )\n\n        return result\n\n    # TODO: add assertions for the 'bad' epsilon cases to ensure users aren't using this method incorrectly.\n    def _pruned_compose(self, other, keep, keep_arc):\n        \"\"\"Implements pruned on-the-fly composition of FSTs.\n\n        Args:\n            other: FST to compose with\n            keep: Function that determines which states to keep\n            keep_arc: Function that determines which arcs to keep\n\n        Returns:\n            The composed FST with pruning applied\n        \"\"\"\n        C = FST(R=self.R)\n\n        # index arcs in `other` to so that they are fast against later\n        tmp = defaultdict(list)\n        for i, (a, b), j, w in other.arcs():\n            tmp[i, a].append((b, j, w))\n\n        visited = set()\n        stack = []\n\n        # add initial states\n        for P, w1 in self.I:\n            for Q, w2 in other.I:\n                PQ = (P, Q)\n\n                if not keep(PQ):\n                    continue\n\n                C.add_I(PQ, w1 * w2)\n                visited.add(PQ)\n                stack.append(PQ)\n\n        # traverse the machine using depth-first search\n        while stack:\n            P, Q = PQ = stack.pop()\n\n            # (q,p) is simultaneously a final state in the respective machines\n            if P in self.stop and Q in other.stop:\n                C.add_F(PQ, self.stop[P] * other.stop[Q])\n                # Note: final states are not necessarily absorbing -&gt; fall thru\n\n            # Arcs of the composition machine are given by a cross-product-like\n            # construction that matches an arc labeled `a:b` with an arc labeled\n            # `b:c` in the left and right machines respectively.\n            for (a, b), P\u02bc, w1 in self.arcs(P):\n                for c, Q\u02bc, w2 in tmp[Q, b]:\n                    assert b != EPSILON\n\n                    P\u02bcQ\u02bc = (P\u02bc, Q\u02bc)\n\n                    if not keep(P\u02bcQ\u02bc) or not keep_arc(PQ, (a, c), P\u02bcQ\u02bc):\n                        continue\n\n                    C.add_arc(PQ, (a, c), P\u02bcQ\u02bc, w1 * w2)\n\n                    if P\u02bcQ\u02bc not in visited:\n                        stack.append(P\u02bcQ\u02bc)\n                        visited.add(P\u02bcQ\u02bc)\n\n        return C\n\n    def _augment_epsilon_transitions(self, idx):\n        \"\"\"Augments the FST by changing the appropriate epsilon transitions to\n        epsilon_1 or epsilon_2 transitions to be able to perform the composition\n        correctly.  See Fig. 7 on p. 17 of Mohri, \"Weighted Automata Algorithms\".\n\n        Args:\n            idx: 0 if this is the first FST in composition, 1 if second\n\n        Returns:\n            FST with augmented epsilon transitions\n        \"\"\"\n        assert idx in [0, 1]\n\n        T = self.spawn(keep_init=True, keep_stop=True)\n\n        for i in self.states:\n            if idx == 0:\n                T.add_arc(i, (\u03b5, \u03b5_1), i, self.R.one)\n            else:\n                T.add_arc(i, (\u03b5_2, \u03b5), i, self.R.one)\n            for ab, j, w in self.arcs(i):\n                if idx == 0 and ab[1] == \u03b5:\n                    ab = (ab[0], \u03b5_2)\n                elif idx == 1 and ab[0] == \u03b5:\n                    ab = (\u03b5_1, ab[1])\n                T.add_arc(i, ab, j, w)\n\n        return T\n\n    @classmethod\n    def diag(cls, fsa):\n        \"\"\"Convert FSA to diagonal FST that maps strings to themselves.\n\n        Args:\n            fsa: Input FSA to convert\n\n        Returns:\n            FST that maps each string accepted by fsa to itself with same weight\n        \"\"\"\n        fst = cls(fsa.R)\n        for i, a, j, w in fsa.arcs():\n            fst.add_arc(i, (a, a), j, w)\n        for i, w in fsa.I:\n            fst.add_I(i, w)\n        for i, w in fsa.F:\n            fst.add_F(i, w)\n        return fst\n\n    def coarsen(self, N, A, B):\n        \"\"\"Create coarsened Boolean FST by mapping states and symbols.\n\n        Args:\n            N: Function mapping states to coarsened states\n            A: Function mapping input symbols to coarsened input symbols\n            B: Function mapping output symbols to coarsened output symbols\n\n        Returns:\n            Coarsened Boolean FST\n        \"\"\"\n        m = FST(Boolean)\n        for i in self.start:\n            m.add_I(N(i), Boolean.one)\n        for i in self.stop:\n            m.add_F(N(i), Boolean.one)\n        for i, (a, b), j, _ in self.arcs():\n            m.add_arc(N(i), (A(a), B(b)), N(j), Boolean.one)\n        return m\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.T","title":"<code>T</code>  <code>cached</code> <code>property</code>","text":"<p>Return the transpose of this FST by swapping input/output labels.</p> <p>Returns:</p> Type Description <p>A new FST with input/output labels swapped</p>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.__call__","title":"<code>__call__(x, y)</code>","text":"<p>Compute the weight of mapping input x to output y.</p> <p>If x or y is None, returns a weighted language representing the cross section.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Input string or None</p> required <code>y</code> <p>Output string or None</p> required <p>Returns:</p> Type Description <p>Weight of mapping x to y, or a WFSA representing the cross section if x or y is None</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def __call__(self, x, y):\n    \"\"\"Compute the weight of mapping input x to output y.\n\n    If x or y is None, returns a weighted language representing the cross section.\n\n    Args:\n        x: Input string or None\n        y: Output string or None\n\n    Returns:\n        Weight of mapping x to y, or a WFSA representing the cross section if x or y is None\n    \"\"\"\n    if x is not None and y is not None:\n        x = FST.from_string(x, self.R)\n        y = FST.from_string(y, self.R)\n        return (x @ self @ y).total_weight()\n\n    elif x is not None and y is None:\n        x = FST.from_string(x, self.R)\n        return (x @ self).project(1)\n\n    elif x is None and y is not None:\n        y = FST.from_string(y, self.R)\n        return (self @ y).project(0)\n\n    else:\n        return self\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.__init__","title":"<code>__init__(R)</code>","text":"<p>Initialize an empty FST.</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <p>The semiring for transition weights</p> required Source code in <code>genlm/grammar/fst.py</code> <pre><code>def __init__(self, R):\n    \"\"\"Initialize an empty FST.\n\n    Args:\n        R: The semiring for transition weights\n    \"\"\"\n    super().__init__(R=R)\n\n    # alphabets\n    self.A = set()  # input alphabet\n    self.B = set()  # output alphabet\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Compose this FST with another FST or automaton.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another FST, CFG or automaton to compose with</p> required <p>Returns:</p> Type Description <p>The composed FST</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def __matmul__(self, other):\n    \"\"\"Compose this FST with another FST or automaton.\n\n    Args:\n        other: Another FST, CFG or automaton to compose with\n\n    Returns:\n        The composed FST\n    \"\"\"\n    if not isinstance(other, FST):\n        from genlm.grammar.cfg import CFG\n\n        if isinstance(other, CFG):\n            return other @ self.T\n        else:\n            other = FST.diag(other)\n\n    # minor efficiency trick: it's slightly more efficient to associate the composition as follows\n    if len(self.states) &lt; len(other.states):\n        return (\n            self._augment_epsilon_transitions(0)  # rename epsilons on the right\n            ._compose(\n                epsilon_filter_fst(self.R, self.B), coarsen=False\n            )  # this FST carefully combines the special epsilons\n            ._compose(\n                other._augment_epsilon_transitions(1)\n            )  # rename epsilons on th left\n        )\n\n    else:\n        return self._augment_epsilon_transitions(\n            0\n        )._compose(  # rename epsilons on the right\n            epsilon_filter_fst(\n                self.R, self.B\n            )._compose(  # this FST carefully combines the special epsilons\n                other._augment_epsilon_transitions(1), coarsen=False\n            )\n        )  # rename epsilons on th left\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.add_arc","title":"<code>add_arc(i, ab, j, w)</code>","text":"<p>Add a weighted transition between states.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <p>Source state</p> required <code>ab</code> <p>Tuple (a,b) of input/output symbols, or EPSILON</p> required <code>j</code> <p>Target state</p> required <code>w</code> <p>Weight of the transition</p> required <p>Returns:</p> Type Description <p>self</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def add_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n    \"\"\"Add a weighted transition between states.\n\n    Args:\n        i: Source state\n        ab: Tuple (a,b) of input/output symbols, or EPSILON\n        j: Target state\n        w: Weight of the transition\n\n    Returns:\n        self\n    \"\"\"\n    if ab != EPSILON:\n        (a, b) = ab\n        self.A.add(a)\n        self.B.add(b)\n    return super().add_arc(i, ab, j, w)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.coarsen","title":"<code>coarsen(N, A, B)</code>","text":"<p>Create coarsened Boolean FST by mapping states and symbols.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <p>Function mapping states to coarsened states</p> required <code>A</code> <p>Function mapping input symbols to coarsened input symbols</p> required <code>B</code> <p>Function mapping output symbols to coarsened output symbols</p> required <p>Returns:</p> Type Description <p>Coarsened Boolean FST</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def coarsen(self, N, A, B):\n    \"\"\"Create coarsened Boolean FST by mapping states and symbols.\n\n    Args:\n        N: Function mapping states to coarsened states\n        A: Function mapping input symbols to coarsened input symbols\n        B: Function mapping output symbols to coarsened output symbols\n\n    Returns:\n        Coarsened Boolean FST\n    \"\"\"\n    m = FST(Boolean)\n    for i in self.start:\n        m.add_I(N(i), Boolean.one)\n    for i in self.stop:\n        m.add_F(N(i), Boolean.one)\n    for i, (a, b), j, _ in self.arcs():\n        m.add_arc(N(i), (A(a), B(b)), N(j), Boolean.one)\n    return m\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.diag","title":"<code>diag(fsa)</code>  <code>classmethod</code>","text":"<p>Convert FSA to diagonal FST that maps strings to themselves.</p> <p>Parameters:</p> Name Type Description Default <code>fsa</code> <p>Input FSA to convert</p> required <p>Returns:</p> Type Description <p>FST that maps each string accepted by fsa to itself with same weight</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>@classmethod\ndef diag(cls, fsa):\n    \"\"\"Convert FSA to diagonal FST that maps strings to themselves.\n\n    Args:\n        fsa: Input FSA to convert\n\n    Returns:\n        FST that maps each string accepted by fsa to itself with same weight\n    \"\"\"\n    fst = cls(fsa.R)\n    for i, a, j, w in fsa.arcs():\n        fst.add_arc(i, (a, a), j, w)\n    for i, w in fsa.I:\n        fst.add_I(i, w)\n    for i, w in fsa.F:\n        fst.add_F(i, w)\n    return fst\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.from_pairs","title":"<code>from_pairs(pairs, R)</code>  <code>staticmethod</code>","text":"<p>Create an FST accepting the given input-output string pairs.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <p>List of (input_string, output_string) tuples</p> required <code>R</code> <p>Semiring for weights</p> required <p>Returns:</p> Type Description <p>An FST accepting the given string pairs with weight one</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>@staticmethod\ndef from_pairs(pairs, R):\n    \"\"\"Create an FST accepting the given input-output string pairs.\n\n    Args:\n        pairs: List of (input_string, output_string) tuples\n        R: Semiring for weights\n\n    Returns:\n        An FST accepting the given string pairs with weight one\n    \"\"\"\n    p = FST(R)\n    p.add_I(0, R.one)\n    p.add_F(1, R.one)\n    for i, (xs, ys) in enumerate(pairs):\n        p.add_arc(0, EPSILON, (i, 0), R.one)\n        for j, (x, y) in enumerate(zip_longest(xs, ys, fillvalue=EPSILON)):\n            p.add_arc((i, j), (x, y), (i, j + 1), R.one)\n        p.add_arc((i, max(len(xs), len(ys))), EPSILON, 1, R.one)\n    return p\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.from_string","title":"<code>from_string(xs, R, w=None)</code>  <code>classmethod</code>","text":"<p>Create an FST that accepts only the given string with optional weight.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <p>Input string</p> required <code>R</code> <p>Semiring for weights</p> required <code>w</code> <p>Optional weight for the string</p> <code>None</code> <p>Returns:</p> Type Description <p>An FST accepting only xs with weight w</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>@classmethod\ndef from_string(cls, xs, R, w=None):\n    \"\"\"Create an FST that accepts only the given string with optional weight.\n\n    Args:\n        xs: Input string\n        R: Semiring for weights\n        w: Optional weight for the string\n\n    Returns:\n        An FST accepting only xs with weight w\n    \"\"\"\n    return cls.diag(WFSA.from_string(xs=xs, R=R, w=w))\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.project","title":"<code>project(axis)</code>","text":"<p>Project the FST onto one of its components to create a WFSA.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>0 for input projection, 1 for output projection</p> required <p>Returns:</p> Type Description <p>A WFSA over the projected alphabet</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def project(self, axis):\n    \"\"\"Project the FST onto one of its components to create a WFSA.\n\n    Args:\n        axis: 0 for input projection, 1 for output projection\n\n    Returns:\n        A WFSA over the projected alphabet\n    \"\"\"\n    assert axis in [0, 1]\n    A = WFSA(R=self.R)\n    for i, (a, b), j, w in self.arcs():\n        if axis == 0:\n            A.add_arc(i, a, j, w)\n        else:\n            A.add_arc(i, b, j, w)\n    for i, w in self.I:\n        A.add_I(i, w)\n    for i, w in self.F:\n        A.add_F(i, w)\n    return A\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.prune_to_alphabet","title":"<code>prune_to_alphabet(A, B)</code>","text":"<p>Remove transitions with labels not in the given alphabets.</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <p>Set of allowed input symbols, or None to allow all</p> required <code>B</code> <p>Set of allowed output symbols, or None to allow all</p> required <p>Returns:</p> Type Description <p>A new FST with invalid transitions removed</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def prune_to_alphabet(self, A, B):\n    \"\"\"Remove transitions with labels not in the given alphabets.\n\n    Args:\n        A: Set of allowed input symbols, or None to allow all\n        B: Set of allowed output symbols, or None to allow all\n\n    Returns:\n        A new FST with invalid transitions removed\n    \"\"\"\n    T = self.spawn()\n    for i, (a, b), j, w in self.arcs():\n        if (A is None or a in A) and (B is None or b in B):\n            T.add_arc(i, (a, b), j, w)\n    for q, w in self.I:\n        T.add_I(q, w)\n    for q, w in self.F:\n        T.add_F(q, w)\n    return T.trim\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.FST.set_arc","title":"<code>set_arc(i, ab, j, w)</code>","text":"<p>Set the weight of a transition between states.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <p>Source state</p> required <code>ab</code> <p>Tuple (a,b) of input/output symbols, or EPSILON</p> required <code>j</code> <p>Target state</p> required <code>w</code> <p>New weight for the transition</p> required <p>Returns:</p> Type Description <p>self</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def set_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n    \"\"\"Set the weight of a transition between states.\n\n    Args:\n        i: Source state\n        ab: Tuple (a,b) of input/output symbols, or EPSILON\n        j: Target state\n        w: New weight for the transition\n\n    Returns:\n        self\n    \"\"\"\n    if ab != EPSILON:\n        (a, b) = ab\n        self.A.add(a)\n        self.B.add(b)\n    return super().set_arc(i, ab, j, w)\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.WFSA","title":"<code>WFSA</code>","text":"<p>               Bases: <code>WFSA</code></p> <p>Weighted finite-state automata where weights are a field (e.g., real-valued).</p> Source code in <code>genlm/grammar/wfsa/field_wfsa.py</code> <pre><code>class WFSA(base.WFSA):\n    \"\"\"\n    Weighted finite-state automata where weights are a field (e.g., real-valued).\n    \"\"\"\n\n    def __init__(self, R=Float):\n        super().__init__(R=R)\n\n    def __hash__(self):\n        return hash(self.simple)\n\n    def threshold(self, threshold):\n        \"Drop init, arcs, final below a given abs-threshold.\"\n        m = self.__class__(self.R)\n        for q, w in self.I:\n            if abs(w) &gt;= threshold:\n                m.add_I(q, w)\n        for i, a, j, w in self.arcs():\n            if abs(w) &gt;= threshold:\n                m.add_arc(i, a, j, w)\n        for q, w in self.F:\n            if abs(w) &gt;= threshold:\n                m.add_F(q, w)\n        return m\n\n    def graphviz(\n        self,\n        fmt=lambda x: f\"{round(x, 3):g}\" if isinstance(x, (float, int)) else str(x),\n        **kwargs,\n    ):  # pylint: disable=arguments-differ\n        return super().graphviz(fmt=fmt, **kwargs)\n\n    @cached_property\n    def simple(self):\n        self = self.epsremove.renumber\n\n        S = self.dim\n        start = np.full(S, self.R.zero)\n        arcs = {a: np.full((S, S), self.R.zero) for a in self.alphabet}\n        stop = np.full(S, self.R.zero)\n\n        for i, w in self.I:\n            start[i] += w\n        for i, a, j, w in self.arcs():\n            arcs[a][i, j] += w\n        for i, w in self.F:\n            stop[i] += w\n\n        assert EPSILON not in arcs\n\n        return Simple(start, arcs, stop)\n\n    def __eq__(self, other):\n        return self.simple == other.simple\n\n    def counterexample(self, other):\n        return self.simple.counterexample(other.simple)\n\n    @cached_property\n    def min(self):\n        return self.simple.min.to_wfsa()\n\n    #    @cached_property\n    #    def epsremove(self):\n    #        return self.simple.to_wfsa()\n\n    def multiplicity(self, m):\n        return WFSA.lift(EPSILON, m) * self\n\n    @classmethod\n    def lift(cls, x, w, R=None):\n        if R is None:\n            R = Float\n        m = cls(R=R)\n        m.add_I(0, R.one)\n        m.add_arc(0, x, 1, w)\n        m.add_F(1, R.one)\n        return m\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.WFSA.threshold","title":"<code>threshold(threshold)</code>","text":"<p>Drop init, arcs, final below a given abs-threshold.</p> Source code in <code>genlm/grammar/wfsa/field_wfsa.py</code> <pre><code>def threshold(self, threshold):\n    \"Drop init, arcs, final below a given abs-threshold.\"\n    m = self.__class__(self.R)\n    for q, w in self.I:\n        if abs(w) &gt;= threshold:\n            m.add_I(q, w)\n    for i, a, j, w in self.arcs():\n        if abs(w) &gt;= threshold:\n            m.add_arc(i, a, j, w)\n    for q, w in self.F:\n        if abs(w) &gt;= threshold:\n            m.add_F(q, w)\n    return m\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.add_EOS","title":"<code>add_EOS(cfg, eos=None)</code>","text":"<p>Add an end-of-sequence symbol to a CFG's language.</p> <p>Transforms the grammar to append the EOS symbol to every string it generates.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The input grammar</p> required <code>eos</code> <code>optional</code> <p>The end-of-sequence symbol to add. Defaults to \u25aa.</p> <code>None</code> <p>Returns:</p> Type Description <code>CFG</code> <p>A new grammar that generates strings ending in EOS</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If EOS is already in the grammar's vocabulary</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def add_EOS(cfg, eos=None):\n    \"\"\"Add an end-of-sequence symbol to a CFG's language.\n\n    Transforms the grammar to append the EOS symbol to every string it generates.\n\n    Args:\n        cfg (CFG): The input grammar\n        eos (optional): The end-of-sequence symbol to add. Defaults to \u25aa.\n\n    Returns:\n        (CFG): A new grammar that generates strings ending in EOS\n\n    Raises:\n        AssertionError: If EOS is already in the grammar's vocabulary\n\n    \"\"\"\n    S = _gen_nt(\"&lt;START&gt;\")\n    new = cfg.spawn(S=S)\n    eos = eos or EOS\n    assert eos not in cfg.V\n    new.V.add(eos)\n    new.add(cfg.R.one, S, cfg.S, eos)\n    for r in cfg:\n        new.add(r.w, r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/__init__/#genlm.grammar.locally_normalize","title":"<code>locally_normalize(self, **kwargs)</code>","text":"<p>Locally normalize the grammar's rule weights.</p> <p>Returns a transformed grammar where: 1. The total weight of rules with the same head symbol sums to one 2. Each derivation's weight is proportional to the original grammar    (differs only by a multiplicative normalization constant)</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to self.agenda()</p> <code>{}</code> <p>Returns:</p> Type Description <code>CFG</code> <p>A new grammar with locally normalized weights</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def locally_normalize(self, **kwargs):\n    \"\"\"Locally normalize the grammar's rule weights.\n\n    Returns a transformed grammar where:\n    1. The total weight of rules with the same head symbol sums to one\n    2. Each derivation's weight is proportional to the original grammar\n       (differs only by a multiplicative normalization constant)\n\n    Args:\n        **kwargs: Additional arguments passed to self.agenda()\n\n    Returns:\n        (CFG): A new grammar with locally normalized weights\n    \"\"\"\n    new = self.spawn()\n    Z = self.agenda(**kwargs)\n    for r in self:\n        if Z[r.head] == 0:\n            continue\n        new.add(r.w * Z.product(r.body) / Z[r.head], r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/","title":"cfg","text":""},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG","title":"<code>CFG</code>","text":"<p>Weighted Context-free Grammar</p> <p>A weighted context-free grammar consists of:</p> <ul> <li> <p><code>R</code>: A semiring that defines the weights</p> </li> <li> <p><code>S</code>: A start symbol (nonterminal)</p> </li> <li> <p><code>V</code>: A set of terminal symbols (vocabulary)</p> </li> <li> <p><code>N</code>: A set of nonterminal symbols</p> </li> <li> <p><code>rules</code>: A list of weighted production rules</p> </li> </ul> <p>Each rule has the form: w: X -&gt; Y1 Y2 ... Yn where:</p> <ul> <li> <p>w is a weight from the semiring R</p> </li> <li> <p>X is a nonterminal symbol</p> </li> <li> <p>Y1...Yn are terminal or nonterminal symbols</p> </li> </ul> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>class CFG:\n    \"\"\"\n    Weighted Context-free Grammar\n\n    A weighted context-free grammar consists of:\\n\n    - `R`: A semiring that defines the weights\\n\n    - `S`: A start symbol (nonterminal)\\n\n    - `V`: A set of terminal symbols (vocabulary)\\n\n    - `N`: A set of nonterminal symbols\\n\n    - `rules`: A list of weighted production rules\\n\n\n    Each rule has the form: w: X -&gt; Y1 Y2 ... Yn where:\\n\n    - w is a weight from the semiring R\\n\n    - X is a nonterminal symbol\\n\n    - Y1...Yn are terminal or nonterminal symbols\\n\n    \"\"\"\n\n    def __init__(self, R, S, V):\n        \"\"\"\n        Initialize a weighted CFG.\n\n        Args:\n            R: The semiring for rule weights\n            S: The start symbol (nonterminal)\n            V: The set of terminal symbols (vocabulary)\n        \"\"\"\n        self.R = R  # semiring\n        self.V = V  # alphabet\n        self.N = {S}  # nonterminals\n        self.S = S  # unique start symbol\n        self.rules = []  # rules\n        self._trim_cache = [None, None]\n\n    def __repr__(self):\n        \"\"\"Return string representation of the grammar.\"\"\"\n        return \"Grammar {\\n%s\\n}\" % \"\\n\".join(f\"  {r}\" for r in self)\n\n    def _repr_html_(self):\n        \"\"\"Return HTML representation of the grammar for Jupyter notebooks.\"\"\"\n        return f'&lt;pre style=\"width: fit-content; text-align: left; border: thin solid black; padding: 0.5em;\"&gt;{self}&lt;/pre&gt;'\n\n    @classmethod\n    def from_string(\n        cls,\n        string,\n        semiring,\n        comment=\"#\",\n        start=\"S\",\n        is_terminal=lambda x: not x[0].isupper(),\n    ):\n        \"\"\"\n        Create a CFG from a string representation.\n\n        Args:\n            string: The grammar rules as a string\n            semiring: The semiring for rule weights\n            comment: Comment character to ignore lines (default: '#')\n            start: Start symbol (default: 'S')\n            is_terminal: Function to identify terminal symbols (default: lowercase first letter)\n\n        Returns:\n            A new CFG instance\n        \"\"\"\n        V = set()\n        cfg = cls(R=semiring, S=start, V=V)\n        string = string.replace(\"-&gt;\", \"\u2192\")  # synonym for the arrow\n        for line in string.split(\"\\n\"):\n            line = line.strip()\n            if not line or line.startswith(comment):\n                continue\n            try:\n                [(w, lhs, rhs)] = re.findall(r\"(.*):\\s*(\\S+)\\s*\u2192\\s*(.*)$\", line)\n                lhs = lhs.strip()\n                rhs = rhs.strip().split()\n                for x in rhs:\n                    if is_terminal(x):\n                        V.add(x)\n                cfg.add(semiring.from_string(w), lhs, *rhs)\n            except ValueError:\n                raise ValueError(f\"bad input line:\\n{line}\")  # pylint: disable=W0707\n        return cfg\n\n    def __getitem__(self, root):\n        \"\"\"\n        Return a grammar that denotes the sublanguage of the nonterminal `root`.\n\n        Args:\n            root: The nonterminal to use as the new start symbol\n\n        Returns:\n            A new CFG with root as the start symbol\n        \"\"\"\n        new = self.spawn(S=root)\n        for r in self:\n            new.add(r.w, r.head, *r.body)\n        return new\n\n    def __len__(self):\n        \"\"\"Return number of rules in the grammar.\"\"\"\n        return len(self.rules)\n\n    def __call__(self, xs):\n        \"\"\"\n        Compute the total weight of the sequence xs.\n\n        Args:\n            xs: A sequence of terminal symbols\n\n        Returns:\n            The total weight of all derivations of xs\n        \"\"\"\n        self = self.cnf  # need to do this here because the start symbol might change\n        return self._parse_chart(xs)[0, self.S, len(xs)]\n\n    def _parse_chart(self, xs):\n        \"\"\"\n        Implements CKY algorithm for evaluating the total weight of the xs sequence.\n\n        Args:\n            xs: A sequence of terminal symbols\n\n        Returns:\n            A chart containing the weights of all subderivations\n        \"\"\"\n        (nullary, terminal, binary) = self._cnf  # will convert to CNF\n        N = len(xs)\n        # nullary rule\n        c = self.R.chart()\n        for i in range(N + 1):\n            c[i, self.S, i] += nullary\n        # preterminal rules\n        for i in range(N):\n            for r in terminal[xs[i]]:\n                c[i, r.head, i + 1] += r.w\n        # binary rules\n        for span in range(2, N + 1):\n            for i in range(N - span + 1):\n                k = i + span\n                for j in range(i + 1, k):\n                    for r in binary:\n                        X, [Y, Z] = r.head, r.body\n                        c[i, X, k] += r.w * c[i, Y, j] * c[j, Z, k]\n        return c\n\n    def language(self, depth):\n        \"\"\"\n        Enumerate strings generated by this cfg by derivations up to the given depth.\n\n        Args:\n            depth: Maximum derivation depth to consider\n\n        Returns:\n            A chart containing the weighted language up to the given depth\n        \"\"\"\n        lang = self.R.chart()\n        for d in self.derivations(self.S, depth):\n            lang[d.Yield()] += d.weight()\n        return lang\n\n    @cached_property\n    def rhs(self):\n        \"\"\"\n        Map from each nonterminal to the list of rules with it as their left-hand side.\n\n        Returns:\n            A dict mapping nonterminals to lists of rules\n        \"\"\"\n        rhs = defaultdict(list)\n        for r in self:\n            rhs[r.head].append(r)\n        return rhs\n\n    def is_terminal(self, x):\n        \"\"\"Return True if x is a terminal symbol.\"\"\"\n        return x in self.V\n\n    def is_nonterminal(self, X):\n        \"\"\"Return True if X is a nonterminal symbol.\"\"\"\n        return not self.is_terminal(X)\n\n    def __iter__(self):\n        \"\"\"Iterate over the rules in the grammar.\"\"\"\n        return iter(self.rules)\n\n    @property\n    def size(self):\n        \"\"\"Return total size of the grammar (sum of rule lengths).\"\"\"\n        return sum(1 + len(r.body) for r in self)\n\n    @property\n    def num_rules(self):\n        \"\"\"Return number of rules in the grammar.\"\"\"\n        return len(self.rules)\n\n    @property\n    def expected_length(self):\n        \"\"\"\n        Compute the expected length of a string using the Expectation semiring.\n\n        Returns:\n            The expected length of strings generated by this grammar\n\n        Raises:\n            AssertionError: If grammar is not over the Float semiring\n        \"\"\"\n        assert self.R == Float, (\n            \"This method only supports grammars over the Float semiring\"\n        )\n        new_cfg = self.__class__(R=Expectation, S=self.S, V=self.V)\n        for r in self:\n            new_cfg.add(\n                Expectation(r.w, r.w * sum(self.is_terminal(y) for y in r.body)),\n                r.head,\n                *r.body,\n            )\n        return new_cfg.treesum().score[1]\n\n    def spawn(self, *, R=None, S=None, V=None):\n        \"\"\"\n        Create an empty grammar with the same R, S, and V.\n\n        Args:\n            R: Optional new semiring\n            S: Optional new start symbol\n            V: Optional new vocabulary\n\n        Returns:\n            A new empty CFG with specified parameters\n        \"\"\"\n        return self.__class__(\n            R=self.R if R is None else R,\n            S=self.S if S is None else S,\n            V=set(self.V) if V is None else V,\n        )\n\n    def add(self, w, head, *body):\n        \"\"\"\n        Add a rule of the form w: head -&gt; body1, body2, ... body_k.\n\n        Args:\n            w: The rule weight\n            head: The left-hand side nonterminal\n            *body: The right-hand side symbols\n\n        Returns:\n            The added rule, or None if weight is zero\n        \"\"\"\n        if w == self.R.zero:\n            return  # skip rules with weight zero\n        self.N.add(head)\n        r = Rule(w, head, body)\n        self.rules.append(r)\n        return r\n\n    def renumber(self):\n        \"\"\"\n        Rename nonterminals to integers.\n\n        Returns:\n            A new CFG with integer nonterminals\n        \"\"\"\n        i = Integerizer()\n        max_v = max((x for x in self.V if isinstance(x, int)), default=0)\n        return self.rename(lambda x: i(x) + max_v + 1)\n\n    def rename(self, f):\n        \"\"\"\n        Return a new grammar that is the result of applying f to each nonterminal.\n\n        Args:\n            f: Function to rename nonterminals\n\n        Returns:\n            A new CFG with renamed nonterminals\n        \"\"\"\n        new = self.spawn(S=f(self.S))\n        for r in self:\n            new.add(\n                r.w, f(r.head), *((y if self.is_terminal(y) else f(y) for y in r.body))\n            )\n        return new\n\n    def map_values(self, f, R):\n        \"\"\"\n        Return a new grammar that is the result of applying f: self.R -&gt; R to each rule's weight.\n\n        Args:\n            f: Function to map weights\n            R: New semiring for weights\n\n        Returns:\n            A new CFG with mapped weights\n        \"\"\"\n        new = self.spawn(R=R)\n        for r in self:\n            new.add(f(r.w), r.head, *r.body)\n        return new\n\n    def assert_equal(self, other, verbose=False, throw=True):\n        \"\"\"\n        Assertion for the equality of self and other modulo rule reordering.\n\n        Args:\n            other: The grammar to compare against\n            verbose: If True, print differences\n            throw: If True, raise AssertionError on inequality\n\n        Raises:\n            AssertionError: If grammars are not equal and throw=True\n        \"\"\"\n        assert verbose or throw\n        if isinstance(other, str):\n            other = self.__class__.from_string(other, self.R)\n        if verbose:\n            # TODO: need to check the weights in the print out; we do it in the assertion\n            S = set(self.rules)\n            G = set(other.rules)\n            for r in sorted(S | G, key=str):\n                if r in S and r in G:\n                    continue\n                # if r in S and r not in G: continue\n                # if r not in S and r in G: continue\n                print(\n                    colors.mark(r in S),\n                    # colors.mark(r in S and r in G),\n                    colors.mark(r in G),\n                    r,\n                )\n        assert not throw or Counter(self.rules) == Counter(other.rules), (\n            f\"\\n\\nhave=\\n{str(self)}\\nwant=\\n{str(other)}\"\n        )\n\n    def treesum(self, **kwargs):\n        \"\"\"\n        Total weight of the start symbol.\n\n        Returns:\n            The total weight of all derivations from the start symbol\n        \"\"\"\n        return self.agenda(**kwargs)[self.S]\n\n    def trim(self, bottomup_only=False):\n        \"\"\"\n        Return an equivalent grammar with no dead or useless nonterminals or rules.\n\n        Args:\n            bottomup_only: If True, only remove non-generating nonterminals\n\n        Returns:\n            A new trimmed CFG\n        \"\"\"\n        if self._trim_cache[bottomup_only] is not None:\n            return self._trim_cache[bottomup_only]\n\n        C = set(self.V)\n        C.update(e.head for e in self.rules if len(e.body) == 0)\n\n        incoming = defaultdict(list)\n        outgoing = defaultdict(list)\n        for e in self:\n            incoming[e.head].append(e)\n            for b in e.body:\n                outgoing[b].append(e)\n\n        agenda = set(C)\n        while agenda:\n            x = agenda.pop()\n            for e in outgoing[x]:\n                if all((b in C) for b in e.body):\n                    if e.head not in C:\n                        C.add(e.head)\n                        agenda.add(e.head)\n\n        if bottomup_only:\n            val = self._trim(C)\n            self._trim_cache[bottomup_only] = val\n            val._trim_cache[bottomup_only] = val\n            return val\n\n        T = {self.S}\n        agenda.update(T)\n        while agenda:\n            x = agenda.pop()\n            for e in incoming[x]:\n                # assert e.head in T\n                for b in e.body:\n                    if b not in T and b in C:\n                        T.add(b)\n                        agenda.add(b)\n\n        val = self._trim(T)\n        self._trim_cache[bottomup_only] = val\n        val._trim_cache[bottomup_only] = val\n        return val\n\n    def cotrim(self):\n        \"\"\"\n        Trim the grammar so that all nonterminals are generating.\n\n        Returns:\n            A new CFG with only generating nonterminals\n        \"\"\"\n        return self.trim(bottomup_only=True)\n\n    def _trim(self, symbols):\n        \"\"\"\n        Helper method for trim() - creates new grammar with only given symbols.\n\n        Args:\n            symbols: Set of symbols to keep\n\n        Returns:\n            A new CFG with only rules using the given symbols\n        \"\"\"\n        new = self.spawn()\n        for p in self:\n            if p.head in symbols and p.w != self.R.zero and set(p.body) &lt;= symbols:\n                new.add(p.w, p.head, *p.body)\n        return new\n\n    # ___________________________________________________________________________\n    # Derivation enumeration\n\n    def derivations(self, X, H):\n        \"\"\"\n        Enumerate derivations of symbol X with height &lt;= H.\n\n        Args:\n            X: The symbol to derive from (default: start symbol)\n            H: Maximum derivation height\n\n        Yields:\n            Derivation objects representing derivation trees\n        \"\"\"\n        if X is None:\n            X = self.S\n        if self.is_terminal(X):\n            yield X\n        elif H &lt;= 0:\n            return\n        else:\n            for r in self.rhs[X]:\n                for ys in self._derivations_list(r.body, H - 1):\n                    yield Derivation(r, X, *ys)\n\n    def _derivations_list(self, Xs, H):\n        \"\"\"\n        Helper method for derivations; expands any list of symbols X up to depth H.\n\n        Args:\n            Xs: List of symbols to derive\n            H: Maximum derivation height\n\n        Yields:\n            Tuples of derivations\n        \"\"\"\n        if len(Xs) == 0:\n            yield ()\n        else:\n            for x in self.derivations(Xs[0], H):\n                for xs in self._derivations_list(Xs[1:], H):\n                    yield (x, *xs)\n\n    # ___________________________________________________________________________\n    # Transformations\n\n    def _unary_graph(self):\n        \"\"\"\n        Compute the matrix closure of unary rules.\n\n        Returns:\n            A WeightedGraph representing unary rule closure\n        \"\"\"\n        A = WeightedGraph(self.R)\n        for r in self:\n            if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n                A[r.head, r.body[0]] += r.w\n        A.N |= self.N\n        return A\n\n    def _unary_graph_transpose(self):\n        \"\"\"\n        Compute the matrix closure of unary rules (transposed).\n\n        Returns:\n            A WeightedGraph representing transposed unary rule closure\n        \"\"\"\n        A = WeightedGraph(self.R)\n        for r in self:\n            if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n                A[r.body[0], r.head] += r.w\n        A.N |= self.N\n        return A\n\n    def unaryremove(self):\n        \"\"\"\n        Return an equivalent grammar with no unary rules.\n\n        Returns:\n            A new CFG without unary rules\n        \"\"\"\n        W = self._unary_graph().closure_scc_based()\n        # W = self._unary_graph().closure_reference()\n\n        new = self.spawn()\n        for r in self:\n            if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n                continue\n            for Y in self.N:\n                new.add(W[Y, r.head] * r.w, Y, *r.body)\n\n        return new\n\n    def has_unary_cycle(self):\n        \"\"\"\n        Check if the grammar has unary cycles.\n\n        Returns:\n            True if the grammar contains unary cycles\n        \"\"\"\n        f = self._unary_graph().buckets\n        return any(\n            True for r in self if len(r.body) == 1 and f.get(r.head) == f.get(r.body[0])\n        )\n\n    def unarycycleremove(self, trim=True):\n        \"\"\"\n        Return an equivalent grammar with no unary cycles.\n\n        Args:\n            trim: If True, trim the resulting grammar\n\n        Returns:\n            A new CFG without unary cycles\n        \"\"\"\n\n        def bot(x):\n            return x if x in acyclic else (x, \"bot\")\n\n        G = self._unary_graph()\n\n        new = self.spawn(S=self.S)\n\n        bucket = G.buckets\n\n        acyclic = set()\n        for nodes, _ in G.Blocks:\n            if len(nodes) == 1:\n                [X] = nodes\n                if G[X, X] == self.R.zero:\n                    acyclic.add(X)\n\n        # run Lehmann's on each cylical SCC\n        for nodes, W in G.Blocks:\n            if len(nodes) == 1:\n                [X] = nodes\n                if X in acyclic:\n                    continue\n\n            for X1, X2 in W:\n                new.add(W[X1, X2], X1, bot(X2))\n\n        for r in self:\n            if len(r.body) == 1 and bucket.get(r.body[0]) == bucket[r.head]:\n                continue\n            new.add(r.w, bot(r.head), *r.body)\n\n        # TODO: figure out how to ensure that the new grammar is trimmed by\n        # construction (assuming the input grammar was trim).\n        if trim:\n            new = new.trim()\n\n        return new\n\n    def nullaryremove(self, binarize=True, trim=True, **kwargs):\n        \"\"\"\n        Return an equivalent grammar with no nullary rules except for one at the start symbol.\n\n        Args:\n            binarize: If True, binarize the grammar first\n            trim: If True, trim the resulting grammar\n            **kwargs: Additional arguments passed to _push_null_weights\n\n        Returns:\n            A new CFG without nullary rules (except at start)\n        \"\"\"\n        # A really wide rule can take a very long time because of the power set\n        # in this rule so it is really important to binarize.\n        if binarize:\n            self = self.binarize()  # pragma: no cover\n        self = self.separate_start()\n        tmp = self._push_null_weights(self.null_weight(), **kwargs)\n        return tmp.trim() if trim else tmp\n\n    def null_weight(self):\n        \"\"\"\n        Compute the map from nonterminal to total weight of generating the empty string.\n\n        Returns:\n            A dict mapping nonterminals to their null weights\n        \"\"\"\n        ecfg = self.spawn(V=set())\n        for p in self:\n            if not any(self.is_terminal(y) for y in p.body):\n                ecfg.add(p.w, p.head, *p.body)\n        return ecfg.agenda()\n\n    def null_weight_start(self):\n        \"\"\"\n        Compute the null weight of the start symbol.\n\n        Returns:\n            The total weight of generating the empty string from the start symbol\n        \"\"\"\n        return self.null_weight()[self.S]\n\n    def _push_null_weights(self, null_weight, rename=NotNull):\n        \"\"\"\n        Returns a grammar that generates the same weighted language but is nullary-free\n        at all nonterminals except its start symbol.\n\n        Args:\n            null_weight: Dict mapping nonterminals to their null weights\n            rename: Function to rename nonterminals (default: NotNull)\n\n        Returns:\n            A new CFG without nullary rules (except at start)\n        \"\"\"\n        # Warning: this method might have issues when `separate_start` hasn't\n        # been run before.  So we run it rather than leaving it up to chance.\n        assert self.S not in {y for r in self for y in r.body}\n\n        def f(x):\n            \"Rename nonterminal if necessary\"\n            if (\n                null_weight[x] == self.R.zero or x == self.S\n            ):  # not necessary; keep old name\n                return x\n            else:\n                return rename(x)\n\n        rcfg = self.spawn()\n        rcfg.add(null_weight[self.S], self.S)\n\n        for r in self:\n            if len(r.body) == 0:\n                continue  # drop nullary rule\n\n            for B in product([0, 1], repeat=len(r.body)):\n                v, new_body = r.w, []\n\n                for i, b in enumerate(B):\n                    if b:\n                        v *= null_weight[r.body[i]]\n                    else:\n                        new_body.append(f(r.body[i]))\n\n                # exclude the cases that would be new nullary rules!\n                if len(new_body) &gt; 0:\n                    rcfg.add(v, f(r.head), *new_body)\n\n        return rcfg\n\n    def separate_start(self):\n        \"\"\"\n        Ensure that the start symbol does not appear on the RHS of any rule.\n\n        Returns:\n            A new CFG with start symbol only on LHS\n        \"\"\"\n        # create a new start symbol if the current one appears on the rhs of any existing rule\n        if self.S in {y for r in self for y in r.body}:\n            S = _gen_nt(self.S)\n            new = self.spawn(S=S)\n            # preterminal rules\n            new.add(self.R.one, S, self.S)\n            for r in self:\n                new.add(r.w, r.head, *r.body)\n            return new\n        else:\n            return self\n\n    def separate_terminals(self):\n        \"\"\"\n        Ensure that each terminal is produced by a preterminal rule.\n\n        Returns:\n            A new CFG with terminals only in preterminal rules\n        \"\"\"\n        one = self.R.one\n        new = self.spawn()\n\n        _preterminal = {}\n\n        def preterminal(x):\n            y = _preterminal.get(x)\n            if y is None:\n                y = new.add(one, _gen_nt(), x)\n                _preterminal[x] = y\n            return y\n\n        for r in self:\n            if len(r.body) == 1 and self.is_terminal(r.body[0]):\n                new.add(r.w, r.head, *r.body)\n            else:\n                new.add(\n                    r.w,\n                    r.head,\n                    *(\n                        (preterminal(y).head if self.is_terminal(y) else y)\n                        for y in r.body\n                    ),\n                )\n\n        return new\n\n    def binarize(self):\n        \"\"\"\n        Return an equivalent grammar with arity \u2264 2.\n\n        Returns:\n            A new CFG with binary rules\n        \"\"\"\n        new = self.spawn()\n\n        stack = list(self)\n        while stack:\n            p = stack.pop()\n            if len(p.body) &lt;= 2:\n                new.add(p.w, p.head, *p.body)\n            else:\n                stack.extend(self._fold(p, [(0, 1)]))\n\n        return new\n\n    def _fold(self, p, I):\n        \"\"\"\n        Helper method for binarization - folds a rule into binary rules.\n\n        Args:\n            p: The rule to fold\n            I: List of (start,end) indices for folding\n\n        Returns:\n            List of new binary rules\n        \"\"\"\n        # new productions\n        P, heads = [], []\n        for i, j in I:\n            head = _gen_nt()\n            heads.append(head)\n            body = p.body[i : j + 1]\n            P.append(Rule(self.R.one, head, body))\n\n        # new \"head\" production\n        body = tuple()\n        start = 0\n        for (end, n), head in zip(I, heads):\n            body += p.body[start:end] + (head,)\n            start = n + 1\n        body += p.body[start:]\n        P.append(Rule(p.w, p.head, body))\n\n        return P\n\n    @cached_property\n    def cnf(self):\n        \"\"\"\n        Transform this grammar into Chomsky Normal Form (CNF).\n\n        Returns:\n            A new CFG in CNF\n        \"\"\"\n        new = (\n            self.separate_terminals()\n            .nullaryremove(binarize=True)\n            .trim()\n            .unaryremove()\n            .trim()\n        )\n        assert new.in_cnf(), \"\\n\".join(\n            str(r) for r in new._find_invalid_cnf_rule()\n        )  # pragma: no cover\n        return new\n\n    # TODO: make CNF grammars a speciazed subclass of CFG.\n    @cached_property\n    def _cnf(self):\n        \"\"\"\n        Note: Throws an exception if the grammar is not in CNF.\n\n        Returns:\n            Tuple of (nullary weight, terminal rules dict, binary rules list)\n        \"\"\"\n        nullary = self.R.zero\n        terminal = defaultdict(list)\n        binary = []\n        for r in self:\n            if len(r.body) == 0:\n                nullary += r.w\n                assert r.head == self.S, [self.S, r]\n            elif len(r.body) == 1:\n                terminal[r.body[0]].append(r)\n                assert self.is_terminal(r.body[0])\n            else:\n                assert len(r.body) == 2\n                binary.append(r)\n                assert self.is_nonterminal(r.body[0])\n                assert self.is_nonterminal(r.body[1])\n        return (nullary, terminal, binary)\n\n    def in_cnf(self):\n        \"\"\"\n        Return true if the grammar is in CNF.\n\n        Returns:\n            True if grammar is in Chomsky Normal Form\n        \"\"\"\n        return len(list(self._find_invalid_cnf_rule())) == 0\n\n    def _find_invalid_cnf_rule(self):\n        \"\"\"\n        Return true if the grammar is in CNF.\n\n        Yields:\n            Rules that violate CNF\n        \"\"\"\n        for r in self:\n            assert r.head in self.N\n            if len(r.body) == 0 and r.head == self.S:\n                continue\n            elif len(r.body) == 1 and self.is_terminal(r.body[0]):\n                continue\n            elif len(r.body) == 2 and all(\n                self.is_nonterminal(y) and y != self.S for y in r.body\n            ):\n                continue\n            else:\n                yield r\n\n    #    def has_nullary(self):\n    #        return any((len(p.body) == 0) for p in self if p.head != self.S)\n\n    def unfold(self, i, k):\n        \"\"\"\n        Apply the unfolding transformation to rule i and subgoal k.\n\n        Args:\n            i: Index of rule to unfold\n            k: Index of subgoal in rule body\n\n        Returns:\n            A new CFG with the rule unfolded\n        \"\"\"\n        assert isinstance(i, int) and isinstance(k, int)\n        s = self.rules[i]\n        assert self.is_nonterminal(s.body[k])\n\n        new = self.spawn()\n        for j, r in enumerate(self):\n            if j != i:\n                new.add(r.w, r.head, *r.body)\n\n        for r in self.rhs[s.body[k]]:\n            new.add(s.w * r.w, s.head, *s.body[:k], *r.body, *s.body[k + 1 :])\n\n        return new\n\n    def dependency_graph(self):\n        \"\"\"\n        Head-to-body dependency graph of the rules of the grammar.\n\n        Returns:\n            A WeightedGraph representing dependencies between symbols\n        \"\"\"\n        deps = WeightedGraph(Boolean)\n        for r in self:\n            for y in r.body:\n                deps[r.head, y] += Boolean.one\n        deps.N |= self.N\n        deps.N |= self.V\n        return deps\n\n    # TODO: the default treesum algorithm should probably be SCC-decomposed newton's method\n    # def agenda(self, tol=1e-12, maxiter=float('inf')):\n    def agenda(self, tol=1e-12, maxiter=100_000):\n        \"\"\"\n        Agenda-based semi-naive evaluation for treesums.\n\n        Args:\n            tol: Convergence tolerance\n            maxiter: Maximum iterations\n\n        Returns:\n            A chart containing the treesum weights\n        \"\"\"\n        old = self.R.chart()\n\n        # precompute the mapping from updates to where they need to go\n        routing = defaultdict(list)\n        for r in self:\n            for k in range(len(r.body)):\n                routing[r.body[k]].append((r, k))\n\n        deps = self.dependency_graph()\n        blocks = deps.blocks\n        bucket = deps.buckets\n\n        # helper function\n        def update(x, W):\n            change[bucket[x]][x] += W\n\n        change = defaultdict(self.R.chart)\n        for a in self.V:\n            update(a, self.R.one)\n\n        for r in self:\n            if len(r.body) == 0:\n                update(r.head, r.w)\n\n        b = len(blocks)\n        iteration = 0\n        while b &gt;= 0:\n            iteration += 1\n\n            # Move on to the next block\n            if len(change[b]) == 0 or iteration &gt; maxiter:\n                b -= 1\n                iteration = 0  # reset iteration number for the next bucket\n                continue\n\n            u, v = change[b].popitem()\n\n            new = old[u] + v\n\n            if self.R.metric(old[u], new) &lt;= tol:\n                continue\n\n            for r, k in routing[u]:\n                W = r.w\n                for j in range(len(r.body)):\n                    if u == r.body[j]:\n                        if j &lt; k:\n                            W *= new\n                        elif j == k:\n                            W *= v\n                        else:\n                            W *= old[u]\n                    else:\n                        W *= old[r.body[j]]\n\n                update(r.head, W)\n\n            old[u] = new\n\n        return old\n\n    def naive_bottom_up(self, *, tol=1e-12, timeout=100_000):\n        \"Naive bottom-up evaluation for treesums; better to use `agenda`.\"\n\n        def _approx_equal(U, V):\n            return all((self.R.metric(U[X], V[X]) &lt;= tol) for X in self.N)\n\n        R = self.R\n        V = R.chart()\n        counter = 0\n        while counter &lt; timeout:\n            U = self._bottom_up_step(V)\n            if _approx_equal(U, V):\n                break\n            V = U\n            counter += 1\n        return V\n\n    def _bottom_up_step(self, V):\n        R = self.R\n        one = R.one\n        U = R.chart()\n        for a in self.V:\n            U[a] = one\n        for p in self:\n            update = p.w\n            for X in p.body:\n                if self.is_nonterminal(X):\n                    update *= V[X]\n            U[p.head] += update\n        return U\n\n    def prefix_weight(self, xs):\n        \"Total weight of all derivations that have `xs` as a prefix.\"\n        return self.prefix_grammar(xs)\n\n    @cached_property\n    def prefix_grammar(self):\n        \"Grammar that generates prefixing of this grammar's language.\"\n        return self @ prefix_transducer(self.R, self.V)\n\n    def derivatives(self, s):\n        \"Return the sequence of derivatives for each prefix of `s`.\"\n        M = len(s)\n        D = [self]\n        for m in range(M):\n            D.append(D[m].derivative(s[m]))\n        return D\n\n    # Implementation note: This implementation of the derivative grammar\n    # performs nullary elimination at the same time.\n    def derivative(self, a, i=0):\n        \"Return a grammar that generates the derivative with respect to `a`.\"\n\n        def slash(x, y):\n            return Slash(x, y, i=i)\n\n        D = self.spawn(S=slash(self.S, a))\n        U = self.null_weight()\n        for r in self:\n            D.add(r.w, r.head, *r.body)\n            delta = self.R.one\n            for k, y in enumerate(r.body):\n                if slash(r.head, a) in self.N:\n                    continue  # SKIP!\n                if self.is_terminal(y):\n                    if y == a:\n                        D.add(delta * r.w, slash(r.head, a), *r.body[k + 1 :])\n                else:\n                    D.add(\n                        delta * r.w,\n                        slash(r.head, a),\n                        slash(r.body[k], a),\n                        *r.body[k + 1 :],\n                    )\n                delta *= U[y]\n        return D\n\n    def _compose_bottom_up_epsilon(self, fst):\n        \"Determine which items of the composition grammar are supported\"\n\n        A = set()\n\n        I = defaultdict(set)  # incomplete items\n        C = defaultdict(set)  # complete items\n        R = defaultdict(set)  # rules indexed by first subgoal; non-nullary\n\n        special_rules = [Rule(self.R.one, a, (EPSILON, a)) for a in self.V] + [\n            Rule(self.R.one, Other(self.S), (self.S,)),\n            Rule(self.R.one, Other(self.S), (Other(self.S), EPSILON)),\n        ]\n\n        for r in itertools.chain(self, special_rules):\n            if len(r.body) &gt; 0:\n                R[r.body[0]].add(r)\n\n        # we have two base cases:\n        #\n        # base case 1: arcs\n        for i, (a, _), j, _ in fst.arcs():\n            A.add((i, a, (), j))  # empty tuple -&gt; the rule 'complete'\n\n        # base case 2: nullary rules\n        for r in self:\n            if len(r.body) == 0:\n                for i in fst.states:\n                    A.add((i, r.head, (), i))\n\n        # drain the agenda\n        while A:\n            (i, X, Ys, j) = A.pop()\n\n            # No pending items ==&gt; the item is complete\n            if not Ys:\n                if j in C[i, X]:\n                    continue\n                C[i, X].add(j)\n\n                # combine the newly completed item with incomplete rules that are\n                # looking for an item like this one\n                for h, X1, Zs in I[i, X]:\n                    A.add((h, X1, Zs[1:], j))\n\n                # initialize rules that can start with an item like this one\n                for r in R[X]:\n                    A.add((i, r.head, r.body[1:], j))\n\n            # Still have pending items ==&gt; advanced the pending items\n            else:\n                if (i, X, Ys) in I[j, Ys[0]]:\n                    continue\n                I[j, Ys[0]].add((i, X, Ys))\n\n                for k in C[j, Ys[0]]:\n                    A.add((i, X, Ys[1:], k))\n\n        return C\n\n    def __matmul__(self, fst):\n        \"Return a CFG denoting the pointwise product or composition of `self` and `fs`.\"\n\n        # coerce something sequence like into a diagonal FST\n        if isinstance(fst, (str, tuple)):\n            fst = FST.from_string(fst, self.R)\n        # coerce something FSA-like into an FST, might throw an error\n        if not isinstance(fst, FST):\n            fst = fst.to_fst()\n\n        # Initialize the new CFG:\n        # - its start symbol is chosen arbitrarily to be `self.S`\n        # - its the alphabet changes - it is now 'output' alphabet of the transducer\n        new_start = self.S\n        new = self.spawn(S=new_start, V=fst.B - {EPSILON})\n\n        # The bottom-up intersection algorithm is a two-pass algorithm\n        #\n        # Pass 1: Determine the set of items that are possiblly nonzero-valued\n        C = self._compose_bottom_up_epsilon(fst)\n\n        special_rules = [Rule(self.R.one, a, (EPSILON, a)) for a in self.V] + [\n            Rule(self.R.one, Other(self.S), (self.S,)),\n            Rule(self.R.one, Other(self.S), (Other(self.S), EPSILON)),\n        ]\n\n        def join(start, Ys):\n            \"\"\"\n            Helper method; expands the rule body\n\n            Given Ys = [Y_1, ... Y_K], we will enumerate expansion of the form\n\n            (s_0, Y_1, s_1), (s_1, Y_2, s_2), ..., (s_{k-1}, Y_K, s_K)\n\n            where each (s_k, Y_k, s_k) in the expansion is a completed items\n            (i.e., \\forall k: (s_k, Y_k, s_k) in C).\n            \"\"\"\n            if not Ys:\n                yield []\n            else:\n                for K in C[start, Ys[0]]:\n                    for rest in join(K, Ys[1:]):\n                        yield [(start, Ys[0], K)] + rest\n\n        start = {I for (I, _) in C}\n\n        for r in itertools.chain(self, special_rules):\n            if len(r.body) == 0:\n                for s in fst.states:\n                    new.add(r.w, (s, r.head, s))\n            else:\n                for I in start:\n                    for rhs in join(I, r.body):\n                        K = rhs[-1][-1]\n                        new.add(r.w, (I, r.head, K), *rhs)\n\n        for i, wi in fst.start.items():\n            for k, wf in fst.stop.items():\n                new.add(wi * wf, new_start, (i, Other(self.S), k))\n\n        for i, (a, b), j, w in fst.arcs():\n            if b == EPSILON:\n                new.add(w, (i, a, j))\n            else:\n                new.add(w, (i, a, j), b)\n        return new\n\n    def truncate_length(self, max_length):\n        \"Transform this grammar so that it only generates strings with length \u2264 `max_length`.\"\n        from genlm.grammar import WFSA\n\n        m = WFSA(self.R)\n        m.add_I(0, self.R.one)\n        m.add_F(0, self.R.one)\n        for t in range(max_length):\n            for x in self.V:\n                m.add_arc(t, x, t + 1, self.R.one)\n            m.add_F(t + 1, self.R.one)\n        return self @ m\n\n    def materialize(self, max_length):\n        \"Return a `Chart` with this grammar's weighted language for strings \u2264 `max_length`.\"\n        return self.cnf.language(max_length).filter(lambda x: len(x) &lt;= max_length)\n\n    def to_bytes(self):\n        \"\"\"Convert terminal symbols from strings to bytes representation.\n\n        This method creates a new grammar where all terminal string symbols are\n        converted to their UTF-8 byte representation. Non-terminal symbols are\n        preserved as-is.\n\n        Returns:\n            CFG: A new grammar with byte terminal symbols\n\n        Raises:\n            ValueError: If a terminal symbol is not a string\n        \"\"\"\n        new = self.spawn(S=self.S, R=self.R, V=set())\n\n        for r in self:\n            new_body = []\n            for x in r.body:\n                if self.is_terminal(x):\n                    if not isinstance(x, str):\n                        raise ValueError(f\"unsupported terminal type: {type(x)}\")\n                    bs = list(x.encode(\"utf-8\"))\n                    for b in bs:\n                        new.V.add(b)\n                    new_body.extend(bs)\n                else:\n                    new_body.append(x)\n            new.add(r.w, r.head, *new_body)\n\n        return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.cnf","title":"<code>cnf</code>  <code>cached</code> <code>property</code>","text":"<p>Transform this grammar into Chomsky Normal Form (CNF).</p> <p>Returns:</p> Type Description <p>A new CFG in CNF</p>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.expected_length","title":"<code>expected_length</code>  <code>property</code>","text":"<p>Compute the expected length of a string using the Expectation semiring.</p> <p>Returns:</p> Type Description <p>The expected length of strings generated by this grammar</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If grammar is not over the Float semiring</p>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.num_rules","title":"<code>num_rules</code>  <code>property</code>","text":"<p>Return number of rules in the grammar.</p>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.prefix_grammar","title":"<code>prefix_grammar</code>  <code>cached</code> <code>property</code>","text":"<p>Grammar that generates prefixing of this grammar's language.</p>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.rhs","title":"<code>rhs</code>  <code>cached</code> <code>property</code>","text":"<p>Map from each nonterminal to the list of rules with it as their left-hand side.</p> <p>Returns:</p> Type Description <p>A dict mapping nonterminals to lists of rules</p>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.size","title":"<code>size</code>  <code>property</code>","text":"<p>Return total size of the grammar (sum of rule lengths).</p>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.__call__","title":"<code>__call__(xs)</code>","text":"<p>Compute the total weight of the sequence xs.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <p>A sequence of terminal symbols</p> required <p>Returns:</p> Type Description <p>The total weight of all derivations of xs</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __call__(self, xs):\n    \"\"\"\n    Compute the total weight of the sequence xs.\n\n    Args:\n        xs: A sequence of terminal symbols\n\n    Returns:\n        The total weight of all derivations of xs\n    \"\"\"\n    self = self.cnf  # need to do this here because the start symbol might change\n    return self._parse_chart(xs)[0, self.S, len(xs)]\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.__getitem__","title":"<code>__getitem__(root)</code>","text":"<p>Return a grammar that denotes the sublanguage of the nonterminal <code>root</code>.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <p>The nonterminal to use as the new start symbol</p> required <p>Returns:</p> Type Description <p>A new CFG with root as the start symbol</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __getitem__(self, root):\n    \"\"\"\n    Return a grammar that denotes the sublanguage of the nonterminal `root`.\n\n    Args:\n        root: The nonterminal to use as the new start symbol\n\n    Returns:\n        A new CFG with root as the start symbol\n    \"\"\"\n    new = self.spawn(S=root)\n    for r in self:\n        new.add(r.w, r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.__init__","title":"<code>__init__(R, S, V)</code>","text":"<p>Initialize a weighted CFG.</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <p>The semiring for rule weights</p> required <code>S</code> <p>The start symbol (nonterminal)</p> required <code>V</code> <p>The set of terminal symbols (vocabulary)</p> required Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __init__(self, R, S, V):\n    \"\"\"\n    Initialize a weighted CFG.\n\n    Args:\n        R: The semiring for rule weights\n        S: The start symbol (nonterminal)\n        V: The set of terminal symbols (vocabulary)\n    \"\"\"\n    self.R = R  # semiring\n    self.V = V  # alphabet\n    self.N = {S}  # nonterminals\n    self.S = S  # unique start symbol\n    self.rules = []  # rules\n    self._trim_cache = [None, None]\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the rules in the grammar.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the rules in the grammar.\"\"\"\n    return iter(self.rules)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.__len__","title":"<code>__len__()</code>","text":"<p>Return number of rules in the grammar.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __len__(self):\n    \"\"\"Return number of rules in the grammar.\"\"\"\n    return len(self.rules)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.__matmul__","title":"<code>__matmul__(fst)</code>","text":"<p>Return a CFG denoting the pointwise product or composition of <code>self</code> and <code>fs</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __matmul__(self, fst):\n    \"Return a CFG denoting the pointwise product or composition of `self` and `fs`.\"\n\n    # coerce something sequence like into a diagonal FST\n    if isinstance(fst, (str, tuple)):\n        fst = FST.from_string(fst, self.R)\n    # coerce something FSA-like into an FST, might throw an error\n    if not isinstance(fst, FST):\n        fst = fst.to_fst()\n\n    # Initialize the new CFG:\n    # - its start symbol is chosen arbitrarily to be `self.S`\n    # - its the alphabet changes - it is now 'output' alphabet of the transducer\n    new_start = self.S\n    new = self.spawn(S=new_start, V=fst.B - {EPSILON})\n\n    # The bottom-up intersection algorithm is a two-pass algorithm\n    #\n    # Pass 1: Determine the set of items that are possiblly nonzero-valued\n    C = self._compose_bottom_up_epsilon(fst)\n\n    special_rules = [Rule(self.R.one, a, (EPSILON, a)) for a in self.V] + [\n        Rule(self.R.one, Other(self.S), (self.S,)),\n        Rule(self.R.one, Other(self.S), (Other(self.S), EPSILON)),\n    ]\n\n    def join(start, Ys):\n        \"\"\"\n        Helper method; expands the rule body\n\n        Given Ys = [Y_1, ... Y_K], we will enumerate expansion of the form\n\n        (s_0, Y_1, s_1), (s_1, Y_2, s_2), ..., (s_{k-1}, Y_K, s_K)\n\n        where each (s_k, Y_k, s_k) in the expansion is a completed items\n        (i.e., \\forall k: (s_k, Y_k, s_k) in C).\n        \"\"\"\n        if not Ys:\n            yield []\n        else:\n            for K in C[start, Ys[0]]:\n                for rest in join(K, Ys[1:]):\n                    yield [(start, Ys[0], K)] + rest\n\n    start = {I for (I, _) in C}\n\n    for r in itertools.chain(self, special_rules):\n        if len(r.body) == 0:\n            for s in fst.states:\n                new.add(r.w, (s, r.head, s))\n        else:\n            for I in start:\n                for rhs in join(I, r.body):\n                    K = rhs[-1][-1]\n                    new.add(r.w, (I, r.head, K), *rhs)\n\n    for i, wi in fst.start.items():\n        for k, wf in fst.stop.items():\n            new.add(wi * wf, new_start, (i, Other(self.S), k))\n\n    for i, (a, b), j, w in fst.arcs():\n        if b == EPSILON:\n            new.add(w, (i, a, j))\n        else:\n            new.add(w, (i, a, j), b)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation of the grammar.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return string representation of the grammar.\"\"\"\n    return \"Grammar {\\n%s\\n}\" % \"\\n\".join(f\"  {r}\" for r in self)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.add","title":"<code>add(w, head, *body)</code>","text":"<p>Add a rule of the form w: head -&gt; body1, body2, ... body_k.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <p>The rule weight</p> required <code>head</code> <p>The left-hand side nonterminal</p> required <code>*body</code> <p>The right-hand side symbols</p> <code>()</code> <p>Returns:</p> Type Description <p>The added rule, or None if weight is zero</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def add(self, w, head, *body):\n    \"\"\"\n    Add a rule of the form w: head -&gt; body1, body2, ... body_k.\n\n    Args:\n        w: The rule weight\n        head: The left-hand side nonterminal\n        *body: The right-hand side symbols\n\n    Returns:\n        The added rule, or None if weight is zero\n    \"\"\"\n    if w == self.R.zero:\n        return  # skip rules with weight zero\n    self.N.add(head)\n    r = Rule(w, head, body)\n    self.rules.append(r)\n    return r\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.agenda","title":"<code>agenda(tol=1e-12, maxiter=100000)</code>","text":"<p>Agenda-based semi-naive evaluation for treesums.</p> <p>Parameters:</p> Name Type Description Default <code>tol</code> <p>Convergence tolerance</p> <code>1e-12</code> <code>maxiter</code> <p>Maximum iterations</p> <code>100000</code> <p>Returns:</p> Type Description <p>A chart containing the treesum weights</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def agenda(self, tol=1e-12, maxiter=100_000):\n    \"\"\"\n    Agenda-based semi-naive evaluation for treesums.\n\n    Args:\n        tol: Convergence tolerance\n        maxiter: Maximum iterations\n\n    Returns:\n        A chart containing the treesum weights\n    \"\"\"\n    old = self.R.chart()\n\n    # precompute the mapping from updates to where they need to go\n    routing = defaultdict(list)\n    for r in self:\n        for k in range(len(r.body)):\n            routing[r.body[k]].append((r, k))\n\n    deps = self.dependency_graph()\n    blocks = deps.blocks\n    bucket = deps.buckets\n\n    # helper function\n    def update(x, W):\n        change[bucket[x]][x] += W\n\n    change = defaultdict(self.R.chart)\n    for a in self.V:\n        update(a, self.R.one)\n\n    for r in self:\n        if len(r.body) == 0:\n            update(r.head, r.w)\n\n    b = len(blocks)\n    iteration = 0\n    while b &gt;= 0:\n        iteration += 1\n\n        # Move on to the next block\n        if len(change[b]) == 0 or iteration &gt; maxiter:\n            b -= 1\n            iteration = 0  # reset iteration number for the next bucket\n            continue\n\n        u, v = change[b].popitem()\n\n        new = old[u] + v\n\n        if self.R.metric(old[u], new) &lt;= tol:\n            continue\n\n        for r, k in routing[u]:\n            W = r.w\n            for j in range(len(r.body)):\n                if u == r.body[j]:\n                    if j &lt; k:\n                        W *= new\n                    elif j == k:\n                        W *= v\n                    else:\n                        W *= old[u]\n                else:\n                    W *= old[r.body[j]]\n\n            update(r.head, W)\n\n        old[u] = new\n\n    return old\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.assert_equal","title":"<code>assert_equal(other, verbose=False, throw=True)</code>","text":"<p>Assertion for the equality of self and other modulo rule reordering.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>The grammar to compare against</p> required <code>verbose</code> <p>If True, print differences</p> <code>False</code> <code>throw</code> <p>If True, raise AssertionError on inequality</p> <code>True</code> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If grammars are not equal and throw=True</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def assert_equal(self, other, verbose=False, throw=True):\n    \"\"\"\n    Assertion for the equality of self and other modulo rule reordering.\n\n    Args:\n        other: The grammar to compare against\n        verbose: If True, print differences\n        throw: If True, raise AssertionError on inequality\n\n    Raises:\n        AssertionError: If grammars are not equal and throw=True\n    \"\"\"\n    assert verbose or throw\n    if isinstance(other, str):\n        other = self.__class__.from_string(other, self.R)\n    if verbose:\n        # TODO: need to check the weights in the print out; we do it in the assertion\n        S = set(self.rules)\n        G = set(other.rules)\n        for r in sorted(S | G, key=str):\n            if r in S and r in G:\n                continue\n            # if r in S and r not in G: continue\n            # if r not in S and r in G: continue\n            print(\n                colors.mark(r in S),\n                # colors.mark(r in S and r in G),\n                colors.mark(r in G),\n                r,\n            )\n    assert not throw or Counter(self.rules) == Counter(other.rules), (\n        f\"\\n\\nhave=\\n{str(self)}\\nwant=\\n{str(other)}\"\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.binarize","title":"<code>binarize()</code>","text":"<p>Return an equivalent grammar with arity \u2264 2.</p> <p>Returns:</p> Type Description <p>A new CFG with binary rules</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def binarize(self):\n    \"\"\"\n    Return an equivalent grammar with arity \u2264 2.\n\n    Returns:\n        A new CFG with binary rules\n    \"\"\"\n    new = self.spawn()\n\n    stack = list(self)\n    while stack:\n        p = stack.pop()\n        if len(p.body) &lt;= 2:\n            new.add(p.w, p.head, *p.body)\n        else:\n            stack.extend(self._fold(p, [(0, 1)]))\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.cotrim","title":"<code>cotrim()</code>","text":"<p>Trim the grammar so that all nonterminals are generating.</p> <p>Returns:</p> Type Description <p>A new CFG with only generating nonterminals</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def cotrim(self):\n    \"\"\"\n    Trim the grammar so that all nonterminals are generating.\n\n    Returns:\n        A new CFG with only generating nonterminals\n    \"\"\"\n    return self.trim(bottomup_only=True)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.dependency_graph","title":"<code>dependency_graph()</code>","text":"<p>Head-to-body dependency graph of the rules of the grammar.</p> <p>Returns:</p> Type Description <p>A WeightedGraph representing dependencies between symbols</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def dependency_graph(self):\n    \"\"\"\n    Head-to-body dependency graph of the rules of the grammar.\n\n    Returns:\n        A WeightedGraph representing dependencies between symbols\n    \"\"\"\n    deps = WeightedGraph(Boolean)\n    for r in self:\n        for y in r.body:\n            deps[r.head, y] += Boolean.one\n    deps.N |= self.N\n    deps.N |= self.V\n    return deps\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.derivations","title":"<code>derivations(X, H)</code>","text":"<p>Enumerate derivations of symbol X with height &lt;= H.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The symbol to derive from (default: start symbol)</p> required <code>H</code> <p>Maximum derivation height</p> required <p>Yields:</p> Type Description <p>Derivation objects representing derivation trees</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def derivations(self, X, H):\n    \"\"\"\n    Enumerate derivations of symbol X with height &lt;= H.\n\n    Args:\n        X: The symbol to derive from (default: start symbol)\n        H: Maximum derivation height\n\n    Yields:\n        Derivation objects representing derivation trees\n    \"\"\"\n    if X is None:\n        X = self.S\n    if self.is_terminal(X):\n        yield X\n    elif H &lt;= 0:\n        return\n    else:\n        for r in self.rhs[X]:\n            for ys in self._derivations_list(r.body, H - 1):\n                yield Derivation(r, X, *ys)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.derivative","title":"<code>derivative(a, i=0)</code>","text":"<p>Return a grammar that generates the derivative with respect to <code>a</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def derivative(self, a, i=0):\n    \"Return a grammar that generates the derivative with respect to `a`.\"\n\n    def slash(x, y):\n        return Slash(x, y, i=i)\n\n    D = self.spawn(S=slash(self.S, a))\n    U = self.null_weight()\n    for r in self:\n        D.add(r.w, r.head, *r.body)\n        delta = self.R.one\n        for k, y in enumerate(r.body):\n            if slash(r.head, a) in self.N:\n                continue  # SKIP!\n            if self.is_terminal(y):\n                if y == a:\n                    D.add(delta * r.w, slash(r.head, a), *r.body[k + 1 :])\n            else:\n                D.add(\n                    delta * r.w,\n                    slash(r.head, a),\n                    slash(r.body[k], a),\n                    *r.body[k + 1 :],\n                )\n            delta *= U[y]\n    return D\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.derivatives","title":"<code>derivatives(s)</code>","text":"<p>Return the sequence of derivatives for each prefix of <code>s</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def derivatives(self, s):\n    \"Return the sequence of derivatives for each prefix of `s`.\"\n    M = len(s)\n    D = [self]\n    for m in range(M):\n        D.append(D[m].derivative(s[m]))\n    return D\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.from_string","title":"<code>from_string(string, semiring, comment='#', start='S', is_terminal=lambda x: not x[0].isupper())</code>  <code>classmethod</code>","text":"<p>Create a CFG from a string representation.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <p>The grammar rules as a string</p> required <code>semiring</code> <p>The semiring for rule weights</p> required <code>comment</code> <p>Comment character to ignore lines (default: '#')</p> <code>'#'</code> <code>start</code> <p>Start symbol (default: 'S')</p> <code>'S'</code> <code>is_terminal</code> <p>Function to identify terminal symbols (default: lowercase first letter)</p> <code>lambda x: not isupper()</code> <p>Returns:</p> Type Description <p>A new CFG instance</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>@classmethod\ndef from_string(\n    cls,\n    string,\n    semiring,\n    comment=\"#\",\n    start=\"S\",\n    is_terminal=lambda x: not x[0].isupper(),\n):\n    \"\"\"\n    Create a CFG from a string representation.\n\n    Args:\n        string: The grammar rules as a string\n        semiring: The semiring for rule weights\n        comment: Comment character to ignore lines (default: '#')\n        start: Start symbol (default: 'S')\n        is_terminal: Function to identify terminal symbols (default: lowercase first letter)\n\n    Returns:\n        A new CFG instance\n    \"\"\"\n    V = set()\n    cfg = cls(R=semiring, S=start, V=V)\n    string = string.replace(\"-&gt;\", \"\u2192\")  # synonym for the arrow\n    for line in string.split(\"\\n\"):\n        line = line.strip()\n        if not line or line.startswith(comment):\n            continue\n        try:\n            [(w, lhs, rhs)] = re.findall(r\"(.*):\\s*(\\S+)\\s*\u2192\\s*(.*)$\", line)\n            lhs = lhs.strip()\n            rhs = rhs.strip().split()\n            for x in rhs:\n                if is_terminal(x):\n                    V.add(x)\n            cfg.add(semiring.from_string(w), lhs, *rhs)\n        except ValueError:\n            raise ValueError(f\"bad input line:\\n{line}\")  # pylint: disable=W0707\n    return cfg\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.has_unary_cycle","title":"<code>has_unary_cycle()</code>","text":"<p>Check if the grammar has unary cycles.</p> <p>Returns:</p> Type Description <p>True if the grammar contains unary cycles</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def has_unary_cycle(self):\n    \"\"\"\n    Check if the grammar has unary cycles.\n\n    Returns:\n        True if the grammar contains unary cycles\n    \"\"\"\n    f = self._unary_graph().buckets\n    return any(\n        True for r in self if len(r.body) == 1 and f.get(r.head) == f.get(r.body[0])\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.in_cnf","title":"<code>in_cnf()</code>","text":"<p>Return true if the grammar is in CNF.</p> <p>Returns:</p> Type Description <p>True if grammar is in Chomsky Normal Form</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def in_cnf(self):\n    \"\"\"\n    Return true if the grammar is in CNF.\n\n    Returns:\n        True if grammar is in Chomsky Normal Form\n    \"\"\"\n    return len(list(self._find_invalid_cnf_rule())) == 0\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.is_nonterminal","title":"<code>is_nonterminal(X)</code>","text":"<p>Return True if X is a nonterminal symbol.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def is_nonterminal(self, X):\n    \"\"\"Return True if X is a nonterminal symbol.\"\"\"\n    return not self.is_terminal(X)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.is_terminal","title":"<code>is_terminal(x)</code>","text":"<p>Return True if x is a terminal symbol.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def is_terminal(self, x):\n    \"\"\"Return True if x is a terminal symbol.\"\"\"\n    return x in self.V\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.language","title":"<code>language(depth)</code>","text":"<p>Enumerate strings generated by this cfg by derivations up to the given depth.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <p>Maximum derivation depth to consider</p> required <p>Returns:</p> Type Description <p>A chart containing the weighted language up to the given depth</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def language(self, depth):\n    \"\"\"\n    Enumerate strings generated by this cfg by derivations up to the given depth.\n\n    Args:\n        depth: Maximum derivation depth to consider\n\n    Returns:\n        A chart containing the weighted language up to the given depth\n    \"\"\"\n    lang = self.R.chart()\n    for d in self.derivations(self.S, depth):\n        lang[d.Yield()] += d.weight()\n    return lang\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.map_values","title":"<code>map_values(f, R)</code>","text":"<p>Return a new grammar that is the result of applying f: self.R -&gt; R to each rule's weight.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Function to map weights</p> required <code>R</code> <p>New semiring for weights</p> required <p>Returns:</p> Type Description <p>A new CFG with mapped weights</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def map_values(self, f, R):\n    \"\"\"\n    Return a new grammar that is the result of applying f: self.R -&gt; R to each rule's weight.\n\n    Args:\n        f: Function to map weights\n        R: New semiring for weights\n\n    Returns:\n        A new CFG with mapped weights\n    \"\"\"\n    new = self.spawn(R=R)\n    for r in self:\n        new.add(f(r.w), r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.materialize","title":"<code>materialize(max_length)</code>","text":"<p>Return a <code>Chart</code> with this grammar's weighted language for strings \u2264 <code>max_length</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def materialize(self, max_length):\n    \"Return a `Chart` with this grammar's weighted language for strings \u2264 `max_length`.\"\n    return self.cnf.language(max_length).filter(lambda x: len(x) &lt;= max_length)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.naive_bottom_up","title":"<code>naive_bottom_up(*, tol=1e-12, timeout=100000)</code>","text":"<p>Naive bottom-up evaluation for treesums; better to use <code>agenda</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def naive_bottom_up(self, *, tol=1e-12, timeout=100_000):\n    \"Naive bottom-up evaluation for treesums; better to use `agenda`.\"\n\n    def _approx_equal(U, V):\n        return all((self.R.metric(U[X], V[X]) &lt;= tol) for X in self.N)\n\n    R = self.R\n    V = R.chart()\n    counter = 0\n    while counter &lt; timeout:\n        U = self._bottom_up_step(V)\n        if _approx_equal(U, V):\n            break\n        V = U\n        counter += 1\n    return V\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.null_weight","title":"<code>null_weight()</code>","text":"<p>Compute the map from nonterminal to total weight of generating the empty string.</p> <p>Returns:</p> Type Description <p>A dict mapping nonterminals to their null weights</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def null_weight(self):\n    \"\"\"\n    Compute the map from nonterminal to total weight of generating the empty string.\n\n    Returns:\n        A dict mapping nonterminals to their null weights\n    \"\"\"\n    ecfg = self.spawn(V=set())\n    for p in self:\n        if not any(self.is_terminal(y) for y in p.body):\n            ecfg.add(p.w, p.head, *p.body)\n    return ecfg.agenda()\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.null_weight_start","title":"<code>null_weight_start()</code>","text":"<p>Compute the null weight of the start symbol.</p> <p>Returns:</p> Type Description <p>The total weight of generating the empty string from the start symbol</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def null_weight_start(self):\n    \"\"\"\n    Compute the null weight of the start symbol.\n\n    Returns:\n        The total weight of generating the empty string from the start symbol\n    \"\"\"\n    return self.null_weight()[self.S]\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.nullaryremove","title":"<code>nullaryremove(binarize=True, trim=True, **kwargs)</code>","text":"<p>Return an equivalent grammar with no nullary rules except for one at the start symbol.</p> <p>Parameters:</p> Name Type Description Default <code>binarize</code> <p>If True, binarize the grammar first</p> <code>True</code> <code>trim</code> <p>If True, trim the resulting grammar</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to _push_null_weights</p> <code>{}</code> <p>Returns:</p> Type Description <p>A new CFG without nullary rules (except at start)</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def nullaryremove(self, binarize=True, trim=True, **kwargs):\n    \"\"\"\n    Return an equivalent grammar with no nullary rules except for one at the start symbol.\n\n    Args:\n        binarize: If True, binarize the grammar first\n        trim: If True, trim the resulting grammar\n        **kwargs: Additional arguments passed to _push_null_weights\n\n    Returns:\n        A new CFG without nullary rules (except at start)\n    \"\"\"\n    # A really wide rule can take a very long time because of the power set\n    # in this rule so it is really important to binarize.\n    if binarize:\n        self = self.binarize()  # pragma: no cover\n    self = self.separate_start()\n    tmp = self._push_null_weights(self.null_weight(), **kwargs)\n    return tmp.trim() if trim else tmp\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.prefix_weight","title":"<code>prefix_weight(xs)</code>","text":"<p>Total weight of all derivations that have <code>xs</code> as a prefix.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def prefix_weight(self, xs):\n    \"Total weight of all derivations that have `xs` as a prefix.\"\n    return self.prefix_grammar(xs)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.rename","title":"<code>rename(f)</code>","text":"<p>Return a new grammar that is the result of applying f to each nonterminal.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Function to rename nonterminals</p> required <p>Returns:</p> Type Description <p>A new CFG with renamed nonterminals</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def rename(self, f):\n    \"\"\"\n    Return a new grammar that is the result of applying f to each nonterminal.\n\n    Args:\n        f: Function to rename nonterminals\n\n    Returns:\n        A new CFG with renamed nonterminals\n    \"\"\"\n    new = self.spawn(S=f(self.S))\n    for r in self:\n        new.add(\n            r.w, f(r.head), *((y if self.is_terminal(y) else f(y) for y in r.body))\n        )\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.renumber","title":"<code>renumber()</code>","text":"<p>Rename nonterminals to integers.</p> <p>Returns:</p> Type Description <p>A new CFG with integer nonterminals</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def renumber(self):\n    \"\"\"\n    Rename nonterminals to integers.\n\n    Returns:\n        A new CFG with integer nonterminals\n    \"\"\"\n    i = Integerizer()\n    max_v = max((x for x in self.V if isinstance(x, int)), default=0)\n    return self.rename(lambda x: i(x) + max_v + 1)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.separate_start","title":"<code>separate_start()</code>","text":"<p>Ensure that the start symbol does not appear on the RHS of any rule.</p> <p>Returns:</p> Type Description <p>A new CFG with start symbol only on LHS</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def separate_start(self):\n    \"\"\"\n    Ensure that the start symbol does not appear on the RHS of any rule.\n\n    Returns:\n        A new CFG with start symbol only on LHS\n    \"\"\"\n    # create a new start symbol if the current one appears on the rhs of any existing rule\n    if self.S in {y for r in self for y in r.body}:\n        S = _gen_nt(self.S)\n        new = self.spawn(S=S)\n        # preterminal rules\n        new.add(self.R.one, S, self.S)\n        for r in self:\n            new.add(r.w, r.head, *r.body)\n        return new\n    else:\n        return self\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.separate_terminals","title":"<code>separate_terminals()</code>","text":"<p>Ensure that each terminal is produced by a preterminal rule.</p> <p>Returns:</p> Type Description <p>A new CFG with terminals only in preterminal rules</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def separate_terminals(self):\n    \"\"\"\n    Ensure that each terminal is produced by a preterminal rule.\n\n    Returns:\n        A new CFG with terminals only in preterminal rules\n    \"\"\"\n    one = self.R.one\n    new = self.spawn()\n\n    _preterminal = {}\n\n    def preterminal(x):\n        y = _preterminal.get(x)\n        if y is None:\n            y = new.add(one, _gen_nt(), x)\n            _preterminal[x] = y\n        return y\n\n    for r in self:\n        if len(r.body) == 1 and self.is_terminal(r.body[0]):\n            new.add(r.w, r.head, *r.body)\n        else:\n            new.add(\n                r.w,\n                r.head,\n                *(\n                    (preterminal(y).head if self.is_terminal(y) else y)\n                    for y in r.body\n                ),\n            )\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.spawn","title":"<code>spawn(*, R=None, S=None, V=None)</code>","text":"<p>Create an empty grammar with the same R, S, and V.</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <p>Optional new semiring</p> <code>None</code> <code>S</code> <p>Optional new start symbol</p> <code>None</code> <code>V</code> <p>Optional new vocabulary</p> <code>None</code> <p>Returns:</p> Type Description <p>A new empty CFG with specified parameters</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def spawn(self, *, R=None, S=None, V=None):\n    \"\"\"\n    Create an empty grammar with the same R, S, and V.\n\n    Args:\n        R: Optional new semiring\n        S: Optional new start symbol\n        V: Optional new vocabulary\n\n    Returns:\n        A new empty CFG with specified parameters\n    \"\"\"\n    return self.__class__(\n        R=self.R if R is None else R,\n        S=self.S if S is None else S,\n        V=set(self.V) if V is None else V,\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.to_bytes","title":"<code>to_bytes()</code>","text":"<p>Convert terminal symbols from strings to bytes representation.</p> <p>This method creates a new grammar where all terminal string symbols are converted to their UTF-8 byte representation. Non-terminal symbols are preserved as-is.</p> <p>Returns:</p> Name Type Description <code>CFG</code> <p>A new grammar with byte terminal symbols</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a terminal symbol is not a string</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def to_bytes(self):\n    \"\"\"Convert terminal symbols from strings to bytes representation.\n\n    This method creates a new grammar where all terminal string symbols are\n    converted to their UTF-8 byte representation. Non-terminal symbols are\n    preserved as-is.\n\n    Returns:\n        CFG: A new grammar with byte terminal symbols\n\n    Raises:\n        ValueError: If a terminal symbol is not a string\n    \"\"\"\n    new = self.spawn(S=self.S, R=self.R, V=set())\n\n    for r in self:\n        new_body = []\n        for x in r.body:\n            if self.is_terminal(x):\n                if not isinstance(x, str):\n                    raise ValueError(f\"unsupported terminal type: {type(x)}\")\n                bs = list(x.encode(\"utf-8\"))\n                for b in bs:\n                    new.V.add(b)\n                new_body.extend(bs)\n            else:\n                new_body.append(x)\n        new.add(r.w, r.head, *new_body)\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.treesum","title":"<code>treesum(**kwargs)</code>","text":"<p>Total weight of the start symbol.</p> <p>Returns:</p> Type Description <p>The total weight of all derivations from the start symbol</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def treesum(self, **kwargs):\n    \"\"\"\n    Total weight of the start symbol.\n\n    Returns:\n        The total weight of all derivations from the start symbol\n    \"\"\"\n    return self.agenda(**kwargs)[self.S]\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.trim","title":"<code>trim(bottomup_only=False)</code>","text":"<p>Return an equivalent grammar with no dead or useless nonterminals or rules.</p> <p>Parameters:</p> Name Type Description Default <code>bottomup_only</code> <p>If True, only remove non-generating nonterminals</p> <code>False</code> <p>Returns:</p> Type Description <p>A new trimmed CFG</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def trim(self, bottomup_only=False):\n    \"\"\"\n    Return an equivalent grammar with no dead or useless nonterminals or rules.\n\n    Args:\n        bottomup_only: If True, only remove non-generating nonterminals\n\n    Returns:\n        A new trimmed CFG\n    \"\"\"\n    if self._trim_cache[bottomup_only] is not None:\n        return self._trim_cache[bottomup_only]\n\n    C = set(self.V)\n    C.update(e.head for e in self.rules if len(e.body) == 0)\n\n    incoming = defaultdict(list)\n    outgoing = defaultdict(list)\n    for e in self:\n        incoming[e.head].append(e)\n        for b in e.body:\n            outgoing[b].append(e)\n\n    agenda = set(C)\n    while agenda:\n        x = agenda.pop()\n        for e in outgoing[x]:\n            if all((b in C) for b in e.body):\n                if e.head not in C:\n                    C.add(e.head)\n                    agenda.add(e.head)\n\n    if bottomup_only:\n        val = self._trim(C)\n        self._trim_cache[bottomup_only] = val\n        val._trim_cache[bottomup_only] = val\n        return val\n\n    T = {self.S}\n    agenda.update(T)\n    while agenda:\n        x = agenda.pop()\n        for e in incoming[x]:\n            # assert e.head in T\n            for b in e.body:\n                if b not in T and b in C:\n                    T.add(b)\n                    agenda.add(b)\n\n    val = self._trim(T)\n    self._trim_cache[bottomup_only] = val\n    val._trim_cache[bottomup_only] = val\n    return val\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.truncate_length","title":"<code>truncate_length(max_length)</code>","text":"<p>Transform this grammar so that it only generates strings with length \u2264 <code>max_length</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def truncate_length(self, max_length):\n    \"Transform this grammar so that it only generates strings with length \u2264 `max_length`.\"\n    from genlm.grammar import WFSA\n\n    m = WFSA(self.R)\n    m.add_I(0, self.R.one)\n    m.add_F(0, self.R.one)\n    for t in range(max_length):\n        for x in self.V:\n            m.add_arc(t, x, t + 1, self.R.one)\n        m.add_F(t + 1, self.R.one)\n    return self @ m\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.unarycycleremove","title":"<code>unarycycleremove(trim=True)</code>","text":"<p>Return an equivalent grammar with no unary cycles.</p> <p>Parameters:</p> Name Type Description Default <code>trim</code> <p>If True, trim the resulting grammar</p> <code>True</code> <p>Returns:</p> Type Description <p>A new CFG without unary cycles</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def unarycycleremove(self, trim=True):\n    \"\"\"\n    Return an equivalent grammar with no unary cycles.\n\n    Args:\n        trim: If True, trim the resulting grammar\n\n    Returns:\n        A new CFG without unary cycles\n    \"\"\"\n\n    def bot(x):\n        return x if x in acyclic else (x, \"bot\")\n\n    G = self._unary_graph()\n\n    new = self.spawn(S=self.S)\n\n    bucket = G.buckets\n\n    acyclic = set()\n    for nodes, _ in G.Blocks:\n        if len(nodes) == 1:\n            [X] = nodes\n            if G[X, X] == self.R.zero:\n                acyclic.add(X)\n\n    # run Lehmann's on each cylical SCC\n    for nodes, W in G.Blocks:\n        if len(nodes) == 1:\n            [X] = nodes\n            if X in acyclic:\n                continue\n\n        for X1, X2 in W:\n            new.add(W[X1, X2], X1, bot(X2))\n\n    for r in self:\n        if len(r.body) == 1 and bucket.get(r.body[0]) == bucket[r.head]:\n            continue\n        new.add(r.w, bot(r.head), *r.body)\n\n    # TODO: figure out how to ensure that the new grammar is trimmed by\n    # construction (assuming the input grammar was trim).\n    if trim:\n        new = new.trim()\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.unaryremove","title":"<code>unaryremove()</code>","text":"<p>Return an equivalent grammar with no unary rules.</p> <p>Returns:</p> Type Description <p>A new CFG without unary rules</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def unaryremove(self):\n    \"\"\"\n    Return an equivalent grammar with no unary rules.\n\n    Returns:\n        A new CFG without unary rules\n    \"\"\"\n    W = self._unary_graph().closure_scc_based()\n    # W = self._unary_graph().closure_reference()\n\n    new = self.spawn()\n    for r in self:\n        if len(r.body) == 1 and self.is_nonterminal(r.body[0]):\n            continue\n        for Y in self.N:\n            new.add(W[Y, r.head] * r.w, Y, *r.body)\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.CFG.unfold","title":"<code>unfold(i, k)</code>","text":"<p>Apply the unfolding transformation to rule i and subgoal k.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <p>Index of rule to unfold</p> required <code>k</code> <p>Index of subgoal in rule body</p> required <p>Returns:</p> Type Description <p>A new CFG with the rule unfolded</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def unfold(self, i, k):\n    \"\"\"\n    Apply the unfolding transformation to rule i and subgoal k.\n\n    Args:\n        i: Index of rule to unfold\n        k: Index of subgoal in rule body\n\n    Returns:\n        A new CFG with the rule unfolded\n    \"\"\"\n    assert isinstance(i, int) and isinstance(k, int)\n    s = self.rules[i]\n    assert self.is_nonterminal(s.body[k])\n\n    new = self.spawn()\n    for j, r in enumerate(self):\n        if j != i:\n            new.add(r.w, r.head, *r.body)\n\n    for r in self.rhs[s.body[k]]:\n        new.add(s.w * r.w, s.head, *s.body[:k], *r.body, *s.body[k + 1 :])\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.Derivation","title":"<code>Derivation</code>","text":"<p>A derivation tree in a context-free grammar.</p> <p>Attributes:</p> Name Type Description <code>r</code> <code>Rule</code> <p>The rule used at this node, or None</p> <code>x</code> <p>The symbol at this node</p> <code>ys</code> <p>Child nodes of the derivation</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>class Derivation:\n    \"\"\"A derivation tree in a context-free grammar.\n\n    Attributes:\n        r (Rule): The rule used at this node, or None\n        x: The symbol at this node\n        ys: Child nodes of the derivation\n    \"\"\"\n\n    def __init__(self, r, x, *ys):\n        \"\"\"Initialize a Derivation.\n\n        Args:\n            r (Rule): The rule used at this node, or None\n            x: The symbol at this node\n            *ys: Child nodes of the derivation\n        \"\"\"\n        assert isinstance(r, Rule) or r is None\n        self.r = r\n        self.x = x\n        self.ys = ys\n\n    def __hash__(self):\n        return hash((self.r, self.x, self.ys))\n\n    def __eq__(self, other):\n        return (self.r, self.x, self.ys) == (other.r, other.x, other.ys)\n\n    def __repr__(self):\n        open_p = colors.dark.white % \"(\"\n        close_p = colors.dark.white % \")\"\n        children = \" \".join(str(y) for y in self.ys)\n        return f\"{open_p}{self.x} {children}{close_p}\"\n\n    def weight(self):\n        \"\"\"Compute the weight of this derivation.\n\n        Returns:\n            The weight of this derivation, computed by multiplying the rule weight\n            with the weights of all child derivations.\n        \"\"\"\n        W = self.r.w\n        for y in self.ys:\n            if isinstance(y, Derivation):\n                W *= y.weight()\n        return W\n\n    def Yield(self):\n        \"\"\"Return the yield (terminal string) of this derivation.\n\n        Returns:\n            tuple: The sequence of terminal symbols at the leaves of this derivation tree.\n        \"\"\"\n        if isinstance(self, Derivation):\n            return tuple(w for y in self.ys for w in Derivation.Yield(y))\n        else:\n            return (self,)\n\n    def _repr_html_(self):\n        return self.to_nltk()._repr_svg_()\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.Derivation.Yield","title":"<code>Yield()</code>","text":"<p>Return the yield (terminal string) of this derivation.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <p>The sequence of terminal symbols at the leaves of this derivation tree.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def Yield(self):\n    \"\"\"Return the yield (terminal string) of this derivation.\n\n    Returns:\n        tuple: The sequence of terminal symbols at the leaves of this derivation tree.\n    \"\"\"\n    if isinstance(self, Derivation):\n        return tuple(w for y in self.ys for w in Derivation.Yield(y))\n    else:\n        return (self,)\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.Derivation.__init__","title":"<code>__init__(r, x, *ys)</code>","text":"<p>Initialize a Derivation.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>Rule</code> <p>The rule used at this node, or None</p> required <code>x</code> <p>The symbol at this node</p> required <code>*ys</code> <p>Child nodes of the derivation</p> <code>()</code> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __init__(self, r, x, *ys):\n    \"\"\"Initialize a Derivation.\n\n    Args:\n        r (Rule): The rule used at this node, or None\n        x: The symbol at this node\n        *ys: Child nodes of the derivation\n    \"\"\"\n    assert isinstance(r, Rule) or r is None\n    self.r = r\n    self.x = x\n    self.ys = ys\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.Derivation.weight","title":"<code>weight()</code>","text":"<p>Compute the weight of this derivation.</p> <p>Returns:</p> Type Description <p>The weight of this derivation, computed by multiplying the rule weight</p> <p>with the weights of all child derivations.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def weight(self):\n    \"\"\"Compute the weight of this derivation.\n\n    Returns:\n        The weight of this derivation, computed by multiplying the rule weight\n        with the weights of all child derivations.\n    \"\"\"\n    W = self.r.w\n    for y in self.ys:\n        if isinstance(y, Derivation):\n            W *= y.weight()\n    return W\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.Rule","title":"<code>Rule</code>","text":"<p>A weighted production rule in a context-free grammar.</p> <p>Attributes:</p> Name Type Description <code>w</code> <p>Weight of the rule</p> <code>head</code> <p>Left-hand side nonterminal symbol</p> <code>body</code> <p>Right-hand side sequence of symbols</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>class Rule:\n    \"\"\"A weighted production rule in a context-free grammar.\n\n    Attributes:\n        w: Weight of the rule\n        head: Left-hand side nonterminal symbol\n        body: Right-hand side sequence of symbols\n    \"\"\"\n\n    def __init__(self, w, head, body):\n        \"\"\"Initialize a Rule.\n\n        Args:\n            w: Weight of the rule\n            head: Left-hand side nonterminal symbol\n            body: Right-hand side sequence of symbols\n        \"\"\"\n        self.w = w\n        self.head = head\n        self.body = body\n        self._hash = hash((head, body))\n\n    def __eq__(self, other):\n        return (\n            isinstance(other, Rule)\n            and self.w == other.w\n            and self._hash == other._hash\n            and other.head == self.head\n            and other.body == self.body\n        )\n\n    def __hash__(self):\n        return self._hash\n\n    def __repr__(self):\n        return f\"{self.w}: {self.head} \u2192 {' '.join(map(str, self.body))}\"\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.Rule.__init__","title":"<code>__init__(w, head, body)</code>","text":"<p>Initialize a Rule.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <p>Weight of the rule</p> required <code>head</code> <p>Left-hand side nonterminal symbol</p> required <code>body</code> <p>Right-hand side sequence of symbols</p> required Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def __init__(self, w, head, body):\n    \"\"\"Initialize a Rule.\n\n    Args:\n        w: Weight of the rule\n        head: Left-hand side nonterminal symbol\n        body: Right-hand side sequence of symbols\n    \"\"\"\n    self.w = w\n    self.head = head\n    self.body = body\n    self._hash = hash((head, body))\n</code></pre>"},{"location":"reference/genlm/grammar/cfg/#genlm.grammar.cfg.prefix_transducer","title":"<code>prefix_transducer(R, V)</code>","text":"<p>Construct the prefix transducer over semiring <code>R</code> and alphabet <code>V</code>.</p> Source code in <code>genlm/grammar/cfg.py</code> <pre><code>def prefix_transducer(R, V):\n    \"Construct the prefix transducer over semiring `R` and alphabet `V`.\"\n    P = FST(R)\n    P.add_I(0, R.one)\n    P.add_I(1, R.one)\n    for x in V:\n        P.add_arc(0, (x, x), 0, R.one)\n        P.add_arc(0, (x, x), 1, R.one)\n        P.add_arc(1, (x, EPSILON), 1, R.one)\n    P.add_F(1, R.one)\n    return P\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/","title":"cfglm","text":"<p>Fast computation of the posterior distrubtion over the next word in a WCFG language model.</p>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.BoolCFGLM","title":"<code>BoolCFGLM</code>","text":"<p>               Bases: <code>LM</code></p> <p>Language model interface for Boolean-weighted CFGs.</p> <p>Uses Earley's algorithm or CKY for inference. The grammar is converted to use Boolean weights if needed, where positive weights become True and zero/negative weights become False.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use</p> required <code>alg</code> <code>str</code> <p>Parsing algorithm to use - either 'earley' or 'cky'</p> <code>'earley'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alg is not 'earley' or 'cky'</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>class BoolCFGLM(LM):\n    \"\"\"Language model interface for Boolean-weighted CFGs.\n\n    Uses Earley's algorithm or CKY for inference. The grammar is converted to use\n    Boolean weights if needed, where positive weights become True and zero/negative\n    weights become False.\n\n    Args:\n        cfg (CFG): The context-free grammar to use\n        alg (str): Parsing algorithm to use - either 'earley' or 'cky'\n\n    Raises:\n        ValueError: If alg is not 'earley' or 'cky'\n    \"\"\"\n\n    def __init__(self, cfg, alg=\"earley\"):\n        \"\"\"Initialize a BoolCFGLM.\n\n        Args:\n            cfg (CFG): The context-free grammar to use as the language model\n            alg (str): Parsing algorithm to use - either 'earley' or 'cky'\n\n        Raises:\n            ValueError: If alg is not 'earley' or 'cky'\n        \"\"\"\n        if EOS not in cfg.V:\n            cfg = add_EOS(cfg, eos=EOS)\n        if cfg.R != Boolean:\n            cfg = cfg.map_values(lambda x: Boolean(x &gt; 0), Boolean)\n        if alg == \"earley\":\n            from genlm.grammar.parse.earley import Earley\n\n            self.model = Earley(cfg.prefix_grammar)\n        elif alg == \"cky\":\n            from genlm.grammar.parse.cky import CKYLM\n\n            self.model = CKYLM(cfg)\n        else:\n            raise ValueError(f\"unrecognized option {alg}\")\n        super().__init__(eos=EOS, V=cfg.V)\n\n    def p_next(self, context):\n        \"\"\"Compute next token probabilities given a context.\n\n        Args:\n            context (sequence): The conditioning context\n\n        Returns:\n            (Float.chart): The next token weights\n\n        Raises:\n            AssertionError: If context contains out-of-vocabulary tokens\n        \"\"\"\n        assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n        p = self.model.next_token_weights(self.model.chart(context)).trim()\n        return Float.chart({w: 1 for w in p})\n\n    def __call__(self, context):\n        \"\"\"Check if a context is possible under this grammar.\n\n        Args:\n            context (sequence): The context to check\n\n        Returns:\n            (bool): True if the context has non-zero weight\n        \"\"\"\n        return float(super().__call__(context) &gt; 0)\n\n    def clear_cache(self):\n        \"\"\"Clear any cached computations.\"\"\"\n        self.model.clear_cache()\n\n    @classmethod\n    def from_string(cls, x, semiring=Boolean, **kwargs):\n        \"\"\"Create a BoolCFGLM from a string representation of a grammar.\n\n        Args:\n            x (str): The grammar string\n            semiring: The semiring for weights (default: Boolean)\n            **kwargs: Additional arguments passed to __init__\n\n        Returns:\n            (BoolCFGLM): A new language model\n        \"\"\"\n        return cls(CFG.from_string(x, semiring), **kwargs)\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.BoolCFGLM.__call__","title":"<code>__call__(context)</code>","text":"<p>Check if a context is possible under this grammar.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>sequence</code> <p>The context to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the context has non-zero weight</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def __call__(self, context):\n    \"\"\"Check if a context is possible under this grammar.\n\n    Args:\n        context (sequence): The context to check\n\n    Returns:\n        (bool): True if the context has non-zero weight\n    \"\"\"\n    return float(super().__call__(context) &gt; 0)\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.BoolCFGLM.__init__","title":"<code>__init__(cfg, alg='earley')</code>","text":"<p>Initialize a BoolCFGLM.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use as the language model</p> required <code>alg</code> <code>str</code> <p>Parsing algorithm to use - either 'earley' or 'cky'</p> <code>'earley'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If alg is not 'earley' or 'cky'</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def __init__(self, cfg, alg=\"earley\"):\n    \"\"\"Initialize a BoolCFGLM.\n\n    Args:\n        cfg (CFG): The context-free grammar to use as the language model\n        alg (str): Parsing algorithm to use - either 'earley' or 'cky'\n\n    Raises:\n        ValueError: If alg is not 'earley' or 'cky'\n    \"\"\"\n    if EOS not in cfg.V:\n        cfg = add_EOS(cfg, eos=EOS)\n    if cfg.R != Boolean:\n        cfg = cfg.map_values(lambda x: Boolean(x &gt; 0), Boolean)\n    if alg == \"earley\":\n        from genlm.grammar.parse.earley import Earley\n\n        self.model = Earley(cfg.prefix_grammar)\n    elif alg == \"cky\":\n        from genlm.grammar.parse.cky import CKYLM\n\n        self.model = CKYLM(cfg)\n    else:\n        raise ValueError(f\"unrecognized option {alg}\")\n    super().__init__(eos=EOS, V=cfg.V)\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.BoolCFGLM.clear_cache","title":"<code>clear_cache()</code>","text":"<p>Clear any cached computations.</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def clear_cache(self):\n    \"\"\"Clear any cached computations.\"\"\"\n    self.model.clear_cache()\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.BoolCFGLM.from_string","title":"<code>from_string(x, semiring=Boolean, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a BoolCFGLM from a string representation of a grammar.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The grammar string</p> required <code>semiring</code> <p>The semiring for weights (default: Boolean)</p> <code>Boolean</code> <code>**kwargs</code> <p>Additional arguments passed to init</p> <code>{}</code> <p>Returns:</p> Type Description <code>BoolCFGLM</code> <p>A new language model</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>@classmethod\ndef from_string(cls, x, semiring=Boolean, **kwargs):\n    \"\"\"Create a BoolCFGLM from a string representation of a grammar.\n\n    Args:\n        x (str): The grammar string\n        semiring: The semiring for weights (default: Boolean)\n        **kwargs: Additional arguments passed to __init__\n\n    Returns:\n        (BoolCFGLM): A new language model\n    \"\"\"\n    return cls(CFG.from_string(x, semiring), **kwargs)\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.BoolCFGLM.p_next","title":"<code>p_next(context)</code>","text":"<p>Compute next token probabilities given a context.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>sequence</code> <p>The conditioning context</p> required <p>Returns:</p> Type Description <code>chart</code> <p>The next token weights</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If context contains out-of-vocabulary tokens</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def p_next(self, context):\n    \"\"\"Compute next token probabilities given a context.\n\n    Args:\n        context (sequence): The conditioning context\n\n    Returns:\n        (Float.chart): The next token weights\n\n    Raises:\n        AssertionError: If context contains out-of-vocabulary tokens\n    \"\"\"\n    assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n    p = self.model.next_token_weights(self.model.chart(context)).trim()\n    return Float.chart({w: 1 for w in p})\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.add_EOS","title":"<code>add_EOS(cfg, eos=None)</code>","text":"<p>Add an end-of-sequence symbol to a CFG's language.</p> <p>Transforms the grammar to append the EOS symbol to every string it generates.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The input grammar</p> required <code>eos</code> <code>optional</code> <p>The end-of-sequence symbol to add. Defaults to \u25aa.</p> <code>None</code> <p>Returns:</p> Type Description <code>CFG</code> <p>A new grammar that generates strings ending in EOS</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If EOS is already in the grammar's vocabulary</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def add_EOS(cfg, eos=None):\n    \"\"\"Add an end-of-sequence symbol to a CFG's language.\n\n    Transforms the grammar to append the EOS symbol to every string it generates.\n\n    Args:\n        cfg (CFG): The input grammar\n        eos (optional): The end-of-sequence symbol to add. Defaults to \u25aa.\n\n    Returns:\n        (CFG): A new grammar that generates strings ending in EOS\n\n    Raises:\n        AssertionError: If EOS is already in the grammar's vocabulary\n\n    \"\"\"\n    S = _gen_nt(\"&lt;START&gt;\")\n    new = cfg.spawn(S=S)\n    eos = eos or EOS\n    assert eos not in cfg.V\n    new.V.add(eos)\n    new.add(cfg.R.one, S, cfg.S, eos)\n    for r in cfg:\n        new.add(r.w, r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/cfglm/#genlm.grammar.cfglm.locally_normalize","title":"<code>locally_normalize(self, **kwargs)</code>","text":"<p>Locally normalize the grammar's rule weights.</p> <p>Returns a transformed grammar where: 1. The total weight of rules with the same head symbol sums to one 2. Each derivation's weight is proportional to the original grammar    (differs only by a multiplicative normalization constant)</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments passed to self.agenda()</p> <code>{}</code> <p>Returns:</p> Type Description <code>CFG</code> <p>A new grammar with locally normalized weights</p> Source code in <code>genlm/grammar/cfglm.py</code> <pre><code>def locally_normalize(self, **kwargs):\n    \"\"\"Locally normalize the grammar's rule weights.\n\n    Returns a transformed grammar where:\n    1. The total weight of rules with the same head symbol sums to one\n    2. Each derivation's weight is proportional to the original grammar\n       (differs only by a multiplicative normalization constant)\n\n    Args:\n        **kwargs: Additional arguments passed to self.agenda()\n\n    Returns:\n        (CFG): A new grammar with locally normalized weights\n    \"\"\"\n    new = self.spawn()\n    Z = self.agenda(**kwargs)\n    for r in self:\n        if Z[r.head] == 0:\n            continue\n        new.add(r.w * Z.product(r.body) / Z[r.head], r.head, *r.body)\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/chart/","title":"chart","text":""},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart","title":"<code>Chart</code>","text":"<p>               Bases: <code>dict</code></p> <p>A weighted chart data structure that extends dict with semiring operations.</p> <p>The Chart class provides methods for semiring operations like addition and multiplication, as well as utilities for filtering, comparing, and manipulating weighted values.</p> <p>Attributes:</p> Name Type Description <code>semiring</code> <p>The semiring that defines the weight operations</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>class Chart(dict):\n    \"\"\"A weighted chart data structure that extends dict with semiring operations.\n\n    The Chart class provides methods for semiring operations like addition and multiplication,\n    as well as utilities for filtering, comparing, and manipulating weighted values.\n\n    Attributes:\n        semiring: The semiring that defines the weight operations\n    \"\"\"\n\n    def __init__(self, semiring, vals=()):\n        \"\"\"Initialize a Chart.\n\n        Args:\n            semiring: The semiring for weight operations\n            vals: Optional initial values for the chart\n        \"\"\"\n        self.semiring = semiring\n        super().__init__(vals)\n\n    def __missing__(self, k):\n        \"\"\"Return zero weight for missing keys.\"\"\"\n        return self.semiring.zero\n\n    def spawn(self):\n        \"\"\"Create a new empty Chart with the same semiring.\"\"\"\n        return Chart(self.semiring)\n\n    def __add__(self, other):\n        \"\"\"Add two charts element-wise.\n\n        Args:\n            other: Another Chart to add to this one\n\n        Returns:\n            A new Chart containing the element-wise sum\n        \"\"\"\n        new = self.spawn()\n        for k, v in self.items():\n            new[k] += v\n        for k, v in other.items():\n            new[k] += v\n        return new\n\n    def __mul__(self, other):\n        \"\"\"Multiply two charts element-wise.\n\n        Args:\n            other: Another Chart to multiply with this one\n\n        Returns:\n            A new Chart containing the element-wise product\n        \"\"\"\n        new = self.spawn()\n        for k in self:\n            v = self[k] * other[k]\n            if v == self.semiring.zero:\n                continue\n            new[k] += v\n        return new\n\n    def product(self, ks):\n        \"\"\"Compute the product of values for the given keys.\n\n        Args:\n            ks: Sequence of keys to multiply values for\n\n        Returns:\n            The product of values for the given keys\n        \"\"\"\n        v = self.semiring.one\n        for k in ks:\n            v *= self[k]\n        return v\n\n    def copy(self):\n        \"\"\"Create a shallow copy of this Chart.\"\"\"\n        return Chart(self.semiring, self)\n\n    def trim(self):\n        \"\"\"Return a new Chart with zero-weight entries removed.\"\"\"\n        return Chart(\n            self.semiring, {k: v for k, v in self.items() if v != self.semiring.zero}\n        )\n\n    def metric(self, other):\n        \"\"\"Compute the maximum distance between this Chart and another.\n\n        Args:\n            other: Another Chart to compare against\n\n        Returns:\n            The maximum semiring metric between corresponding values\n        \"\"\"\n        assert isinstance(other, Chart)\n        err = 0\n        for x in self.keys() | other.keys():\n            err = max(err, self.semiring.metric(self[x], other[x]))\n        return err\n\n    def _repr_html_(self):\n        \"\"\"Return HTML representation for Jupyter notebooks.\"\"\"\n        return (\n            '&lt;div style=\"font-family: Monospace;\"&gt;'\n            + format_table(self.trim().items(), headings=[\"key\", \"value\"])\n            + \"&lt;/div&gt;\"\n        )\n\n    def __repr__(self):\n        \"\"\"Return string representation, excluding zero weights.\"\"\"\n        return repr({k: v for k, v in self.items() if v != self.semiring.zero})\n\n    def __str__(self, style_value=lambda k, v: str(v)):\n        \"\"\"Return formatted string representation.\n\n        Args:\n            style_value: Optional function to format values\n\n        Returns:\n            Formatted string showing non-zero entries\n        \"\"\"\n\n        def key(k):\n            return -self.semiring.metric(self[k], self.semiring.zero)\n\n        return (\n            \"Chart {\\n\"\n            + \"\\n\".join(\n                f\"  {k!r}: {style_value(k, self[k])},\"\n                for k in sorted(self, key=key)\n                if self[k] != self.semiring.zero\n            )\n            + \"\\n}\"\n        )\n\n    def assert_equal(self, want, *, domain=None, tol=1e-5, verbose=False, throw=True):\n        \"\"\"Assert that this Chart equals another within tolerance.\n\n        Args:\n            want: The expected Chart or dict of values\n            domain: Optional set of keys to check\n            tol: Tolerance for floating point comparisons\n            verbose: Whether to print detailed comparison\n            throw: Whether to raise AssertionError on mismatch\n        \"\"\"\n        if not isinstance(want, Chart):\n            want = self.semiring.chart(want)\n        if domain is None:\n            domain = self.keys() | want.keys()\n        assert verbose or throw\n        errors = []\n        for x in domain:\n            if self.semiring.metric(self[x], want[x]) &lt;= tol:\n                if verbose:\n                    print(colors.mark(True), x, self[x])\n            else:\n                if verbose:\n                    print(colors.mark(False), x, self[x], want[x])\n                errors.append(x)\n        if throw:\n            for x in errors:\n                raise AssertionError(f\"{x}: {self[x]} {want[x]}\")\n\n    def argmax(self):\n        \"\"\"Return the key with maximum value.\"\"\"\n        return max(self, key=self.__getitem__)\n\n    def argmin(self):\n        \"\"\"Return the key with minimum value.\"\"\"\n        return min(self, key=self.__getitem__)\n\n    def top(self, k):\n        \"\"\"Return a new Chart with the k largest values.\n\n        Args:\n            k: Number of top values to keep\n\n        Returns:\n            A new Chart containing only the k largest values\n        \"\"\"\n        return Chart(\n            self.semiring,\n            {k: self[k] for k in sorted(self, key=self.__getitem__, reverse=True)[:k]},\n        )\n\n    def max(self):\n        \"\"\"Return the maximum value in the Chart.\"\"\"\n        return max(self.values())\n\n    def min(self):\n        \"\"\"Return the minimum value in the Chart.\"\"\"\n        return min(self.values())\n\n    def sum(self):\n        \"\"\"Return the sum of all values in the Chart.\"\"\"\n        return sum(self.values())\n\n    def sort(self, **kwargs):\n        \"\"\"Return a new Chart with entries sorted by key.\n\n        Args:\n            **kwargs: Arguments passed to sorted()\n\n        Returns:\n            A new Chart with sorted entries\n        \"\"\"\n        return self.semiring.chart((k, self[k]) for k in sorted(self, **kwargs))\n\n    def sort_descending(self):\n        \"\"\"Return a new Chart with entries sorted by decreasing value.\"\"\"\n        return self.semiring.chart(\n            (k, self[k]) for k in sorted(self, key=lambda k: -self[k])\n        )\n\n    def normalize(self):\n        \"\"\"Return a new Chart with values normalized to sum to 1.\"\"\"\n        Z = self.sum()\n        if Z == 0:\n            return self\n        return self.semiring.chart((k, v / Z) for k, v in self.items())\n\n    def filter(self, f):\n        \"\"\"Return a new Chart keeping only entries where f(key) is True.\n\n        Args:\n            f: Predicate function that takes a key and returns bool\n\n        Returns:\n            A new Chart containing only entries where f(key) is True\n        \"\"\"\n        return self.semiring.chart((k, v) for k, v in self.items() if f(k))\n\n    def project(self, f):\n        \"\"\"Apply a function to keys, summing weights when transformed keys overlap.\n\n        Args:\n            f: Function to transform keys\n\n        Returns:\n            A new Chart with transformed keys and summed weights\n        \"\"\"\n        out = self.semiring.chart()\n        for k, v in self.items():\n            out[f(k)] += v\n        return out\n\n    # TODO: the more general version of this method is join\n    def compare(self, other, *, domain=None):\n        \"\"\"Compare this Chart to another using pandas DataFrame.\n\n        Args:\n            other: Another Chart or dict to compare against\n            domain: Optional set of keys to compare\n\n        Returns:\n            pandas DataFrame showing key-by-key comparison\n        \"\"\"\n        import pandas as pd\n\n        if not isinstance(other, Chart):\n            other = self.semiring.chart(other)\n        if domain is None:\n            domain = self.keys() | other.keys()\n        rows = []\n        for x in domain:\n            m = self.semiring.metric(self[x], other[x])\n            rows.append(dict(key=x, self=self[x], other=other[x], metric=m))\n        return pd.DataFrame(rows)\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.__add__","title":"<code>__add__(other)</code>","text":"<p>Add two charts element-wise.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart to add to this one</p> required <p>Returns:</p> Type Description <p>A new Chart containing the element-wise sum</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __add__(self, other):\n    \"\"\"Add two charts element-wise.\n\n    Args:\n        other: Another Chart to add to this one\n\n    Returns:\n        A new Chart containing the element-wise sum\n    \"\"\"\n    new = self.spawn()\n    for k, v in self.items():\n        new[k] += v\n    for k, v in other.items():\n        new[k] += v\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.__init__","title":"<code>__init__(semiring, vals=())</code>","text":"<p>Initialize a Chart.</p> <p>Parameters:</p> Name Type Description Default <code>semiring</code> <p>The semiring for weight operations</p> required <code>vals</code> <p>Optional initial values for the chart</p> <code>()</code> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __init__(self, semiring, vals=()):\n    \"\"\"Initialize a Chart.\n\n    Args:\n        semiring: The semiring for weight operations\n        vals: Optional initial values for the chart\n    \"\"\"\n    self.semiring = semiring\n    super().__init__(vals)\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.__missing__","title":"<code>__missing__(k)</code>","text":"<p>Return zero weight for missing keys.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __missing__(self, k):\n    \"\"\"Return zero weight for missing keys.\"\"\"\n    return self.semiring.zero\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Multiply two charts element-wise.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart to multiply with this one</p> required <p>Returns:</p> Type Description <p>A new Chart containing the element-wise product</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __mul__(self, other):\n    \"\"\"Multiply two charts element-wise.\n\n    Args:\n        other: Another Chart to multiply with this one\n\n    Returns:\n        A new Chart containing the element-wise product\n    \"\"\"\n    new = self.spawn()\n    for k in self:\n        v = self[k] * other[k]\n        if v == self.semiring.zero:\n            continue\n        new[k] += v\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation, excluding zero weights.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return string representation, excluding zero weights.\"\"\"\n    return repr({k: v for k, v in self.items() if v != self.semiring.zero})\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.__str__","title":"<code>__str__(style_value=lambda k, v: str(v))</code>","text":"<p>Return formatted string representation.</p> <p>Parameters:</p> Name Type Description Default <code>style_value</code> <p>Optional function to format values</p> <code>lambda k, v: str(v)</code> <p>Returns:</p> Type Description <p>Formatted string showing non-zero entries</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def __str__(self, style_value=lambda k, v: str(v)):\n    \"\"\"Return formatted string representation.\n\n    Args:\n        style_value: Optional function to format values\n\n    Returns:\n        Formatted string showing non-zero entries\n    \"\"\"\n\n    def key(k):\n        return -self.semiring.metric(self[k], self.semiring.zero)\n\n    return (\n        \"Chart {\\n\"\n        + \"\\n\".join(\n            f\"  {k!r}: {style_value(k, self[k])},\"\n            for k in sorted(self, key=key)\n            if self[k] != self.semiring.zero\n        )\n        + \"\\n}\"\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.argmax","title":"<code>argmax()</code>","text":"<p>Return the key with maximum value.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def argmax(self):\n    \"\"\"Return the key with maximum value.\"\"\"\n    return max(self, key=self.__getitem__)\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.argmin","title":"<code>argmin()</code>","text":"<p>Return the key with minimum value.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def argmin(self):\n    \"\"\"Return the key with minimum value.\"\"\"\n    return min(self, key=self.__getitem__)\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.assert_equal","title":"<code>assert_equal(want, *, domain=None, tol=1e-05, verbose=False, throw=True)</code>","text":"<p>Assert that this Chart equals another within tolerance.</p> <p>Parameters:</p> Name Type Description Default <code>want</code> <p>The expected Chart or dict of values</p> required <code>domain</code> <p>Optional set of keys to check</p> <code>None</code> <code>tol</code> <p>Tolerance for floating point comparisons</p> <code>1e-05</code> <code>verbose</code> <p>Whether to print detailed comparison</p> <code>False</code> <code>throw</code> <p>Whether to raise AssertionError on mismatch</p> <code>True</code> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def assert_equal(self, want, *, domain=None, tol=1e-5, verbose=False, throw=True):\n    \"\"\"Assert that this Chart equals another within tolerance.\n\n    Args:\n        want: The expected Chart or dict of values\n        domain: Optional set of keys to check\n        tol: Tolerance for floating point comparisons\n        verbose: Whether to print detailed comparison\n        throw: Whether to raise AssertionError on mismatch\n    \"\"\"\n    if not isinstance(want, Chart):\n        want = self.semiring.chart(want)\n    if domain is None:\n        domain = self.keys() | want.keys()\n    assert verbose or throw\n    errors = []\n    for x in domain:\n        if self.semiring.metric(self[x], want[x]) &lt;= tol:\n            if verbose:\n                print(colors.mark(True), x, self[x])\n        else:\n            if verbose:\n                print(colors.mark(False), x, self[x], want[x])\n            errors.append(x)\n    if throw:\n        for x in errors:\n            raise AssertionError(f\"{x}: {self[x]} {want[x]}\")\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.compare","title":"<code>compare(other, *, domain=None)</code>","text":"<p>Compare this Chart to another using pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart or dict to compare against</p> required <code>domain</code> <p>Optional set of keys to compare</p> <code>None</code> <p>Returns:</p> Type Description <p>pandas DataFrame showing key-by-key comparison</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def compare(self, other, *, domain=None):\n    \"\"\"Compare this Chart to another using pandas DataFrame.\n\n    Args:\n        other: Another Chart or dict to compare against\n        domain: Optional set of keys to compare\n\n    Returns:\n        pandas DataFrame showing key-by-key comparison\n    \"\"\"\n    import pandas as pd\n\n    if not isinstance(other, Chart):\n        other = self.semiring.chart(other)\n    if domain is None:\n        domain = self.keys() | other.keys()\n    rows = []\n    for x in domain:\n        m = self.semiring.metric(self[x], other[x])\n        rows.append(dict(key=x, self=self[x], other=other[x], metric=m))\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.copy","title":"<code>copy()</code>","text":"<p>Create a shallow copy of this Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def copy(self):\n    \"\"\"Create a shallow copy of this Chart.\"\"\"\n    return Chart(self.semiring, self)\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.filter","title":"<code>filter(f)</code>","text":"<p>Return a new Chart keeping only entries where f(key) is True.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Predicate function that takes a key and returns bool</p> required <p>Returns:</p> Type Description <p>A new Chart containing only entries where f(key) is True</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def filter(self, f):\n    \"\"\"Return a new Chart keeping only entries where f(key) is True.\n\n    Args:\n        f: Predicate function that takes a key and returns bool\n\n    Returns:\n        A new Chart containing only entries where f(key) is True\n    \"\"\"\n    return self.semiring.chart((k, v) for k, v in self.items() if f(k))\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.max","title":"<code>max()</code>","text":"<p>Return the maximum value in the Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def max(self):\n    \"\"\"Return the maximum value in the Chart.\"\"\"\n    return max(self.values())\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.metric","title":"<code>metric(other)</code>","text":"<p>Compute the maximum distance between this Chart and another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another Chart to compare against</p> required <p>Returns:</p> Type Description <p>The maximum semiring metric between corresponding values</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def metric(self, other):\n    \"\"\"Compute the maximum distance between this Chart and another.\n\n    Args:\n        other: Another Chart to compare against\n\n    Returns:\n        The maximum semiring metric between corresponding values\n    \"\"\"\n    assert isinstance(other, Chart)\n    err = 0\n    for x in self.keys() | other.keys():\n        err = max(err, self.semiring.metric(self[x], other[x]))\n    return err\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.min","title":"<code>min()</code>","text":"<p>Return the minimum value in the Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def min(self):\n    \"\"\"Return the minimum value in the Chart.\"\"\"\n    return min(self.values())\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.normalize","title":"<code>normalize()</code>","text":"<p>Return a new Chart with values normalized to sum to 1.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def normalize(self):\n    \"\"\"Return a new Chart with values normalized to sum to 1.\"\"\"\n    Z = self.sum()\n    if Z == 0:\n        return self\n    return self.semiring.chart((k, v / Z) for k, v in self.items())\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.product","title":"<code>product(ks)</code>","text":"<p>Compute the product of values for the given keys.</p> <p>Parameters:</p> Name Type Description Default <code>ks</code> <p>Sequence of keys to multiply values for</p> required <p>Returns:</p> Type Description <p>The product of values for the given keys</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def product(self, ks):\n    \"\"\"Compute the product of values for the given keys.\n\n    Args:\n        ks: Sequence of keys to multiply values for\n\n    Returns:\n        The product of values for the given keys\n    \"\"\"\n    v = self.semiring.one\n    for k in ks:\n        v *= self[k]\n    return v\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.project","title":"<code>project(f)</code>","text":"<p>Apply a function to keys, summing weights when transformed keys overlap.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <p>Function to transform keys</p> required <p>Returns:</p> Type Description <p>A new Chart with transformed keys and summed weights</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def project(self, f):\n    \"\"\"Apply a function to keys, summing weights when transformed keys overlap.\n\n    Args:\n        f: Function to transform keys\n\n    Returns:\n        A new Chart with transformed keys and summed weights\n    \"\"\"\n    out = self.semiring.chart()\n    for k, v in self.items():\n        out[f(k)] += v\n    return out\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.sort","title":"<code>sort(**kwargs)</code>","text":"<p>Return a new Chart with entries sorted by key.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arguments passed to sorted()</p> <code>{}</code> <p>Returns:</p> Type Description <p>A new Chart with sorted entries</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def sort(self, **kwargs):\n    \"\"\"Return a new Chart with entries sorted by key.\n\n    Args:\n        **kwargs: Arguments passed to sorted()\n\n    Returns:\n        A new Chart with sorted entries\n    \"\"\"\n    return self.semiring.chart((k, self[k]) for k in sorted(self, **kwargs))\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.sort_descending","title":"<code>sort_descending()</code>","text":"<p>Return a new Chart with entries sorted by decreasing value.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def sort_descending(self):\n    \"\"\"Return a new Chart with entries sorted by decreasing value.\"\"\"\n    return self.semiring.chart(\n        (k, self[k]) for k in sorted(self, key=lambda k: -self[k])\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.spawn","title":"<code>spawn()</code>","text":"<p>Create a new empty Chart with the same semiring.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def spawn(self):\n    \"\"\"Create a new empty Chart with the same semiring.\"\"\"\n    return Chart(self.semiring)\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.sum","title":"<code>sum()</code>","text":"<p>Return the sum of all values in the Chart.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def sum(self):\n    \"\"\"Return the sum of all values in the Chart.\"\"\"\n    return sum(self.values())\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.top","title":"<code>top(k)</code>","text":"<p>Return a new Chart with the k largest values.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <p>Number of top values to keep</p> required <p>Returns:</p> Type Description <p>A new Chart containing only the k largest values</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def top(self, k):\n    \"\"\"Return a new Chart with the k largest values.\n\n    Args:\n        k: Number of top values to keep\n\n    Returns:\n        A new Chart containing only the k largest values\n    \"\"\"\n    return Chart(\n        self.semiring,\n        {k: self[k] for k in sorted(self, key=self.__getitem__, reverse=True)[:k]},\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/chart/#genlm.grammar.chart.Chart.trim","title":"<code>trim()</code>","text":"<p>Return a new Chart with zero-weight entries removed.</p> Source code in <code>genlm/grammar/chart.py</code> <pre><code>def trim(self):\n    \"\"\"Return a new Chart with zero-weight entries removed.\"\"\"\n    return Chart(\n        self.semiring, {k: v for k, v in self.items() if v != self.semiring.zero}\n    )\n</code></pre>"},{"location":"reference/genlm/grammar/fst/","title":"fst","text":""},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST","title":"<code>FST</code>","text":"<p>               Bases: <code>WFSA</code></p> <p>A weighted finite-state transducer that maps between two alphabets.</p> <p>A finite-state transducer (FST) extends a weighted finite-state automaton (WFSA) by having two alphabets - an input alphabet A and an output alphabet B. Each transition is labeled with a pair (a,b) where a is from A and b is from B.</p> <p>The FST defines a weighted relation between strings over A and strings over B.</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>class FST(WFSA):\n    \"\"\"A weighted finite-state transducer that maps between two alphabets.\n\n    A finite-state transducer (FST) extends a weighted finite-state automaton (WFSA)\n    by having two alphabets - an input alphabet A and an output alphabet B. Each transition\n    is labeled with a pair (a,b) where a is from A and b is from B.\n\n    The FST defines a weighted relation between strings over A and strings over B.\n    \"\"\"\n\n    def __init__(self, R):\n        \"\"\"Initialize an empty FST.\n\n        Args:\n            R: The semiring for transition weights\n        \"\"\"\n        super().__init__(R=R)\n\n        # alphabets\n        self.A = set()  # input alphabet\n        self.B = set()  # output alphabet\n\n    def add_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n        \"\"\"Add a weighted transition between states.\n\n        Args:\n            i: Source state\n            ab: Tuple (a,b) of input/output symbols, or EPSILON\n            j: Target state\n            w: Weight of the transition\n\n        Returns:\n            self\n        \"\"\"\n        if ab != EPSILON:\n            (a, b) = ab\n            self.A.add(a)\n            self.B.add(b)\n        return super().add_arc(i, ab, j, w)\n\n    def set_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n        \"\"\"Set the weight of a transition between states.\n\n        Args:\n            i: Source state\n            ab: Tuple (a,b) of input/output symbols, or EPSILON\n            j: Target state\n            w: New weight for the transition\n\n        Returns:\n            self\n        \"\"\"\n        if ab != EPSILON:\n            (a, b) = ab\n            self.A.add(a)\n            self.B.add(b)\n        return super().set_arc(i, ab, j, w)\n\n    def __call__(self, x, y):\n        \"\"\"Compute the weight of mapping input x to output y.\n\n        If x or y is None, returns a weighted language representing the cross section.\n\n        Args:\n            x: Input string or None\n            y: Output string or None\n\n        Returns:\n            Weight of mapping x to y, or a WFSA representing the cross section if x or y is None\n        \"\"\"\n        if x is not None and y is not None:\n            x = FST.from_string(x, self.R)\n            y = FST.from_string(y, self.R)\n            return (x @ self @ y).total_weight()\n\n        elif x is not None and y is None:\n            x = FST.from_string(x, self.R)\n            return (x @ self).project(1)\n\n        elif x is None and y is not None:\n            y = FST.from_string(y, self.R)\n            return (self @ y).project(0)\n\n        else:\n            return self\n\n    @classmethod\n    def from_string(cls, xs, R, w=None):\n        \"\"\"Create an FST that accepts only the given string with optional weight.\n\n        Args:\n            xs: Input string\n            R: Semiring for weights\n            w: Optional weight for the string\n\n        Returns:\n            An FST accepting only xs with weight w\n        \"\"\"\n        return cls.diag(WFSA.from_string(xs=xs, R=R, w=w))\n\n    @staticmethod\n    def from_pairs(pairs, R):\n        \"\"\"Create an FST accepting the given input-output string pairs.\n\n        Args:\n            pairs: List of (input_string, output_string) tuples\n            R: Semiring for weights\n\n        Returns:\n            An FST accepting the given string pairs with weight one\n        \"\"\"\n        p = FST(R)\n        p.add_I(0, R.one)\n        p.add_F(1, R.one)\n        for i, (xs, ys) in enumerate(pairs):\n            p.add_arc(0, EPSILON, (i, 0), R.one)\n            for j, (x, y) in enumerate(zip_longest(xs, ys, fillvalue=EPSILON)):\n                p.add_arc((i, j), (x, y), (i, j + 1), R.one)\n            p.add_arc((i, max(len(xs), len(ys))), EPSILON, 1, R.one)\n        return p\n\n    def project(self, axis):\n        \"\"\"Project the FST onto one of its components to create a WFSA.\n\n        Args:\n            axis: 0 for input projection, 1 for output projection\n\n        Returns:\n            A WFSA over the projected alphabet\n        \"\"\"\n        assert axis in [0, 1]\n        A = WFSA(R=self.R)\n        for i, (a, b), j, w in self.arcs():\n            if axis == 0:\n                A.add_arc(i, a, j, w)\n            else:\n                A.add_arc(i, b, j, w)\n        for i, w in self.I:\n            A.add_I(i, w)\n        for i, w in self.F:\n            A.add_F(i, w)\n        return A\n\n    @cached_property\n    def T(self):\n        \"\"\"Return the transpose of this FST by swapping input/output labels.\n\n        Returns:\n            A new FST with input/output labels swapped\n        \"\"\"\n        T = self.spawn()\n        for i, (a, b), j, w in self.arcs():\n            T.add_arc(i, (b, a), j, w)  # (a,b) -&gt; (b,a)\n        for q, w in self.I:\n            T.add_I(q, w)\n        for q, w in self.F:\n            T.add_F(q, w)\n        return T\n\n    def prune_to_alphabet(self, A, B):\n        \"\"\"Remove transitions with labels not in the given alphabets.\n\n        Args:\n            A: Set of allowed input symbols, or None to allow all\n            B: Set of allowed output symbols, or None to allow all\n\n        Returns:\n            A new FST with invalid transitions removed\n        \"\"\"\n        T = self.spawn()\n        for i, (a, b), j, w in self.arcs():\n            if (A is None or a in A) and (B is None or b in B):\n                T.add_arc(i, (a, b), j, w)\n        for q, w in self.I:\n            T.add_I(q, w)\n        for q, w in self.F:\n            T.add_F(q, w)\n        return T.trim\n\n    def __matmul__(self, other):\n        \"\"\"Compose this FST with another FST or automaton.\n\n        Args:\n            other: Another FST, CFG or automaton to compose with\n\n        Returns:\n            The composed FST\n        \"\"\"\n        if not isinstance(other, FST):\n            from genlm.grammar.cfg import CFG\n\n            if isinstance(other, CFG):\n                return other @ self.T\n            else:\n                other = FST.diag(other)\n\n        # minor efficiency trick: it's slightly more efficient to associate the composition as follows\n        if len(self.states) &lt; len(other.states):\n            return (\n                self._augment_epsilon_transitions(0)  # rename epsilons on the right\n                ._compose(\n                    epsilon_filter_fst(self.R, self.B), coarsen=False\n                )  # this FST carefully combines the special epsilons\n                ._compose(\n                    other._augment_epsilon_transitions(1)\n                )  # rename epsilons on th left\n            )\n\n        else:\n            return self._augment_epsilon_transitions(\n                0\n            )._compose(  # rename epsilons on the right\n                epsilon_filter_fst(\n                    self.R, self.B\n                )._compose(  # this FST carefully combines the special epsilons\n                    other._augment_epsilon_transitions(1), coarsen=False\n                )\n            )  # rename epsilons on th left\n\n    def _compose(self, other, coarsen=True):\n        \"\"\"Internal composition implementation with optional coarsening.\n\n        Args:\n            other: FST to compose with\n            coarsen: Whether to apply pruning/coarsening\n\n        Returns:\n            The composed FST\n        \"\"\"\n        if coarsen and FST.PRUNING is not None:\n            keep = FST.PRUNING(self, other)  # pylint: disable=E1102\n            result = self._pruned_compose(other, keep, keep.keep_arc)\n\n        else:\n            result = self._pruned_compose(\n                other, lambda x: True, lambda i, label, j: True\n            )\n\n        return result\n\n    # TODO: add assertions for the 'bad' epsilon cases to ensure users aren't using this method incorrectly.\n    def _pruned_compose(self, other, keep, keep_arc):\n        \"\"\"Implements pruned on-the-fly composition of FSTs.\n\n        Args:\n            other: FST to compose with\n            keep: Function that determines which states to keep\n            keep_arc: Function that determines which arcs to keep\n\n        Returns:\n            The composed FST with pruning applied\n        \"\"\"\n        C = FST(R=self.R)\n\n        # index arcs in `other` to so that they are fast against later\n        tmp = defaultdict(list)\n        for i, (a, b), j, w in other.arcs():\n            tmp[i, a].append((b, j, w))\n\n        visited = set()\n        stack = []\n\n        # add initial states\n        for P, w1 in self.I:\n            for Q, w2 in other.I:\n                PQ = (P, Q)\n\n                if not keep(PQ):\n                    continue\n\n                C.add_I(PQ, w1 * w2)\n                visited.add(PQ)\n                stack.append(PQ)\n\n        # traverse the machine using depth-first search\n        while stack:\n            P, Q = PQ = stack.pop()\n\n            # (q,p) is simultaneously a final state in the respective machines\n            if P in self.stop and Q in other.stop:\n                C.add_F(PQ, self.stop[P] * other.stop[Q])\n                # Note: final states are not necessarily absorbing -&gt; fall thru\n\n            # Arcs of the composition machine are given by a cross-product-like\n            # construction that matches an arc labeled `a:b` with an arc labeled\n            # `b:c` in the left and right machines respectively.\n            for (a, b), P\u02bc, w1 in self.arcs(P):\n                for c, Q\u02bc, w2 in tmp[Q, b]:\n                    assert b != EPSILON\n\n                    P\u02bcQ\u02bc = (P\u02bc, Q\u02bc)\n\n                    if not keep(P\u02bcQ\u02bc) or not keep_arc(PQ, (a, c), P\u02bcQ\u02bc):\n                        continue\n\n                    C.add_arc(PQ, (a, c), P\u02bcQ\u02bc, w1 * w2)\n\n                    if P\u02bcQ\u02bc not in visited:\n                        stack.append(P\u02bcQ\u02bc)\n                        visited.add(P\u02bcQ\u02bc)\n\n        return C\n\n    def _augment_epsilon_transitions(self, idx):\n        \"\"\"Augments the FST by changing the appropriate epsilon transitions to\n        epsilon_1 or epsilon_2 transitions to be able to perform the composition\n        correctly.  See Fig. 7 on p. 17 of Mohri, \"Weighted Automata Algorithms\".\n\n        Args:\n            idx: 0 if this is the first FST in composition, 1 if second\n\n        Returns:\n            FST with augmented epsilon transitions\n        \"\"\"\n        assert idx in [0, 1]\n\n        T = self.spawn(keep_init=True, keep_stop=True)\n\n        for i in self.states:\n            if idx == 0:\n                T.add_arc(i, (\u03b5, \u03b5_1), i, self.R.one)\n            else:\n                T.add_arc(i, (\u03b5_2, \u03b5), i, self.R.one)\n            for ab, j, w in self.arcs(i):\n                if idx == 0 and ab[1] == \u03b5:\n                    ab = (ab[0], \u03b5_2)\n                elif idx == 1 and ab[0] == \u03b5:\n                    ab = (\u03b5_1, ab[1])\n                T.add_arc(i, ab, j, w)\n\n        return T\n\n    @classmethod\n    def diag(cls, fsa):\n        \"\"\"Convert FSA to diagonal FST that maps strings to themselves.\n\n        Args:\n            fsa: Input FSA to convert\n\n        Returns:\n            FST that maps each string accepted by fsa to itself with same weight\n        \"\"\"\n        fst = cls(fsa.R)\n        for i, a, j, w in fsa.arcs():\n            fst.add_arc(i, (a, a), j, w)\n        for i, w in fsa.I:\n            fst.add_I(i, w)\n        for i, w in fsa.F:\n            fst.add_F(i, w)\n        return fst\n\n    def coarsen(self, N, A, B):\n        \"\"\"Create coarsened Boolean FST by mapping states and symbols.\n\n        Args:\n            N: Function mapping states to coarsened states\n            A: Function mapping input symbols to coarsened input symbols\n            B: Function mapping output symbols to coarsened output symbols\n\n        Returns:\n            Coarsened Boolean FST\n        \"\"\"\n        m = FST(Boolean)\n        for i in self.start:\n            m.add_I(N(i), Boolean.one)\n        for i in self.stop:\n            m.add_F(N(i), Boolean.one)\n        for i, (a, b), j, _ in self.arcs():\n            m.add_arc(N(i), (A(a), B(b)), N(j), Boolean.one)\n        return m\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.T","title":"<code>T</code>  <code>cached</code> <code>property</code>","text":"<p>Return the transpose of this FST by swapping input/output labels.</p> <p>Returns:</p> Type Description <p>A new FST with input/output labels swapped</p>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.__call__","title":"<code>__call__(x, y)</code>","text":"<p>Compute the weight of mapping input x to output y.</p> <p>If x or y is None, returns a weighted language representing the cross section.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Input string or None</p> required <code>y</code> <p>Output string or None</p> required <p>Returns:</p> Type Description <p>Weight of mapping x to y, or a WFSA representing the cross section if x or y is None</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def __call__(self, x, y):\n    \"\"\"Compute the weight of mapping input x to output y.\n\n    If x or y is None, returns a weighted language representing the cross section.\n\n    Args:\n        x: Input string or None\n        y: Output string or None\n\n    Returns:\n        Weight of mapping x to y, or a WFSA representing the cross section if x or y is None\n    \"\"\"\n    if x is not None and y is not None:\n        x = FST.from_string(x, self.R)\n        y = FST.from_string(y, self.R)\n        return (x @ self @ y).total_weight()\n\n    elif x is not None and y is None:\n        x = FST.from_string(x, self.R)\n        return (x @ self).project(1)\n\n    elif x is None and y is not None:\n        y = FST.from_string(y, self.R)\n        return (self @ y).project(0)\n\n    else:\n        return self\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.__init__","title":"<code>__init__(R)</code>","text":"<p>Initialize an empty FST.</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <p>The semiring for transition weights</p> required Source code in <code>genlm/grammar/fst.py</code> <pre><code>def __init__(self, R):\n    \"\"\"Initialize an empty FST.\n\n    Args:\n        R: The semiring for transition weights\n    \"\"\"\n    super().__init__(R=R)\n\n    # alphabets\n    self.A = set()  # input alphabet\n    self.B = set()  # output alphabet\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Compose this FST with another FST or automaton.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another FST, CFG or automaton to compose with</p> required <p>Returns:</p> Type Description <p>The composed FST</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def __matmul__(self, other):\n    \"\"\"Compose this FST with another FST or automaton.\n\n    Args:\n        other: Another FST, CFG or automaton to compose with\n\n    Returns:\n        The composed FST\n    \"\"\"\n    if not isinstance(other, FST):\n        from genlm.grammar.cfg import CFG\n\n        if isinstance(other, CFG):\n            return other @ self.T\n        else:\n            other = FST.diag(other)\n\n    # minor efficiency trick: it's slightly more efficient to associate the composition as follows\n    if len(self.states) &lt; len(other.states):\n        return (\n            self._augment_epsilon_transitions(0)  # rename epsilons on the right\n            ._compose(\n                epsilon_filter_fst(self.R, self.B), coarsen=False\n            )  # this FST carefully combines the special epsilons\n            ._compose(\n                other._augment_epsilon_transitions(1)\n            )  # rename epsilons on th left\n        )\n\n    else:\n        return self._augment_epsilon_transitions(\n            0\n        )._compose(  # rename epsilons on the right\n            epsilon_filter_fst(\n                self.R, self.B\n            )._compose(  # this FST carefully combines the special epsilons\n                other._augment_epsilon_transitions(1), coarsen=False\n            )\n        )  # rename epsilons on th left\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.add_arc","title":"<code>add_arc(i, ab, j, w)</code>","text":"<p>Add a weighted transition between states.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <p>Source state</p> required <code>ab</code> <p>Tuple (a,b) of input/output symbols, or EPSILON</p> required <code>j</code> <p>Target state</p> required <code>w</code> <p>Weight of the transition</p> required <p>Returns:</p> Type Description <p>self</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def add_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n    \"\"\"Add a weighted transition between states.\n\n    Args:\n        i: Source state\n        ab: Tuple (a,b) of input/output symbols, or EPSILON\n        j: Target state\n        w: Weight of the transition\n\n    Returns:\n        self\n    \"\"\"\n    if ab != EPSILON:\n        (a, b) = ab\n        self.A.add(a)\n        self.B.add(b)\n    return super().add_arc(i, ab, j, w)\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.coarsen","title":"<code>coarsen(N, A, B)</code>","text":"<p>Create coarsened Boolean FST by mapping states and symbols.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <p>Function mapping states to coarsened states</p> required <code>A</code> <p>Function mapping input symbols to coarsened input symbols</p> required <code>B</code> <p>Function mapping output symbols to coarsened output symbols</p> required <p>Returns:</p> Type Description <p>Coarsened Boolean FST</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def coarsen(self, N, A, B):\n    \"\"\"Create coarsened Boolean FST by mapping states and symbols.\n\n    Args:\n        N: Function mapping states to coarsened states\n        A: Function mapping input symbols to coarsened input symbols\n        B: Function mapping output symbols to coarsened output symbols\n\n    Returns:\n        Coarsened Boolean FST\n    \"\"\"\n    m = FST(Boolean)\n    for i in self.start:\n        m.add_I(N(i), Boolean.one)\n    for i in self.stop:\n        m.add_F(N(i), Boolean.one)\n    for i, (a, b), j, _ in self.arcs():\n        m.add_arc(N(i), (A(a), B(b)), N(j), Boolean.one)\n    return m\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.diag","title":"<code>diag(fsa)</code>  <code>classmethod</code>","text":"<p>Convert FSA to diagonal FST that maps strings to themselves.</p> <p>Parameters:</p> Name Type Description Default <code>fsa</code> <p>Input FSA to convert</p> required <p>Returns:</p> Type Description <p>FST that maps each string accepted by fsa to itself with same weight</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>@classmethod\ndef diag(cls, fsa):\n    \"\"\"Convert FSA to diagonal FST that maps strings to themselves.\n\n    Args:\n        fsa: Input FSA to convert\n\n    Returns:\n        FST that maps each string accepted by fsa to itself with same weight\n    \"\"\"\n    fst = cls(fsa.R)\n    for i, a, j, w in fsa.arcs():\n        fst.add_arc(i, (a, a), j, w)\n    for i, w in fsa.I:\n        fst.add_I(i, w)\n    for i, w in fsa.F:\n        fst.add_F(i, w)\n    return fst\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.from_pairs","title":"<code>from_pairs(pairs, R)</code>  <code>staticmethod</code>","text":"<p>Create an FST accepting the given input-output string pairs.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <p>List of (input_string, output_string) tuples</p> required <code>R</code> <p>Semiring for weights</p> required <p>Returns:</p> Type Description <p>An FST accepting the given string pairs with weight one</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>@staticmethod\ndef from_pairs(pairs, R):\n    \"\"\"Create an FST accepting the given input-output string pairs.\n\n    Args:\n        pairs: List of (input_string, output_string) tuples\n        R: Semiring for weights\n\n    Returns:\n        An FST accepting the given string pairs with weight one\n    \"\"\"\n    p = FST(R)\n    p.add_I(0, R.one)\n    p.add_F(1, R.one)\n    for i, (xs, ys) in enumerate(pairs):\n        p.add_arc(0, EPSILON, (i, 0), R.one)\n        for j, (x, y) in enumerate(zip_longest(xs, ys, fillvalue=EPSILON)):\n            p.add_arc((i, j), (x, y), (i, j + 1), R.one)\n        p.add_arc((i, max(len(xs), len(ys))), EPSILON, 1, R.one)\n    return p\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.from_string","title":"<code>from_string(xs, R, w=None)</code>  <code>classmethod</code>","text":"<p>Create an FST that accepts only the given string with optional weight.</p> <p>Parameters:</p> Name Type Description Default <code>xs</code> <p>Input string</p> required <code>R</code> <p>Semiring for weights</p> required <code>w</code> <p>Optional weight for the string</p> <code>None</code> <p>Returns:</p> Type Description <p>An FST accepting only xs with weight w</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>@classmethod\ndef from_string(cls, xs, R, w=None):\n    \"\"\"Create an FST that accepts only the given string with optional weight.\n\n    Args:\n        xs: Input string\n        R: Semiring for weights\n        w: Optional weight for the string\n\n    Returns:\n        An FST accepting only xs with weight w\n    \"\"\"\n    return cls.diag(WFSA.from_string(xs=xs, R=R, w=w))\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.project","title":"<code>project(axis)</code>","text":"<p>Project the FST onto one of its components to create a WFSA.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>0 for input projection, 1 for output projection</p> required <p>Returns:</p> Type Description <p>A WFSA over the projected alphabet</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def project(self, axis):\n    \"\"\"Project the FST onto one of its components to create a WFSA.\n\n    Args:\n        axis: 0 for input projection, 1 for output projection\n\n    Returns:\n        A WFSA over the projected alphabet\n    \"\"\"\n    assert axis in [0, 1]\n    A = WFSA(R=self.R)\n    for i, (a, b), j, w in self.arcs():\n        if axis == 0:\n            A.add_arc(i, a, j, w)\n        else:\n            A.add_arc(i, b, j, w)\n    for i, w in self.I:\n        A.add_I(i, w)\n    for i, w in self.F:\n        A.add_F(i, w)\n    return A\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.prune_to_alphabet","title":"<code>prune_to_alphabet(A, B)</code>","text":"<p>Remove transitions with labels not in the given alphabets.</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <p>Set of allowed input symbols, or None to allow all</p> required <code>B</code> <p>Set of allowed output symbols, or None to allow all</p> required <p>Returns:</p> Type Description <p>A new FST with invalid transitions removed</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def prune_to_alphabet(self, A, B):\n    \"\"\"Remove transitions with labels not in the given alphabets.\n\n    Args:\n        A: Set of allowed input symbols, or None to allow all\n        B: Set of allowed output symbols, or None to allow all\n\n    Returns:\n        A new FST with invalid transitions removed\n    \"\"\"\n    T = self.spawn()\n    for i, (a, b), j, w in self.arcs():\n        if (A is None or a in A) and (B is None or b in B):\n            T.add_arc(i, (a, b), j, w)\n    for q, w in self.I:\n        T.add_I(q, w)\n    for q, w in self.F:\n        T.add_F(q, w)\n    return T.trim\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.FST.set_arc","title":"<code>set_arc(i, ab, j, w)</code>","text":"<p>Set the weight of a transition between states.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <p>Source state</p> required <code>ab</code> <p>Tuple (a,b) of input/output symbols, or EPSILON</p> required <code>j</code> <p>Target state</p> required <code>w</code> <p>New weight for the transition</p> required <p>Returns:</p> Type Description <p>self</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def set_arc(self, i, ab, j, w):  # pylint: disable=arguments-renamed\n    \"\"\"Set the weight of a transition between states.\n\n    Args:\n        i: Source state\n        ab: Tuple (a,b) of input/output symbols, or EPSILON\n        j: Target state\n        w: New weight for the transition\n\n    Returns:\n        self\n    \"\"\"\n    if ab != EPSILON:\n        (a, b) = ab\n        self.A.add(a)\n        self.B.add(b)\n    return super().set_arc(i, ab, j, w)\n</code></pre>"},{"location":"reference/genlm/grammar/fst/#genlm.grammar.fst.epsilon_filter_fst","title":"<code>epsilon_filter_fst(R, Sigma)</code>","text":"<p>Create epsilon filter FST for composition.</p> <p>Creates a 3-state FST that handles epsilon transitions correctly during composition by filtering invalid epsilon paths.</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <p>Semiring for weights</p> required <code>Sigma</code> <p>Alphabet of non-epsilon symbols</p> required <p>Returns:</p> Type Description <p>Epsilon filter FST</p> Source code in <code>genlm/grammar/fst.py</code> <pre><code>def epsilon_filter_fst(R, Sigma):\n    \"\"\"Create epsilon filter FST for composition.\n\n    Creates a 3-state FST that handles epsilon transitions correctly during\n    composition by filtering invalid epsilon paths.\n\n    Args:\n        R: Semiring for weights\n        Sigma: Alphabet of non-epsilon symbols\n\n    Returns:\n        Epsilon filter FST\n    \"\"\"\n    F = FST(R)\n\n    F.add_I(0, R.one)\n\n    for a in Sigma:\n        F.add_arc(0, (a, a), 0, R.one)\n        F.add_arc(1, (a, a), 0, R.one)\n        F.add_arc(2, (a, a), 0, R.one)\n\n    F.add_arc(0, (\u03b5_2, \u03b5_1), 0, R.one)\n    F.add_arc(0, (\u03b5_1, \u03b5_1), 1, R.one)\n    F.add_arc(0, (\u03b5_2, \u03b5_2), 2, R.one)\n\n    F.add_arc(1, (\u03b5_1, \u03b5_1), 1, R.one)\n    F.add_arc(2, (\u03b5_2, \u03b5_2), 2, R.one)\n\n    F.add_F(0, R.one)\n    F.add_F(1, R.one)\n    F.add_F(2, R.one)\n\n    return F\n</code></pre>"},{"location":"reference/genlm/grammar/lark_interface/","title":"lark_interface","text":""},{"location":"reference/genlm/grammar/lark_interface/#genlm.grammar.lark_interface.LarkStuff","title":"<code>LarkStuff</code>","text":"<p>Utility class for leveraging lark as a front-end syntax for specifying grammars.</p> <p>This class provides functionality to convert Lark grammars into genlm_grammar format, handling various features and edge cases in the conversion process.</p> <p>Attributes:</p> Name Type Description <code>raw_grammar</code> <p>The original Lark grammar string</p> <code>terminals</code> <p>Terminal symbols from the Lark grammar</p> <code>ignore_terms</code> <p>Terms marked with 'ignore' directive in Lark</p> <code>rules</code> <p>Grammar production rules</p> Warning <p>The tokenization semantics may differ from Lark since prioritized/maximum-munch tokenization is not preserved when encoding into the grammar.</p> Note <p>Several features require careful handling in the conversion:</p> <ul> <li> <p>The 'ignore' directive is implemented by concatenating terminal regexes with   an optional prefix containing ignore terms. This preserves semantics but uses   a different implementation.</p> </li> <li> <p>When compiling terminal regexes to Python re syntax, some features may not be   fully supported by the interegular library.</p> </li> <li> <p>Implementations of '.' and '^' use negated character classes relative to   string.printable. Other edge cases may exist, particularly with lookahead/lookbehind.</p> </li> </ul> Source code in <code>genlm/grammar/lark_interface.py</code> <pre><code>class LarkStuff:\n    \"\"\"Utility class for leveraging lark as a front-end syntax for specifying grammars.\n\n    This class provides functionality to convert Lark grammars into genlm_grammar format,\n    handling various features and edge cases in the conversion process.\n\n    Attributes:\n        raw_grammar: The original Lark grammar string\n        terminals: Terminal symbols from the Lark grammar\n        ignore_terms: Terms marked with 'ignore' directive in Lark\n        rules: Grammar production rules\n\n    Warning:\n        The tokenization semantics may differ from Lark since prioritized/maximum-munch\n        tokenization is not preserved when encoding into the grammar.\n\n    Note:\n        Several features require careful handling in the conversion:\n\n        - The 'ignore' directive is implemented by concatenating terminal regexes with\n          an optional prefix containing ignore terms. This preserves semantics but uses\n          a different implementation.\n\n        - When compiling terminal regexes to Python re syntax, some features may not be\n          fully supported by the interegular library.\n\n        - Implementations of '.' and '^' use negated character classes relative to\n          string.printable. Other edge cases may exist, particularly with lookahead/lookbehind.\n    \"\"\"\n\n    __slots__ = (\n        \"raw_grammar\",\n        \"terminals\",\n        \"ignore_terms\",\n        \"rules\",\n    )\n\n    def __init__(self, grammar, cnf=False):\n        \"\"\"Initialize a LarkStuff instance.\n\n        Args:\n            grammar: A Lark grammar string\n            cnf: Whether to convert grammar to Chomsky Normal Form\n\n        Raises:\n            ValueError: If grammar does not define a 'start' rule\n        \"\"\"\n        self.raw_grammar = grammar\n\n        builder = lark.load_grammar.GrammarBuilder()\n        builder.load_grammar(grammar)\n        lark_grammar = builder.build()\n\n        if not any(\n            rule.value == \"start\"\n            for rule in lark_grammar.rule_defs[0]\n            if isinstance(rule, lark.lexer.Token)\n        ):\n            raise ValueError(\"Grammar must define a `start` rule\")\n\n        terminals, rules, ignores = lark_grammar.compile([\"start\"], set())\n\n        if cnf:\n            parser = lark.parsers.cyk.Parser(rules)\n            self.rules = parser.grammar.rules\n        else:\n            self.rules = rules\n\n        self.terminals = terminals\n        self.ignore_terms = ignores\n\n    def convert(self):\n        \"\"\"Convert the Lark grammar into a genlm_grammar.CFG grammar.\n\n        Returns:\n            CFG: A context-free grammar in genlm_grammar format with renumbered states\n        \"\"\"\n        try:\n            rules = [\n                Rule(1, r.lhs.name, tuple(y.name for y in r.rhs)) for r in self.rules\n            ]\n        except AttributeError:\n            rules = [\n                Rule(1, r.origin.name, tuple(y.name for y in r.expansion))\n                for r in self.rules\n            ]\n\n        lhs_count = Counter([r.head for r in rules])\n        cfg = CFG(R=Float, S=\"start\", V={t.name for t in self.terminals})\n        for r in rules:\n            cfg.add(1 / lhs_count[r.head], r.head, *r.body)\n        return cfg.renumber()\n\n    def char_cfg(self, *args, **kwargs):\n        return self._char_cfg(*args, **kwargs, to_bytes=False)\n\n    def byte_cfg(self, *args, **kwargs):\n        return self._char_cfg(*args, **kwargs, to_bytes=True)\n\n    def _char_cfg(\n        self, decay=1, delimiter=\"\", charset=\"core\", recursion=\"right\", to_bytes=False\n    ):\n        \"\"\"Convert to a character- or byte-level CFG with optional ignore patterns.\n\n        Args:\n            decay: Weight decay factor for rules\n            delimiter: Delimiter between tokens (not currently supported)\n            charset: Character set to use ('core' or custom set)\n            recursion: Direction of recursion ('right' or 'left')\n            to_bytes: Whether to convert to a byte-level CFG\n\n        Returns:\n            CFG: A character- or byte-level context-free grammar\n\n        Raises:\n            NotImplementedError: If delimiter is non-empty\n        \"\"\"\n        if delimiter != \"\":\n            raise NotImplementedError(f\"{delimiter = !r} is not supported.\")\n\n        cfg = self.convert()\n\n        # rename all of the internals to avoid naming conflicts.\n        _f = arsenal.Integerizer()\n\n        def f(x):\n            return f\"N{_f(x)}\"\n\n        foo = CFG(Float, S=f(cfg.S), V=set())\n        for r in cfg:\n            foo.add(r.w * decay, f(r.head), *(f(y) for y in r.body))\n        del r\n\n        if self.ignore_terms:\n            # union of ignore patterns\n            IGNORE = \"$IGNORE\"\n            assert IGNORE not in cfg.V\n            ignore = f(IGNORE)\n            foo.add(decay, ignore)\n            for token_class in self.terminals:\n                if token_class.name not in self.ignore_terms:\n                    continue\n                foo.add(decay, ignore, f(token_class.name))\n\n        for token_class in self.terminals:\n            regex = token_class.pattern.to_regexp()\n\n            fsa = interegular_to_wfsa(\n                regex,\n                name=lambda x, t=token_class.name: f((t, x)),\n                charset=charset,\n            )\n\n            if to_bytes:\n                fsa = fsa.to_bytes()\n\n            if token_class.name in self.ignore_terms or not self.ignore_terms:\n                G = fsa.to_cfg(S=f(token_class.name), recursion=recursion)\n\n                foo.V |= G.V\n                for r in G:\n                    foo.add(r.w * decay, r.head, *r.body)\n\n            else:\n                tmp = f((\"tmp\", token_class.name))\n                G = fsa.to_cfg(S=tmp, recursion=recursion)\n\n                foo.V |= G.V\n                for r in G:\n                    foo.add(r.w * decay, r.head, *r.body)\n\n                foo.add(decay, f(token_class.name), ignore, tmp)\n\n        assert len(foo.N &amp; foo.V) == 0\n\n        return foo\n</code></pre>"},{"location":"reference/genlm/grammar/lark_interface/#genlm.grammar.lark_interface.LarkStuff.__init__","title":"<code>__init__(grammar, cnf=False)</code>","text":"<p>Initialize a LarkStuff instance.</p> <p>Parameters:</p> Name Type Description Default <code>grammar</code> <p>A Lark grammar string</p> required <code>cnf</code> <p>Whether to convert grammar to Chomsky Normal Form</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If grammar does not define a 'start' rule</p> Source code in <code>genlm/grammar/lark_interface.py</code> <pre><code>def __init__(self, grammar, cnf=False):\n    \"\"\"Initialize a LarkStuff instance.\n\n    Args:\n        grammar: A Lark grammar string\n        cnf: Whether to convert grammar to Chomsky Normal Form\n\n    Raises:\n        ValueError: If grammar does not define a 'start' rule\n    \"\"\"\n    self.raw_grammar = grammar\n\n    builder = lark.load_grammar.GrammarBuilder()\n    builder.load_grammar(grammar)\n    lark_grammar = builder.build()\n\n    if not any(\n        rule.value == \"start\"\n        for rule in lark_grammar.rule_defs[0]\n        if isinstance(rule, lark.lexer.Token)\n    ):\n        raise ValueError(\"Grammar must define a `start` rule\")\n\n    terminals, rules, ignores = lark_grammar.compile([\"start\"], set())\n\n    if cnf:\n        parser = lark.parsers.cyk.Parser(rules)\n        self.rules = parser.grammar.rules\n    else:\n        self.rules = rules\n\n    self.terminals = terminals\n    self.ignore_terms = ignores\n</code></pre>"},{"location":"reference/genlm/grammar/lark_interface/#genlm.grammar.lark_interface.LarkStuff.convert","title":"<code>convert()</code>","text":"<p>Convert the Lark grammar into a genlm_grammar.CFG grammar.</p> <p>Returns:</p> Name Type Description <code>CFG</code> <p>A context-free grammar in genlm_grammar format with renumbered states</p> Source code in <code>genlm/grammar/lark_interface.py</code> <pre><code>def convert(self):\n    \"\"\"Convert the Lark grammar into a genlm_grammar.CFG grammar.\n\n    Returns:\n        CFG: A context-free grammar in genlm_grammar format with renumbered states\n    \"\"\"\n    try:\n        rules = [\n            Rule(1, r.lhs.name, tuple(y.name for y in r.rhs)) for r in self.rules\n        ]\n    except AttributeError:\n        rules = [\n            Rule(1, r.origin.name, tuple(y.name for y in r.expansion))\n            for r in self.rules\n        ]\n\n    lhs_count = Counter([r.head for r in rules])\n    cfg = CFG(R=Float, S=\"start\", V={t.name for t in self.terminals})\n    for r in rules:\n        cfg.add(1 / lhs_count[r.head], r.head, *r.body)\n    return cfg.renumber()\n</code></pre>"},{"location":"reference/genlm/grammar/lark_interface/#genlm.grammar.lark_interface.interegular_to_wfsa","title":"<code>interegular_to_wfsa(pattern, charset='core', name=lambda x: x)</code>","text":"<p>Convert an interegular regex pattern to a weighted finite state automaton.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <p>The regex pattern string to convert</p> required <code>name</code> <p>Function to transform state names (default: identity function)</p> <code>lambda x: x</code> <code>charset</code> <p>Character set to use for negative character classes. Can be 'core' for <code>string.printable</code>,     or a custom set of characters. This is the set of characters against which negative character     classes are matched.</p> <code>'core'</code> <p>Returns:</p> Type Description <code>WFSA</code> <p>A weighted finite state automaton representing the regex pattern</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If charset is not 'core' or a set</p> Note <p>Multi-character transitions from the regex are excluded with a warning, as they cannot be directly represented in the WFSA format.</p> Source code in <code>genlm/grammar/lark_interface.py</code> <pre><code>def interegular_to_wfsa(pattern, charset=\"core\", name=lambda x: x):\n    \"\"\"Convert an interegular regex pattern to a weighted finite state automaton.\n\n    Args:\n        pattern: The regex pattern string to convert\n        name: Function to transform state names (default: identity function)\n        charset: Character set to use for negative character classes. Can be 'core' for `string.printable`,\n                or a custom set of characters. This is the set of characters against which negative character\n                classes are matched.\n\n    Returns:\n        (WFSA): A weighted finite state automaton representing the regex pattern\n\n    Raises:\n        NotImplementedError: If charset is not 'core' or a set\n\n    Note:\n        Multi-character transitions from the regex are excluded with a warning, as they\n        cannot be directly represented in the WFSA format.\n    \"\"\"\n    if charset == \"core\":\n        charset = set(string.printable)\n    elif isinstance(charset, set):\n        pass\n    else:\n        # TODO: implement other charsets\n        raise NotImplementedError(f\"charset {charset} not implemented\")\n\n    # Compile the regex pattern to an FSM\n    fsm = interegular.parse_pattern(pattern).to_fsm()\n\n    def expand_alphabet(a):\n        if anything_else in fsm.alphabet.by_transition[a]:\n            assert fsm.alphabet.by_transition[a] == [anything_else]\n            return charset - set(fsm.alphabet)\n        else:\n            return fsm.alphabet.by_transition[a]\n\n    if 0:\n        from fsa import FSA\n\n        m = FSA()\n        m.add_start(name(fsm.initial))\n\n        rejection_states = [e for e in fsm.states if not fsm.islive(e)]\n        for i in fsm.states:\n            if i in fsm.finals:\n                m.add_stop(name(i))\n            for a, j in fsm.map[i].items():\n                if j in rejection_states:\n                    continue\n                for A in expand_alphabet(a):\n                    if len(A) != 1:\n                        warnings.warn(\n                            f\"Excluding multi-character arc {A!r} in pattern {pattern!r} (possibly a result of case insensitivity of arcs {expand_alphabet(a)})\"\n                        )\n                    m.add(name(i), A, name(j))\n\n        # DFA minimization\n        M = m.min()\n\n        del m\n        del fsm\n\n        m = WFSA(Float)\n        for i in M.nodes:\n            K = len(list(M.arcs(i))) + (i in M.stop)\n            if i in M.start:\n                m.add_I(name(i), 1)\n            if i in M.stop:\n                m.add_F(name(i), 1 / K)\n            for a, j in M.arcs(i):\n                m.add_arc(name(i), a, name(j), 1 / K)\n        return m\n\n    else:\n        m = WFSA(Float)\n        m.add_I(name(fsm.initial), 1)\n\n        rejection_states = [e for e in fsm.states if not fsm.islive(e)]\n        for i in fsm.states:\n            # determine this state's fan out\n            K = 0\n            for a, j in fsm.map[i].items():\n                # print(f'{i} --{a}/{fsm.alphabet.by_transition[a]}--&gt; {j}')\n                if j in rejection_states:\n                    continue\n                for A in expand_alphabet(a):\n                    assert isinstance(A, str)\n                    if len(A) != 1:\n                        warnings.warn(\n                            f\"Excluding multi-character arc {A!r} in pattern {pattern!r} (possibly a result of case insensitivity of arcs {expand_alphabet(a)})\"\n                        )\n                        continue\n                    K += 1\n            if i in fsm.finals:\n                K += 1\n            if K == 0:\n                continue\n            if i in fsm.finals:\n                m.add_F(name(i), 1 / K)\n            for a, j in fsm.map[i].items():\n                if j in rejection_states:\n                    continue\n                for A in expand_alphabet(a):\n                    m.add_arc(name(i), A, name(j), 1 / K)\n\n        return m\n</code></pre>"},{"location":"reference/genlm/grammar/linear/","title":"linear","text":"<p>Algorithms for solving left-linear or right-linear systems of equations over closed semirings.</p>"},{"location":"reference/genlm/grammar/linear/#genlm.grammar.linear.WeightedGraph","title":"<code>WeightedGraph</code>","text":"<p>Weight graph equipped with efficient methods for solving algebraic path problems.</p> Source code in <code>genlm/grammar/linear.py</code> <pre><code>class WeightedGraph:\n    \"\"\"\n    Weight graph equipped with efficient methods for solving algebraic path\n    problems.\n    \"\"\"\n\n    def __init__(self, WeightType):\n        self.WeightType = WeightType\n        self.N = set()\n        self.incoming = defaultdict(set)\n        self.outgoing = defaultdict(set)\n        self.E = WeightType.chart()\n\n    def __iter__(self):\n        return iter(self.E)\n\n    def __getitem__(self, item):\n        i, j = item\n        return self.E[i, j]\n\n    def __setitem__(self, item, value):\n        i, j = item\n        self.N.add(i)\n        self.N.add(j)\n        if value != self.WeightType.zero:\n            self.E[i, j] = value\n            self.incoming[j].add(i)\n            self.outgoing[i].add(j)\n        return self\n\n    def closure(self):\n        C = WeightedGraph(self.WeightType)\n        K = self.closure_scc_based()\n        for i, j in K:\n            C[i, j] += K[i, j]\n        return C\n\n    def closure_reference(self):\n        return self._closure(self.E, self.N)\n\n    def closure_scc_based(self):\n        K = self.WeightType.chart()\n        for i in self.N:\n            b = self.WeightType.chart()\n            b[i] = self.WeightType.one\n            sol = self.solve_left(b)\n            for j in sol:\n                K[i, j] = sol[j]\n        return K\n\n    def solve_left(self, b):\n        \"\"\"\n        Solve `x = x A + b` using block, upper-triangular decomposition.\n        \"\"\"\n        sol = self.WeightType.chart()\n        for block, B in self.Blocks:\n            # Compute the total weight of entering the block from the left at\n            # each entry j in the block\n            enter = self.WeightType.chart()\n            for j in block:\n                enter[j] += b[j]\n                for i in self.incoming[j]:\n                    enter[j] += sol[i] * self.E[i, j]\n\n            # Now, compute the total weight of completing the block\n            for j, k in B:\n                sol[k] += enter[j] * B[j, k]\n\n        return sol\n\n    def solve_right(self, b):\n        \"\"\"\n        Solve `x = A x + b` using block, upper-triangular decomposition.\n        \"\"\"\n        sol = self.WeightType.chart()\n        for block, B in reversed(self.Blocks):\n            # Compute the total weight of entering the block from the right at\n            # each entry point j in the block\n            enter = self.WeightType.chart()\n            for j in block:\n                enter[j] += b[j]\n                for k in self.outgoing[j]:\n                    enter[j] += self.E[j, k] * sol[k]\n\n            # Now, compute the total weight of completing the block\n            for i, j in B:\n                sol[i] += B[i, j] * enter[j]\n\n        return sol\n\n    def _closure(self, A, N):\n        \"\"\"\n        Compute the reflexive, transitive closure of `A` for the block of nodes `N`.\n        \"\"\"\n\n        # Special handling for the common case of |N| = 1; XXX: I'm surprised\n        # how much faster this version is compared to the loops below it.\n        if len(N) == 1:\n            [i] = N\n            return {(i, i): self.WeightType.star(self.E[i, i])}\n\n        A = self.E\n        old = A.copy()\n        new = self.WeightType.chart()\n        # transitive closure\n        for j in N:\n            new.clear()\n            sjj = self.WeightType.star(old[j, j])\n            for i in N:\n                for k in N:\n                    new[i, k] = old[i, k] + old[i, j] * sjj * old[j, k]\n            old, new = new, old\n        # reflexive closure\n        for i in N:\n            old[i, i] += self.WeightType.one\n        return old\n\n    @cached_property\n    def blocks(self):\n        \"List of blocks.\"\n        return list(self._blocks(self.N))\n\n    def _blocks(self, roots=None):\n        return scc_decomposition(self.incoming.__getitem__, roots)\n\n    @cached_property\n    def buckets(self):\n        \"Map from node to block id.\"\n        return {x: i for i, block in enumerate(self.blocks) for x in block}\n\n    @cached_property\n    def Blocks(self):\n        return [(block, self._closure(self.E, block)) for block in self.blocks]\n\n    def _repr_svg_(self):\n        return self.graphviz()._repr_image_svg_xml()\n\n    def graphviz(self, label_format=str, escape=lambda x: html.escape(str(x))):\n        \"Convert to `graphviz.Digraph` instance for visualization.\"\n        name = Integerizer()\n\n        g = Digraph(\n            node_attr=dict(\n                fontname=\"Monospace\",\n                fontsize=\"9\",\n                height=\"0\",\n                width=\"0\",\n                margin=\"0.055,0.042\",\n                penwidth=\"0.15\",\n                shape=\"box\",\n                style=\"rounded\",\n            ),\n            edge_attr=dict(\n                penwidth=\"0.5\",\n                arrowhead=\"vee\",\n                arrowsize=\"0.5\",\n                fontname=\"Monospace\",\n                fontsize=\"8\",\n            ),\n        )\n\n        for i, j in self:\n            # if self.E[i, j] == self.WeightType.zero:\n            #    continue\n            g.edge(str(name(i)), str(name(j)), label=label_format(self.E[i, j]))\n\n        for i in self.N:\n            g.node(str(name(i)), label=escape(i))\n\n        return g\n</code></pre>"},{"location":"reference/genlm/grammar/linear/#genlm.grammar.linear.WeightedGraph.blocks","title":"<code>blocks</code>  <code>cached</code> <code>property</code>","text":"<p>List of blocks.</p>"},{"location":"reference/genlm/grammar/linear/#genlm.grammar.linear.WeightedGraph.buckets","title":"<code>buckets</code>  <code>cached</code> <code>property</code>","text":"<p>Map from node to block id.</p>"},{"location":"reference/genlm/grammar/linear/#genlm.grammar.linear.WeightedGraph.graphviz","title":"<code>graphviz(label_format=str, escape=lambda x: html.escape(str(x)))</code>","text":"<p>Convert to <code>graphviz.Digraph</code> instance for visualization.</p> Source code in <code>genlm/grammar/linear.py</code> <pre><code>def graphviz(self, label_format=str, escape=lambda x: html.escape(str(x))):\n    \"Convert to `graphviz.Digraph` instance for visualization.\"\n    name = Integerizer()\n\n    g = Digraph(\n        node_attr=dict(\n            fontname=\"Monospace\",\n            fontsize=\"9\",\n            height=\"0\",\n            width=\"0\",\n            margin=\"0.055,0.042\",\n            penwidth=\"0.15\",\n            shape=\"box\",\n            style=\"rounded\",\n        ),\n        edge_attr=dict(\n            penwidth=\"0.5\",\n            arrowhead=\"vee\",\n            arrowsize=\"0.5\",\n            fontname=\"Monospace\",\n            fontsize=\"8\",\n        ),\n    )\n\n    for i, j in self:\n        # if self.E[i, j] == self.WeightType.zero:\n        #    continue\n        g.edge(str(name(i)), str(name(j)), label=label_format(self.E[i, j]))\n\n    for i in self.N:\n        g.node(str(name(i)), label=escape(i))\n\n    return g\n</code></pre>"},{"location":"reference/genlm/grammar/linear/#genlm.grammar.linear.WeightedGraph.solve_left","title":"<code>solve_left(b)</code>","text":"<p>Solve <code>x = x A + b</code> using block, upper-triangular decomposition.</p> Source code in <code>genlm/grammar/linear.py</code> <pre><code>def solve_left(self, b):\n    \"\"\"\n    Solve `x = x A + b` using block, upper-triangular decomposition.\n    \"\"\"\n    sol = self.WeightType.chart()\n    for block, B in self.Blocks:\n        # Compute the total weight of entering the block from the left at\n        # each entry j in the block\n        enter = self.WeightType.chart()\n        for j in block:\n            enter[j] += b[j]\n            for i in self.incoming[j]:\n                enter[j] += sol[i] * self.E[i, j]\n\n        # Now, compute the total weight of completing the block\n        for j, k in B:\n            sol[k] += enter[j] * B[j, k]\n\n    return sol\n</code></pre>"},{"location":"reference/genlm/grammar/linear/#genlm.grammar.linear.WeightedGraph.solve_right","title":"<code>solve_right(b)</code>","text":"<p>Solve <code>x = A x + b</code> using block, upper-triangular decomposition.</p> Source code in <code>genlm/grammar/linear.py</code> <pre><code>def solve_right(self, b):\n    \"\"\"\n    Solve `x = A x + b` using block, upper-triangular decomposition.\n    \"\"\"\n    sol = self.WeightType.chart()\n    for block, B in reversed(self.Blocks):\n        # Compute the total weight of entering the block from the right at\n        # each entry point j in the block\n        enter = self.WeightType.chart()\n        for j in block:\n            enter[j] += b[j]\n            for k in self.outgoing[j]:\n                enter[j] += self.E[j, k] * sol[k]\n\n        # Now, compute the total weight of completing the block\n        for i, j in B:\n            sol[i] += B[i, j] * enter[j]\n\n    return sol\n</code></pre>"},{"location":"reference/genlm/grammar/linear/#genlm.grammar.linear.scc_decomposition","title":"<code>scc_decomposition(successors, roots)</code>","text":"<p>Find the strongly connected components of a graph. Implemention is based on Tarjan's (1972) algorithm; runs in $\\mathcal{O}(E + V)$ time, uses $\\mathcal{O}(V)$ space.</p> <p>Tarjan, R. E. (1972), Depth-first search and linear graph algorithms SIAM Journal on Computing, 1 (2): 146\u2013160, doi:10.1137/0201010</p> Source code in <code>genlm/grammar/linear.py</code> <pre><code>def scc_decomposition(successors, roots):\n    r\"\"\"\n    Find the strongly connected components of a graph.\n    Implemention is based on Tarjan's (1972) algorithm; runs in $\\mathcal{O}(E + V)$ time, uses $\\mathcal{O}(V)$ space.\n\n    Tarjan, R. E. (1972), [Depth-first search and linear graph algorithms](https://epubs.siam.org/doi/10.1137/0201010)\n    SIAM Journal on Computing, 1 (2): 146\u2013160, doi:10.1137/0201010\n\n    \"\"\"\n\n    # 'Low Link Value' of a node is the smallest id reachable by DFS, including itself.\n    # low link values are initialized to each node's id.\n    lowest = {}  # node -&gt; position of the root of the SCC\n\n    stack = []  # stack\n    trail = set()  # set of nodes on the stack\n    t = 0\n\n    def dfs(v):\n        # DFS pushes nodes onto the stack\n        nonlocal t\n        t += 1\n        num = t\n        lowest[v] = t\n        trail.add(v)\n        stack.append(v)\n\n        for w in successors(v):\n            if lowest.get(w) is None:\n                # As usual, only recurse when we haven't already visited this node\n                yield from dfs(w)\n                # The recursive call will find a cycle if there is one.\n                # `lowest` is used to propagate the position of the earliest\n                # node on the cycle in the DFS.\n                lowest[v] = min(lowest[v], lowest[w])\n            elif w in trail:\n                # Collapsing cycles.  If `w` comes before `v` in dfs and `w` is\n                # on the stack, then we've detected a cycle and we can start\n                # collapsing values in the SCC.  It might not be the maximal\n                # SCC. The min and stack will take care of that.\n                lowest[v] = min(lowest[v], lowest[w])\n\n        if lowest[v] == num:\n            # `v` is the root of an SCC; We're totally done with that subgraph.\n            # nodes above `v` on the stack are an SCC.\n            C = []\n            while True:  # pop until we reach v\n                w = stack.pop()\n                trail.remove(w)\n                C.append(w)\n                if w == v:\n                    break\n            yield frozenset(C)\n\n    for v in roots:\n        if lowest.get(v) is None:\n            yield from dfs(v)\n</code></pre>"},{"location":"reference/genlm/grammar/lm/","title":"lm","text":""},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM","title":"<code>LM</code>","text":"<p>Language model base class that defines a probability distribution over strings.</p> <p>A language model p: V* -&gt; [0,1] defines a probability distribution over strings from a vocabulary V of tokens. Every language model admits a left-to-right factorization:</p> <p>p(x_1 x_2 ... x_T) = p(x_1|\u03b5) p(x_2|x_1) ... p(x_T|x_1...x_{T-1}) p(EOS|x_1...x_T)</p> <p>Parameters:</p> Name Type Description Default <code>V</code> <p>Vocabulary of symbols</p> required <code>eos</code> <p>Distinguished end-of-sequence symbol</p> required <p>Attributes:</p> Name Type Description <code>V</code> <p>Vocabulary set</p> <code>eos</code> <p>End-of-sequence symbol</p> Notes <p>Subclasses must implement p_next(xs) which returns p(\u00b7|x_1...x_T).</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>class LM:\n    \"\"\"Language model base class that defines a probability distribution over strings.\n\n    A language model p: V* -&gt; [0,1] defines a probability distribution over strings from\n    a vocabulary V of tokens. Every language model admits a left-to-right factorization:\n\n    p(x_1 x_2 ... x_T) = p(x_1|\u03b5) p(x_2|x_1) ... p(x_T|x_1...x_{T-1}) p(EOS|x_1...x_T)\n\n    Args:\n        V: Vocabulary of symbols\n        eos: Distinguished end-of-sequence symbol\n\n    Attributes:\n        V: Vocabulary set\n        eos: End-of-sequence symbol\n\n    Notes:\n        Subclasses must implement p_next(xs) which returns p(\u00b7|x_1...x_T).\n    \"\"\"\n\n    def __init__(self, V, eos):\n        \"\"\"Initialize language model with vocabulary and end-of-sequence token.\n\n        Args:\n            V: Vocabulary set of tokens\n            eos: End-of-sequence token\n        \"\"\"\n        self.eos = eos\n        self.V = V\n\n    def __call__(self, context):\n        \"\"\"Compute the probability of a complete string.\n\n        Args:\n            context: Sequence of tokens ending with eos token\n\n        Returns:\n            float: Probability of the sequence\n\n        Raises:\n            AssertionError: If context doesn't end with eos or contains invalid tokens\n        \"\"\"\n        assert context[-1] == self.eos\n        P = 1\n        for i, y in enumerate(context):\n            assert y in self.V, y\n            p = self.p_next(context[:i])\n            P *= p[y]\n            if P == 0:\n                break\n        return P\n\n    def logp(self, context):\n        \"\"\"Compute the log probability of a complete string.\n\n        Args:\n            context: Sequence of tokens ending with eos token\n\n        Returns:\n            (float): Log probability of the sequence\n\n        Raises:\n            AssertionError: If context doesn't end with eos\n        \"\"\"\n        assert context[-1] == self.eos\n        return sum(self.logp_next(context[:i])[y] for i, y in enumerate(context))\n\n    def logp_next(self, context):\n        \"\"\"Compute the log conditional distribution over the next token given the prefix.\n\n        Args:\n            context: Sequence of tokens representing the prefix\n\n        Returns:\n            Log probabilities for each possible next token\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses\n        \"\"\"\n        raise NotImplementedError()\n\n    def p_next(self, context):\n        \"\"\"Compute the conditional distribution over the next token given the prefix.\n\n        Args:\n            context: Sequence of tokens representing the prefix\n\n        Returns:\n            Probabilities for each possible next token\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses\n        \"\"\"\n        raise NotImplementedError()\n\n    async def p_next_async(self, context):\n        \"\"\"Asynchronously compute the conditional distribution over the next token.\n\n        Args:\n            context: Sequence of tokens representing the prefix\n\n        Returns:\n            Probabilities for each possible next token\n        \"\"\"\n        return self.p_next(context)\n\n    def p_next_seq(self, context, extension):\n        \"\"\"Compute probability of an extension sequence given a context.\n\n        Args:\n            context: Sequence of tokens representing the prefix\n            extension: Sequence of tokens to compute probability for\n\n        Returns:\n            (float): Probability of the extension sequence given the context\n\n        Raises:\n            AssertionError: If extension is empty\n        \"\"\"\n        assert len(extension) &gt;= 1\n        P = 1\n        for i in range(len(extension)):\n            p = self.p_next(context + extension[:i])\n            P *= p[extension[i]]\n        return P\n\n    def clear_cache(self):  # pragma: no cover\n        \"\"\"Clear any cached computations.\"\"\"\n        pass\n\n    def sample(\n        self,\n        ys=(),\n        draw=sample_dict,\n        prob=True,\n        verbose=0,\n        max_tokens=np.inf,\n        join=lambda ys, y: ys + (y,),\n    ):\n        \"\"\"Sample a sequence from the language model.\n\n        Args:\n            ys: Initial sequence of tokens (default: empty tuple)\n            draw: Function to sample from probability distribution (default: sample_dict)\n            prob: Whether to return probability along with sequence (default: True)\n            verbose: Verbosity level for printing tokens (default: 0)\n            max_tokens: Maximum number of tokens to generate (default: infinity)\n            join: Function to join new token with existing sequence (default: tuple concatenation)\n\n        Returns:\n            If prob=True: Tuple of (generated sequence, probability)\n            If prob=False: Generated sequence\n        \"\"\"\n        assert isinstance(ys, tuple), ys\n        P = 1.0\n        t = 0\n        while True:\n            p = self.p_next(ys).normalize()\n            y = draw(p) if t &lt;= max_tokens else self.eos\n            P *= p[y]\n            t += 1\n            if verbose:\n                if y == self.eos:\n                    print()\n                else:\n                    print(y, end=\"\")\n            if y == self.eos:\n                return (ys, P) if prob else ys\n            ys = join(ys, y)\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.__call__","title":"<code>__call__(context)</code>","text":"<p>Compute the probability of a complete string.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens ending with eos token</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Probability of the sequence</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If context doesn't end with eos or contains invalid tokens</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>def __call__(self, context):\n    \"\"\"Compute the probability of a complete string.\n\n    Args:\n        context: Sequence of tokens ending with eos token\n\n    Returns:\n        float: Probability of the sequence\n\n    Raises:\n        AssertionError: If context doesn't end with eos or contains invalid tokens\n    \"\"\"\n    assert context[-1] == self.eos\n    P = 1\n    for i, y in enumerate(context):\n        assert y in self.V, y\n        p = self.p_next(context[:i])\n        P *= p[y]\n        if P == 0:\n            break\n    return P\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.__init__","title":"<code>__init__(V, eos)</code>","text":"<p>Initialize language model with vocabulary and end-of-sequence token.</p> <p>Parameters:</p> Name Type Description Default <code>V</code> <p>Vocabulary set of tokens</p> required <code>eos</code> <p>End-of-sequence token</p> required Source code in <code>genlm/grammar/lm.py</code> <pre><code>def __init__(self, V, eos):\n    \"\"\"Initialize language model with vocabulary and end-of-sequence token.\n\n    Args:\n        V: Vocabulary set of tokens\n        eos: End-of-sequence token\n    \"\"\"\n    self.eos = eos\n    self.V = V\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.clear_cache","title":"<code>clear_cache()</code>","text":"<p>Clear any cached computations.</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>def clear_cache(self):  # pragma: no cover\n    \"\"\"Clear any cached computations.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.logp","title":"<code>logp(context)</code>","text":"<p>Compute the log probability of a complete string.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens ending with eos token</p> required <p>Returns:</p> Type Description <code>float</code> <p>Log probability of the sequence</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If context doesn't end with eos</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>def logp(self, context):\n    \"\"\"Compute the log probability of a complete string.\n\n    Args:\n        context: Sequence of tokens ending with eos token\n\n    Returns:\n        (float): Log probability of the sequence\n\n    Raises:\n        AssertionError: If context doesn't end with eos\n    \"\"\"\n    assert context[-1] == self.eos\n    return sum(self.logp_next(context[:i])[y] for i, y in enumerate(context))\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.logp_next","title":"<code>logp_next(context)</code>","text":"<p>Compute the log conditional distribution over the next token given the prefix.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens representing the prefix</p> required <p>Returns:</p> Type Description <p>Log probabilities for each possible next token</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>def logp_next(self, context):\n    \"\"\"Compute the log conditional distribution over the next token given the prefix.\n\n    Args:\n        context: Sequence of tokens representing the prefix\n\n    Returns:\n        Log probabilities for each possible next token\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.p_next","title":"<code>p_next(context)</code>","text":"<p>Compute the conditional distribution over the next token given the prefix.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens representing the prefix</p> required <p>Returns:</p> Type Description <p>Probabilities for each possible next token</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>def p_next(self, context):\n    \"\"\"Compute the conditional distribution over the next token given the prefix.\n\n    Args:\n        context: Sequence of tokens representing the prefix\n\n    Returns:\n        Probabilities for each possible next token\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.p_next_async","title":"<code>p_next_async(context)</code>  <code>async</code>","text":"<p>Asynchronously compute the conditional distribution over the next token.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens representing the prefix</p> required <p>Returns:</p> Type Description <p>Probabilities for each possible next token</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>async def p_next_async(self, context):\n    \"\"\"Asynchronously compute the conditional distribution over the next token.\n\n    Args:\n        context: Sequence of tokens representing the prefix\n\n    Returns:\n        Probabilities for each possible next token\n    \"\"\"\n    return self.p_next(context)\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.p_next_seq","title":"<code>p_next_seq(context, extension)</code>","text":"<p>Compute probability of an extension sequence given a context.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens representing the prefix</p> required <code>extension</code> <p>Sequence of tokens to compute probability for</p> required <p>Returns:</p> Type Description <code>float</code> <p>Probability of the extension sequence given the context</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If extension is empty</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>def p_next_seq(self, context, extension):\n    \"\"\"Compute probability of an extension sequence given a context.\n\n    Args:\n        context: Sequence of tokens representing the prefix\n        extension: Sequence of tokens to compute probability for\n\n    Returns:\n        (float): Probability of the extension sequence given the context\n\n    Raises:\n        AssertionError: If extension is empty\n    \"\"\"\n    assert len(extension) &gt;= 1\n    P = 1\n    for i in range(len(extension)):\n        p = self.p_next(context + extension[:i])\n        P *= p[extension[i]]\n    return P\n</code></pre>"},{"location":"reference/genlm/grammar/lm/#genlm.grammar.lm.LM.sample","title":"<code>sample(ys=(), draw=sample_dict, prob=True, verbose=0, max_tokens=np.inf, join=lambda ys, y: ys + (y,))</code>","text":"<p>Sample a sequence from the language model.</p> <p>Parameters:</p> Name Type Description Default <code>ys</code> <p>Initial sequence of tokens (default: empty tuple)</p> <code>()</code> <code>draw</code> <p>Function to sample from probability distribution (default: sample_dict)</p> <code>sample_dict</code> <code>prob</code> <p>Whether to return probability along with sequence (default: True)</p> <code>True</code> <code>verbose</code> <p>Verbosity level for printing tokens (default: 0)</p> <code>0</code> <code>max_tokens</code> <p>Maximum number of tokens to generate (default: infinity)</p> <code>inf</code> <code>join</code> <p>Function to join new token with existing sequence (default: tuple concatenation)</p> <code>lambda ys, y: ys + (y,)</code> <p>Returns:</p> Type Description <p>If prob=True: Tuple of (generated sequence, probability)</p> <p>If prob=False: Generated sequence</p> Source code in <code>genlm/grammar/lm.py</code> <pre><code>def sample(\n    self,\n    ys=(),\n    draw=sample_dict,\n    prob=True,\n    verbose=0,\n    max_tokens=np.inf,\n    join=lambda ys, y: ys + (y,),\n):\n    \"\"\"Sample a sequence from the language model.\n\n    Args:\n        ys: Initial sequence of tokens (default: empty tuple)\n        draw: Function to sample from probability distribution (default: sample_dict)\n        prob: Whether to return probability along with sequence (default: True)\n        verbose: Verbosity level for printing tokens (default: 0)\n        max_tokens: Maximum number of tokens to generate (default: infinity)\n        join: Function to join new token with existing sequence (default: tuple concatenation)\n\n    Returns:\n        If prob=True: Tuple of (generated sequence, probability)\n        If prob=False: Generated sequence\n    \"\"\"\n    assert isinstance(ys, tuple), ys\n    P = 1.0\n    t = 0\n    while True:\n        p = self.p_next(ys).normalize()\n        y = draw(p) if t &lt;= max_tokens else self.eos\n        P *= p[y]\n        t += 1\n        if verbose:\n            if y == self.eos:\n                print()\n            else:\n                print(y, end=\"\")\n        if y == self.eos:\n            return (ys, P) if prob else ys\n        ys = join(ys, y)\n</code></pre>"},{"location":"reference/genlm/grammar/semiring/","title":"semiring","text":""},{"location":"reference/genlm/grammar/util/","title":"util","text":""},{"location":"reference/genlm/grammar/parse/__init__/","title":"parse","text":""},{"location":"reference/genlm/grammar/parse/cky/","title":"cky","text":""},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.CKYLM","title":"<code>CKYLM</code>","text":"<p>               Bases: <code>LM</code></p> <p>Probabilistic Context-Free Grammar Language Model.</p> <p>Uses CKY parsing algorithm and prefix grammar transformation for efficient inference over context-free grammars.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use as the language model</p> required <code>**kwargs</code> <p>Additional arguments passed to IncrementalCKY</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>cfg</code> <code>CFG</code> <p>The original context-free grammar</p> <code>pfg</code> <code>CFG</code> <p>The prefix grammar in CNF form used for incremental parsing</p> <code>model</code> <code>IncrementalCKY</code> <p>The incremental CKY parser for computing probabilities</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>class CKYLM(LM):\n    \"\"\"Probabilistic Context-Free Grammar Language Model.\n\n    Uses CKY parsing algorithm and prefix grammar transformation for efficient inference\n    over context-free grammars.\n\n    Args:\n        cfg (CFG): The context-free grammar to use as the language model\n        **kwargs: Additional arguments passed to IncrementalCKY\n\n    Attributes:\n        cfg (CFG): The original context-free grammar\n        pfg (CFG): The prefix grammar in CNF form used for incremental parsing\n        model (IncrementalCKY): The incremental CKY parser for computing probabilities\n    \"\"\"\n\n    def __init__(self, cfg, **kwargs):\n        \"\"\"Initialize a CKY-based language model.\n\n        Args:\n            cfg (CFG): The context-free grammar to use as the language model. Will be\n                converted to CNF and prefix form for incremental parsing.\n            **kwargs: Additional arguments passed to IncrementalCKY parser initialization\n\n        Raises:\n            AssertionError: If EOS token not in grammar vocabulary\n        \"\"\"\n        if EOS not in cfg.V:\n            cfg = add_EOS(cfg)\n        self.cfg = cfg\n        self.pfg = self.cfg.cnf.prefix_grammar.cnf\n        self.model = IncrementalCKY(self.pfg, **kwargs)\n        super().__init__(V=cfg.V, eos=EOS)\n\n    def p_next(self, context):\n        \"\"\"Compute probability distribution over next tokens given a context.\n\n        Args:\n            context: Sequence of tokens representing the prefix\n\n        Returns:\n            Normalized probability distribution over possible next tokens\n\n        Raises:\n            AssertionError: If context contains tokens not in vocabulary\n        \"\"\"\n        assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n        return self.model.p_next(context).normalize()\n\n    @classmethod\n    def from_string(cls, x, semiring=Float, **kwargs):\n        \"\"\"Create a CKYLM from a grammar string representation.\n\n        Args:\n            x (str): String representation of the grammar\n            semiring: Semiring to use for weights (default: Float)\n            **kwargs: Additional arguments for grammar normalization\n\n        Returns:\n            CKYLM: A new language model instance\n        \"\"\"\n        return cls(locally_normalize(CFG.from_string(x, semiring), **kwargs))\n\n    def clear_cache(self):\n        \"\"\"Clear the parser's chart cache.\"\"\"\n        self.model.clear_cache()\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.CKYLM.__init__","title":"<code>__init__(cfg, **kwargs)</code>","text":"<p>Initialize a CKY-based language model.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use as the language model. Will be converted to CNF and prefix form for incremental parsing.</p> required <code>**kwargs</code> <p>Additional arguments passed to IncrementalCKY parser initialization</p> <code>{}</code> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If EOS token not in grammar vocabulary</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def __init__(self, cfg, **kwargs):\n    \"\"\"Initialize a CKY-based language model.\n\n    Args:\n        cfg (CFG): The context-free grammar to use as the language model. Will be\n            converted to CNF and prefix form for incremental parsing.\n        **kwargs: Additional arguments passed to IncrementalCKY parser initialization\n\n    Raises:\n        AssertionError: If EOS token not in grammar vocabulary\n    \"\"\"\n    if EOS not in cfg.V:\n        cfg = add_EOS(cfg)\n    self.cfg = cfg\n    self.pfg = self.cfg.cnf.prefix_grammar.cnf\n    self.model = IncrementalCKY(self.pfg, **kwargs)\n    super().__init__(V=cfg.V, eos=EOS)\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.CKYLM.clear_cache","title":"<code>clear_cache()</code>","text":"<p>Clear the parser's chart cache.</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def clear_cache(self):\n    \"\"\"Clear the parser's chart cache.\"\"\"\n    self.model.clear_cache()\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.CKYLM.from_string","title":"<code>from_string(x, semiring=Float, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a CKYLM from a grammar string representation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>String representation of the grammar</p> required <code>semiring</code> <p>Semiring to use for weights (default: Float)</p> <code>Float</code> <code>**kwargs</code> <p>Additional arguments for grammar normalization</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>CKYLM</code> <p>A new language model instance</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>@classmethod\ndef from_string(cls, x, semiring=Float, **kwargs):\n    \"\"\"Create a CKYLM from a grammar string representation.\n\n    Args:\n        x (str): String representation of the grammar\n        semiring: Semiring to use for weights (default: Float)\n        **kwargs: Additional arguments for grammar normalization\n\n    Returns:\n        CKYLM: A new language model instance\n    \"\"\"\n    return cls(locally_normalize(CFG.from_string(x, semiring), **kwargs))\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.CKYLM.p_next","title":"<code>p_next(context)</code>","text":"<p>Compute probability distribution over next tokens given a context.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens representing the prefix</p> required <p>Returns:</p> Type Description <p>Normalized probability distribution over possible next tokens</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If context contains tokens not in vocabulary</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def p_next(self, context):\n    \"\"\"Compute probability distribution over next tokens given a context.\n\n    Args:\n        context: Sequence of tokens representing the prefix\n\n    Returns:\n        Normalized probability distribution over possible next tokens\n\n    Raises:\n        AssertionError: If context contains tokens not in vocabulary\n    \"\"\"\n    assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n    return self.model.p_next(context).normalize()\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.IncrementalCKY","title":"<code>IncrementalCKY</code>","text":"<p>An incremental CKY parser implementation for Context-Free Grammars (CFG).</p> <p>This parser maintains a chart cache for efficient incremental parsing and supports weight computations for next-token predictions.</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>class IncrementalCKY:\n    \"\"\"\n    An incremental CKY parser implementation for Context-Free Grammars (CFG).\n\n    This parser maintains a chart cache for efficient incremental parsing and supports\n    weight computations for next-token predictions.\n    \"\"\"\n\n    def __init__(self, cfg):\n        \"\"\"\n        Initialize an incremental CKY parser.\n\n        Args:\n            cfg (CFG): The context-free grammar\n        \"\"\"\n        cfg = cfg.renumber()\n        self.cfg = cfg\n        self.S = cfg.S\n\n        # cache columns of the chart indexed by prefix\n        self._chart = {}\n\n        [self.nullary, self.terminal, binary] = cfg._cnf\n        r_y_xz = defaultdict(list)\n        for r in binary:  # binary rules\n            r_y_xz[r.body[0]].append(r)\n        self.r_y_xz = r_y_xz\n\n    def clear_cache(self):\n        self._chart.clear()\n\n    def __call__(self, x):\n        return self.chart(x)[len(x)][0][self.S]\n\n    def p_next(self, prefix):\n        \"\"\"\n        Compute the weights for all possible next tokens given a prefix.\n\n        Args:\n            prefix: The current sequence of tokens\n\n        Returns:\n            Dictionary mapping possible next tokens to their weights\n        \"\"\"\n        return self.next_token_weights(self.chart(prefix), prefix)\n\n    def chart(self, prefix):\n        \"\"\"\n        Get the parsing chart for a given prefix, computing it if not cached.\n\n        Args:\n            prefix: The sequence of tokens to parse\n\n        Returns:\n            The CKY chart for the prefix\n        \"\"\"\n        c = self._chart.get(prefix)\n        if c is None:\n            c = self._compute_chart(prefix)\n            self._chart[prefix] = c\n        return c\n\n    def _compute_chart(self, prefix):\n        \"\"\"\n        Compute the CKY chart for a given prefix.\n\n        Args:\n            prefix: The sequence of tokens to parse\n\n        Returns:\n            A new chart for the prefix, either initialized for empty prefix\n            or extended from the previous chart\n        \"\"\"\n        if len(prefix) == 0:\n            tmp = [defaultdict(self.cfg.R.chart)]\n            tmp[0][0][self.cfg.S] = self.nullary\n            return tmp\n        else:\n            chart = self.chart(prefix[:-1])\n            last_chart = self.extend_chart(chart, prefix)\n            return chart + [\n                last_chart\n            ]  # TODO: avoid list addition here as it is not constant time!\n\n    def next_token_weights(self, chart, prefix):\n        \"\"\"\n        Compute the total weight for each possible next token following the prefix.\n\n        An O(N\u00b2) time algorithm that calculates the total weight of a each next-token\n        extension of `prefix`.\n\n        Args:\n            chart: The current CKY chart\n            prefix: The current sequence of tokens\n\n        Returns:\n            (Chart) Dictionary mapping possible next tokens to their weights # XXX\n        \"\"\"\n        k = len(prefix) + 1\n\n        cfg = self.cfg\n        terminal = self.terminal\n        r_y_xz = self.r_y_xz\n\n        # the code below is just backprop / outside algorithm\n        \u03b1 = defaultdict(cfg.R.chart)\n        \u03b1[0][cfg.S] += cfg.R.one\n\n        # Binary rules\n        for span in reversed(range(2, k + 1)):\n            i = k - span\n            \u03b1_i = \u03b1[i]\n            for j in range(i + 1, k):\n                chart_ij = chart[j][i]\n\n                \u03b1_j = \u03b1[j]\n                for Y, y in chart_ij.items():\n                    for r in r_y_xz[Y]:\n                        X = r.head\n                        Z = r.body[1]\n                        \u03b1_j[Z] += r.w * y * \u03b1_i[X]\n\n        # Preterminal\n        q = cfg.R.chart()\n        tmp = \u03b1[k - 1]\n        for w in cfg.V:\n            for r in terminal[w]:\n                q[w] += r.w * tmp[r.head]\n\n        return q\n\n    def extend_chart(self, chart, prefix):\n        \"\"\"\n        An O(N\u00b2) time algorithm that extends the parsing chart with the last token of the prefix.\n\n        Args:\n            chart: The current CKY chart\n            prefix: The sequence of tokens including the new token\n\n        Returns:\n            A new chart column incorporating the last token\n        \"\"\"\n        k = len(prefix)\n\n        cfg = self.cfg\n        r_y_xz = self.r_y_xz\n\n        new = defaultdict(cfg.R.chart)\n\n        # Nullary\n        new[k][cfg.S] += self.nullary\n\n        # Preterminal\n        tmp = new[k - 1]\n        for r in self.terminal[prefix[k - 1]]:\n            tmp[r.head] += r.w\n\n        # Binary rules\n        for span in range(2, k + 1):\n            i = k - span\n            new_i = new[i]\n            for j in range(i + 1, k):\n                chart_ij = chart[j][i]\n                new_j = new[j]\n                for Y, y in chart_ij.items():\n                    for r in r_y_xz[Y]:\n                        X = r.head\n                        Z = r.body[1]\n                        z = new_j[Z]\n                        x = r.w * y * z\n                        new_i[X] += x\n\n        return new\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.IncrementalCKY.__init__","title":"<code>__init__(cfg)</code>","text":"<p>Initialize an incremental CKY parser.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar</p> required Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def __init__(self, cfg):\n    \"\"\"\n    Initialize an incremental CKY parser.\n\n    Args:\n        cfg (CFG): The context-free grammar\n    \"\"\"\n    cfg = cfg.renumber()\n    self.cfg = cfg\n    self.S = cfg.S\n\n    # cache columns of the chart indexed by prefix\n    self._chart = {}\n\n    [self.nullary, self.terminal, binary] = cfg._cnf\n    r_y_xz = defaultdict(list)\n    for r in binary:  # binary rules\n        r_y_xz[r.body[0]].append(r)\n    self.r_y_xz = r_y_xz\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.IncrementalCKY.chart","title":"<code>chart(prefix)</code>","text":"<p>Get the parsing chart for a given prefix, computing it if not cached.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <p>The sequence of tokens to parse</p> required <p>Returns:</p> Type Description <p>The CKY chart for the prefix</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def chart(self, prefix):\n    \"\"\"\n    Get the parsing chart for a given prefix, computing it if not cached.\n\n    Args:\n        prefix: The sequence of tokens to parse\n\n    Returns:\n        The CKY chart for the prefix\n    \"\"\"\n    c = self._chart.get(prefix)\n    if c is None:\n        c = self._compute_chart(prefix)\n        self._chart[prefix] = c\n    return c\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.IncrementalCKY.extend_chart","title":"<code>extend_chart(chart, prefix)</code>","text":"<p>An O(N\u00b2) time algorithm that extends the parsing chart with the last token of the prefix.</p> <p>Parameters:</p> Name Type Description Default <code>chart</code> <p>The current CKY chart</p> required <code>prefix</code> <p>The sequence of tokens including the new token</p> required <p>Returns:</p> Type Description <p>A new chart column incorporating the last token</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def extend_chart(self, chart, prefix):\n    \"\"\"\n    An O(N\u00b2) time algorithm that extends the parsing chart with the last token of the prefix.\n\n    Args:\n        chart: The current CKY chart\n        prefix: The sequence of tokens including the new token\n\n    Returns:\n        A new chart column incorporating the last token\n    \"\"\"\n    k = len(prefix)\n\n    cfg = self.cfg\n    r_y_xz = self.r_y_xz\n\n    new = defaultdict(cfg.R.chart)\n\n    # Nullary\n    new[k][cfg.S] += self.nullary\n\n    # Preterminal\n    tmp = new[k - 1]\n    for r in self.terminal[prefix[k - 1]]:\n        tmp[r.head] += r.w\n\n    # Binary rules\n    for span in range(2, k + 1):\n        i = k - span\n        new_i = new[i]\n        for j in range(i + 1, k):\n            chart_ij = chart[j][i]\n            new_j = new[j]\n            for Y, y in chart_ij.items():\n                for r in r_y_xz[Y]:\n                    X = r.head\n                    Z = r.body[1]\n                    z = new_j[Z]\n                    x = r.w * y * z\n                    new_i[X] += x\n\n    return new\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.IncrementalCKY.next_token_weights","title":"<code>next_token_weights(chart, prefix)</code>","text":"<p>Compute the total weight for each possible next token following the prefix.</p> <p>An O(N\u00b2) time algorithm that calculates the total weight of a each next-token extension of <code>prefix</code>.</p> <p>Parameters:</p> Name Type Description Default <code>chart</code> <p>The current CKY chart</p> required <code>prefix</code> <p>The current sequence of tokens</p> required <p>Returns:</p> Type Description <p>(Chart) Dictionary mapping possible next tokens to their weights # XXX</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def next_token_weights(self, chart, prefix):\n    \"\"\"\n    Compute the total weight for each possible next token following the prefix.\n\n    An O(N\u00b2) time algorithm that calculates the total weight of a each next-token\n    extension of `prefix`.\n\n    Args:\n        chart: The current CKY chart\n        prefix: The current sequence of tokens\n\n    Returns:\n        (Chart) Dictionary mapping possible next tokens to their weights # XXX\n    \"\"\"\n    k = len(prefix) + 1\n\n    cfg = self.cfg\n    terminal = self.terminal\n    r_y_xz = self.r_y_xz\n\n    # the code below is just backprop / outside algorithm\n    \u03b1 = defaultdict(cfg.R.chart)\n    \u03b1[0][cfg.S] += cfg.R.one\n\n    # Binary rules\n    for span in reversed(range(2, k + 1)):\n        i = k - span\n        \u03b1_i = \u03b1[i]\n        for j in range(i + 1, k):\n            chart_ij = chart[j][i]\n\n            \u03b1_j = \u03b1[j]\n            for Y, y in chart_ij.items():\n                for r in r_y_xz[Y]:\n                    X = r.head\n                    Z = r.body[1]\n                    \u03b1_j[Z] += r.w * y * \u03b1_i[X]\n\n    # Preterminal\n    q = cfg.R.chart()\n    tmp = \u03b1[k - 1]\n    for w in cfg.V:\n        for r in terminal[w]:\n            q[w] += r.w * tmp[r.head]\n\n    return q\n</code></pre>"},{"location":"reference/genlm/grammar/parse/cky/#genlm.grammar.parse.cky.IncrementalCKY.p_next","title":"<code>p_next(prefix)</code>","text":"<p>Compute the weights for all possible next tokens given a prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <p>The current sequence of tokens</p> required <p>Returns:</p> Type Description <p>Dictionary mapping possible next tokens to their weights</p> Source code in <code>genlm/grammar/parse/cky.py</code> <pre><code>def p_next(self, prefix):\n    \"\"\"\n    Compute the weights for all possible next tokens given a prefix.\n\n    Args:\n        prefix: The current sequence of tokens\n\n    Returns:\n        Dictionary mapping possible next tokens to their weights\n    \"\"\"\n    return self.next_token_weights(self.chart(prefix), prefix)\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley/","title":"earley","text":""},{"location":"reference/genlm/grammar/parse/earley/#genlm.grammar.parse.earley.Earley","title":"<code>Earley</code>","text":"<p>Implements a semiring-weighted version Earley's algorithm that runs in $\\mathcal{O}(N^3|G|)$ time. Note that nullary rules and unary chain cycles will be been removed, altering the set of derivation trees.</p> Source code in <code>genlm/grammar/parse/earley.py</code> <pre><code>class Earley:\n    \"\"\"\n    Implements a semiring-weighted version Earley's algorithm that runs in $\\mathcal{O}(N^3|G|)$ time.\n    Note that nullary rules and unary chain cycles will be been removed, altering the\n    set of derivation trees.\n    \"\"\"\n\n    __slots__ = (\n        \"cfg\",\n        \"order\",\n        \"_chart\",\n        \"V\",\n        \"eos\",\n        \"_initial_column\",\n        \"R_outgoing\",\n        \"rhs\",\n        \"ORDER_MAX\",\n        \"intern_Ys\",\n        \"unit_Ys\",\n        \"first_Ys\",\n        \"rest_Ys\",\n    )\n\n    def __init__(self, cfg):\n        cfg = cfg.nullaryremove(binarize=True).unarycycleremove().renumber()\n        self.cfg = cfg\n\n        # cache of chart columns\n        self._chart = {}\n\n        # Topological ordering on the grammar symbols so that we process unary\n        # rules in a topological order.\n        self.order = cfg._unary_graph_transpose().buckets\n\n        self.ORDER_MAX = 1 + max(self.order.values())\n\n        # left-corner graph\n        R_outgoing = defaultdict(set)\n        for r in cfg:\n            if len(r.body) == 0:\n                continue\n            A = r.head\n            B = r.body[0]\n            if cfg.is_terminal(B):\n                continue\n            R_outgoing[A].add(B)\n        self.R_outgoing = R_outgoing\n\n        # Integerize rule right-hand side states\n        intern_Ys = Integerizer()\n        assert intern_Ys(()) == 0\n\n        for r in self.cfg:\n            for p in range(len(r.body) + 1):\n                intern_Ys.add(r.body[p:])\n\n        self.intern_Ys = intern_Ys\n\n        self.rhs = {}\n        for X in self.cfg.N:\n            self.rhs[X] = []\n            for r in self.cfg.rhs[X]:\n                if r.body == ():\n                    continue\n                self.rhs[X].append((r.w, intern_Ys(r.body)))\n\n        self.first_Ys = np.zeros(len(intern_Ys), dtype=object)\n        self.rest_Ys = np.zeros(len(intern_Ys), dtype=int)\n        self.unit_Ys = np.zeros(len(intern_Ys), dtype=int)\n\n        for Ys, code in list(self.intern_Ys.items()):\n            self.unit_Ys[code] = len(Ys) == 1\n            if len(Ys) &gt; 0:\n                self.first_Ys[code] = Ys[0]\n                self.rest_Ys[code] = intern_Ys(Ys[1:])\n\n        # self.generate_rust_test_case()\n\n        col = Column(0)\n        self.PREDICT(col)\n        self._initial_column = col\n\n    def clear_cache(self):\n        self._chart.clear()\n\n    def __call__(self, x):\n        N = len(x)\n\n        # return if empty string\n        if N == 0:\n            return sum(r.w for r in self.cfg.rhs[self.cfg.S] if r.body == ())\n\n        # initialize bookkeeping structures\n        self._chart[()] = [self._initial_column]\n\n        cols = self.chart(x)\n\n        value = cols[N].c_chart.get((0, self.cfg.S))\n        return value if value is not None else self.cfg.R.zero\n\n    def chart(self, x):\n        x = tuple(x)\n        c = self._chart.get(x)\n        if c is None:\n            self._chart[x] = c = self._compute_chart(x)\n        return c\n\n    def _compute_chart(self, x):\n        if len(x) == 0:\n            return [self._initial_column]\n        else:\n            chart = self.chart(x[:-1])\n            last_chart = self.next_column(chart, x[-1])\n            return chart + [\n                last_chart\n            ]  # TODO: avoid list addition here as it is not constant time!\n\n    def next_column(self, prev_cols, token):\n        prev_col = prev_cols[-1]\n        next_col = Column(prev_cols[-1].k + 1)\n        next_col_c_chart = next_col.c_chart\n        prev_col_i_chart = prev_col.i_chart\n\n        rest_Ys = self.rest_Ys\n        _update = self._update\n\n        Q = LocatorMaxHeap()\n\n        # SCAN: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * word(J, Y, K)\n        for item in prev_col.waiting_for[token]:\n            (I, X, Ys) = item\n            _update(next_col, Q, I, X, rest_Ys[Ys], prev_col_i_chart[item])\n\n        # ATTACH: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * phrase(J, Y/[], K)\n        while Q:\n            jy = Q.pop()[0]\n            (J, Y) = jy\n\n            col_J = prev_cols[J]\n            col_J_i_chart = col_J.i_chart\n            y = next_col_c_chart[jy]\n            for customer in col_J.waiting_for[Y]:\n                (I, X, Ys) = customer\n                _update(next_col, Q, I, X, rest_Ys[Ys], col_J_i_chart[customer] * y)\n\n        self.PREDICT(next_col)\n\n        return next_col\n\n    def PREDICT(self, col):\n        # PREDICT: phrase(K, X/Ys, K) += rule(X -&gt; Ys) with some filtering heuristics\n        k = col.k\n\n        # Filtering heuristic: Don't create the predicted item (K, X, [...], K)\n        # unless there exists an item that wants the X item that it may\n        # eventually provide.  In other words, for predicting this item to be\n        # useful there must be an item of the form (I, X', [X, ...], K) in this\n        # column for which lc(X', X) is true.\n        if col.k == 0:\n            agenda = [self.cfg.S]\n        else:\n            agenda = list(col.waiting_for)\n\n        outgoing = self.R_outgoing\n\n        reachable = set(agenda)\n\n        while agenda:\n            X = agenda.pop()\n            for Y in outgoing[X]:\n                if Y not in reachable:\n                    reachable.add(Y)\n                    agenda.append(Y)\n\n        rhs = self.rhs\n        _update = self._update\n        for X in reachable:\n            for w, Ys in rhs.get(X, ()):\n                _update(col, None, k, X, Ys, w)\n\n    def _update(self, col, Q, I, X, Ys, value):\n        K = col.k\n        if Ys == 0:\n            # Items of the form phrase(I, X/[], K)\n            item = (I, X)\n            was = col.c_chart.get(item)\n            if was is None:\n                Q[item] = -((K - I) * self.ORDER_MAX + self.order[X])\n                col.c_chart[item] = value\n            else:\n                col.c_chart[item] = was + value\n\n        else:\n            # Items of the form phrase(I, X/[Y|Ys], K)\n            item = (I, X, Ys)\n            was = col.i_chart.get(item)\n            if was is None:\n                col.waiting_for[self.first_Ys[Ys]].append(item)\n                col.i_chart[item] = value\n            else:\n                col.i_chart[item] = was + value\n\n    # We have derived the `next_token_weights` algorithm by backpropagation on\n    # the program with respect to the item `phrase(0, s, K)`.\n    #\n    # ATTACH: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * phrase(J, Y/[], K)\n    #\n    # Directly applying the gradient transformation, we get\n    #\n    # \u2207phrase(0, s/[], K) += 1\n    # \u2207phrase(J, Y/[], K) += phrase(I, X/[Y|Ys], J) * \u2207phrase(I, X/Ys, K)\n    #\n    # Some quick analysis reveals that the `Ys` list must always be [], and\n    # that K is always equal to the final column.  We specialize the program\n    # below:\n    #\n    # \u2207phrase(0, s/[], K) += 1\n    # \u2207phrase(J, Y/[], K) += phrase(I, X/[Y], J) * \u2207phrase(I, X/[], K)\n    #\n    # We can abbreviate the names:\n    #\n    # q(0, s) += 1\n    # q(J, Y) += phrase(I, X/[Y], J) * q(I, X)\n    #\n    # These items satisfy (I &gt; J) and (X &gt; Y) where the latter is the\n    # nonterminal ordering.  Thus, we can efficiently evaluate these equations\n    # by backward chaining.\n    #\n    # The final output is the vector\n    #\n    # p(W) += q(I, X) * phrase(I, X/[W], J)  where len(J) * terminal(W).\n    #\n    def next_token_weights(self, cols):\n        is_terminal = self.cfg.is_terminal\n        zero = self.cfg.R.zero\n\n        q = {}\n        q[0, self.cfg.S] = self.cfg.R.one\n\n        col = cols[-1]\n        col_waiting_for = col.waiting_for\n        col_i_chart = col.i_chart\n\n        # SCAN: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * word(J, Y, K)\n        p = self.cfg.R.chart()\n\n        for Y in col_waiting_for:\n            if is_terminal(Y):\n                total = zero\n                for I, X, Ys in col_waiting_for[Y]:\n                    if self.unit_Ys[Ys]:\n                        node = (I, X)\n                        value = self._helper(node, cols, q)\n                        total += col_i_chart[I, X, Ys] * value\n                p[Y] = total\n\n        return p\n\n    def _helper(self, top, cols, q):\n        value = q.get(top)\n        if value is not None:\n            return value\n\n        zero = self.cfg.R.zero\n        stack = [Node(top, None, zero)]\n\n        while stack:\n            node = stack[-1]  # \ud83d\udc40\n\n            # place neighbors above the node on the stack\n            (J, Y) = node.node\n\n            t = node.cursor\n\n            if node.edges is None:\n                node.edges = [x for x in cols[J].waiting_for[Y] if self.unit_Ys[x[2]]]\n\n            # cursor is at the end, all neighbors are done\n            elif t == len(node.edges):\n                # clear the node from the stack\n                stack.pop()\n                # promote the incomplete value node.value to a complete value (q)\n                q[node.node] = node.value\n\n            else:\n                (I, X, _) = arc = node.edges[t]\n                neighbor = (I, X)\n                neighbor_value = q.get(neighbor)\n                if neighbor_value is None:\n                    stack.append(Node(neighbor, None, zero))\n                else:\n                    # neighbor value is ready, advance the cursor, add the\n                    # neighbors contribution to the nodes value\n                    node.cursor += 1\n                    node.value += cols[J].i_chart[arc] * neighbor_value\n\n        return q[top]\n\n    def generate_rust_test_case(self):\n        # generates a test case in Rust code by exporting the parser state variables\n        # Copy-paste the printout to `mod tests { ... }` in lib.rs to debug.\n\n        print(\n            \"\"\"\n    #[test]\n    fn test_earley() {{\n\n        let rhs: HashMap&lt;u32, Vec&lt;RHS&gt;&gt; = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\n                \", \".join(\n                    f\"({x}, \"\n                    + \"vec![{}])\".format(\", \".join(f\"({float(u)}, {v})\" for u, v in y))\n                    for x, y in self.rhs.items()\n                )\n            )\n        )\n\n        print(\n            \"\"\"\n        let order: HashMap&lt;u32, u32&gt; = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\", \".join(f\"({u}, {v})\" for u, v in self.order.items()))\n        )\n\n        print(\n            \"\"\"\n        let outgoing: HashMap&lt;u32, Vec&lt;u32&gt;&gt; = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\n                \", \".join(\n                    \"({}, vec![{}])\".format(i, \", \".join(map(str, s)))\n                    for i, s in self.R_outgoing.items()\n                )\n            )\n        )\n\n        print(\n            \"\"\"\n        let first_ys = vec![\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\n                \", \".join(\n                    f'Terminal(String::from(\"{y}\"))'\n                    if isinstance(y, str)\n                    else f\"Nonterminal({y})\"\n                    for y in self.first_Ys\n                )\n            )\n        )\n\n        print(\n            \"\"\"\n        let rest_ys = vec![\n            {}\n        ];\n        \"\"\".format(\", \".join(map(str, self.rest_Ys)))\n        )\n\n        print(\n            \"\"\"\n        let unit_ys = vec![\n            {}\n        ];\n        \"\"\".format(\", \".join(map(lambda x: str(bool(x)).lower(), self.unit_Ys)))\n        )\n\n        print(\n            \"\"\"\n        let vocab = [\n            {}\n        ].iter().cloned().collect();\n        \"\"\".format(\", \".join(f'String::from(\"{v}\")' for v in self.cfg.V))\n        )\n\n        print(\n            \"\"\"\n        let empty_weight = {};\n        let start = {};\n        let order_max = {};\n        \"\"\".format(\n                sum(r.w for r in self.cfg.rhs[self.cfg.S] if r.body == ()),\n                self.cfg.S,\n                self.ORDER_MAX,\n            )\n        )\n\n        print(\"\"\"\n        let mut earley = Earley::new(\n            rhs, start, order, order_max, outgoing, first_ys,\n            rest_ys, unit_ys, vocab, empty_weight,\n        );\n        let chart = earley.p_next(vec![]);\n        dbg!(&amp;chart);\n\n    }}\n        \"\"\")\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/","title":"earley_rescaled","text":""},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.Column","title":"<code>Column</code>","text":"<p>Represents a column in the Earley chart at position k in the input.</p> <p>Attributes:</p> Name Type Description <code>k</code> <p>Position in the input string</p> <code>i_chart</code> <p>Dictionary of incomplete items</p> <code>c_chart</code> <p>Dictionary of complete items</p> <code>waiting_for</code> <p>Maps nonterminals to items waiting for them</p> <code>Q</code> <p>Priority queue for processing items</p> <code>rescale</code> <p>Rescaling coefficient for numerical stability</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>class Column:\n    \"\"\"\n    Represents a column in the Earley chart at position k in the input.\n\n    Attributes:\n        k: Position in the input string\n        i_chart: Dictionary of incomplete items\n        c_chart: Dictionary of complete items\n        waiting_for: Maps nonterminals to items waiting for them\n        Q: Priority queue for processing items\n        rescale: Rescaling coefficient for numerical stability\n    \"\"\"\n\n    __slots__ = (\"k\", \"i_chart\", \"c_chart\", \"waiting_for\", \"Q\", \"rescale\")\n\n    def __init__(self, k):\n        self.k = k\n        self.i_chart = {}\n        self.c_chart = {}\n\n        # Within column J, this datastructure maps nonterminals Y to a set of items\n        #   Y =&gt; {(I, X, Ys) | phrase(I,X/[Y],J) \u2260 0}\n        self.waiting_for = defaultdict(list)\n\n        # priority queue used when first filling the column\n        self.Q = LocatorMaxHeap()\n\n        self.rescale = None\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.Earley","title":"<code>Earley</code>","text":"<p>Implements a semiring-weighted version of Earley's algorithm with O(N\u00b3|G|) time complexity.</p> <p>This implementation includes rescaling for numerical stability and supports weighted grammars.</p> Warning <p>Assumes that nullary rules and unary chain cycles have been removed.</p> <p>Attributes:</p> Name Type Description <code>cfg</code> <p>Context-free grammar (preprocessed)</p> <code>order</code> <p>Topological ordering of grammar symbols</p> <code>_chart</code> <p>Cache of computed chart columns</p> <code>R</code> <p>Left-corner graph</p> <code>rhs</code> <p>Cached right-hand sides of rules</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>class Earley:\n    \"\"\"\n    Implements a semiring-weighted version of Earley's algorithm with O(N\u00b3|G|) time complexity.\n\n    This implementation includes rescaling for numerical stability and supports weighted grammars.\n\n    Warning:\n        Assumes that nullary rules and unary chain cycles have been removed.\n\n    Attributes:\n        cfg: Context-free grammar (preprocessed)\n        order: Topological ordering of grammar symbols\n        _chart: Cache of computed chart columns\n        R: Left-corner graph\n        rhs: Cached right-hand sides of rules\n    \"\"\"\n\n    __slots__ = (\n        \"cfg\",\n        \"order\",\n        \"_chart\",\n        \"V\",\n        \"eos\",\n        \"_initial_column\",\n        \"R\",\n        \"rhs\",\n        \"ORDER_MAX\",\n        \"intern_Ys\",\n        \"unit_Ys\",\n        \"first_Ys\",\n        \"rest_Ys\",\n    )\n\n    def __init__(self, cfg):\n        cfg = cfg.nullaryremove(binarize=True).unarycycleremove().renumber()\n        self.cfg = cfg\n\n        # cache of chart columns\n        self._chart = {}\n\n        # Topological ordering on the grammar symbols so that we process unary\n        # rules in a topological order.\n        self.order = cfg._unary_graph_transpose().buckets\n\n        self.ORDER_MAX = max(self.order.values())\n\n        # left-corner graph\n        R = WeightedGraph(Boolean)\n        for r in cfg:\n            if len(r.body) == 0:\n                continue\n            A = r.head\n            B = r.body[0]\n            R[A, B] += Boolean.one\n        self.R = R\n\n        # Integerize rule right-hand side states\n        intern_Ys = Integerizer()\n        assert intern_Ys(()) == 0\n\n        for r in self.cfg:\n            for p in range(len(r.body) + 1):\n                intern_Ys.add(r.body[p:])\n\n        self.intern_Ys = intern_Ys\n\n        self.rhs = {}\n        for X in self.cfg.N:\n            self.rhs[X] = []\n            for r in self.cfg.rhs[X]:\n                if r.body == ():\n                    continue\n                self.rhs[X].append((r.w, intern_Ys(r.body)))\n\n        self.first_Ys = np.zeros(len(intern_Ys), dtype=object)\n        self.rest_Ys = np.zeros(len(intern_Ys), dtype=int)\n        self.unit_Ys = np.zeros(len(intern_Ys), dtype=int)\n\n        for Ys, code in list(self.intern_Ys.items()):\n            self.unit_Ys[code] = len(Ys) == 1\n            if len(Ys) &gt; 0:\n                self.first_Ys[code] = Ys[0]\n                self.rest_Ys[code] = intern_Ys(Ys[1:])\n\n        col = Column(0)\n        self.PREDICT(col)\n        col.rescale = self.cfg.R.one\n        col.Q = None\n        self._initial_column = col\n\n    def clear_cache(self):\n        self._chart.clear()\n\n    def __call__(self, x):\n        N = len(x)\n\n        # return if empty string\n        if N == 0:\n            return sum(r.w for r in self.cfg.rhs[self.cfg.S] if r.body == ())\n\n        # initialize bookkeeping structures\n        self._chart[()] = [self._initial_column]\n\n        cols = self.chart(x)\n\n        value = cols[N].c_chart.get((0, self.cfg.S), self.cfg.R.zero)\n        return value / self.rescale(cols, 0, N)\n\n    def rescale(self, cols, I, K):\n        \"returns the product of the rescaling coefficients for `cols[I:K]`.\"\n        C = self.cfg.R.one\n        for c in cols[I:K]:\n            C *= c.rescale\n        return C\n\n    def log_rescale(self, cols, I, K):\n        \"returns the product of the rescaling coefficients for `cols[I:K]`.\"\n        return sum(np.log(c.rescale) for c in cols[I:K])\n\n    def chart(self, x):\n        x = tuple(x)\n        c = self._chart.get(x)\n        if c is None:\n            self._chart[x] = c = self._compute_chart(x)\n        return c\n\n    def _compute_chart(self, x):\n        if len(x) == 0:\n            return [self._initial_column]\n        else:\n            chart = self.chart(x[:-1])\n            last_chart = self.next_column(chart, x[-1])\n            return chart + [\n                last_chart\n            ]  # TODO: avoid list addition here as it is not constant time!\n\n    def logp(self, x):\n        cols = self.chart(x)\n        N = len(x)\n        return np.log(\n            cols[N].c_chart.get((0, self.cfg.S), self.cfg.R.zero)\n        ) - self.log_rescale(cols, 0, N)\n\n    def next_column(self, prev_cols, token):\n        prev_col = prev_cols[-1]\n        next_col = Column(prev_cols[-1].k + 1)\n        next_col_c_chart = next_col.c_chart\n        prev_col_i_chart = prev_col.i_chart\n\n        rest_Ys = self.rest_Ys\n        _update = self._update\n\n        # SCAN: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * word(J, Y, K)\n        for item in prev_col.waiting_for[token]:\n            (I, X, Ys) = item\n            _update(\n                next_col,\n                I,\n                X,\n                rest_Ys[Ys],\n                prev_col_i_chart[item] * prev_col.rescale,\n            )\n\n        # ATTACH: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * phrase(J, Y/[], K)\n        Q = next_col.Q\n        while Q:\n            (J, Y) = item = Q.pop()[0]\n            col_J = prev_cols[J]\n            col_J_i_chart = col_J.i_chart\n            y = next_col_c_chart[item]\n            for item in col_J.waiting_for[Y]:\n                (I, X, Ys) = item\n                _update(next_col, I, X, rest_Ys[Ys], col_J_i_chart[item] * y)\n\n        self.PREDICT(next_col)\n\n        num = prev_col.c_chart.get((0, self.cfg.S), self.cfg.R.zero)\n        den = next_col.c_chart.get((0, self.cfg.S), self.cfg.R.zero)\n\n        if den == 0 or num == 0:\n            next_col.rescale = 1\n        else:\n            next_col.rescale = num / den * prev_col.rescale\n\n        next_col.Q = None  # optional: free up some memory\n\n        return next_col\n\n    def PREDICT(self, col):\n        # PREDICT: phrase(K, X/Ys, K) += rule(X -&gt; Ys) with some filtering heuristics\n        k = col.k\n\n        # Filtering heuristic: Don't create the predicted item (K, X, [...], K)\n        # unless there exists an item that wants the X item that it may\n        # eventually provide.  In other words, for predicting this item to be\n        # useful there must be an item of the form (I, X', [X, ...], K) in this\n        # column for which lc(X', X) is true.\n        if col.k == 0:\n            targets = {self.cfg.S}\n        else:\n            targets = set(col.waiting_for)\n\n        reachable = set(targets)\n        agenda = list(targets)\n        while agenda:\n            X = agenda.pop()\n            for Y in self.R.outgoing[X]:\n                if Y not in reachable:\n                    reachable.add(Y)\n                    agenda.append(Y)\n\n        rhs = self.rhs\n        for X in reachable:\n            for w, Ys in rhs.get(X, ()):\n                self._update(col, k, X, Ys, w)\n\n    def _update(self, col, I, X, Ys, value):\n        K = col.k\n        if Ys == 0:\n            # Items of the form phrase(I, X/[], K)\n            item = (I, X)\n            was = col.c_chart.get(item)\n            if was is None:\n                col.Q[item] = -((K - I) * self.ORDER_MAX + self.order[X])\n                col.c_chart[item] = value\n            else:\n                col.c_chart[item] = was + value\n\n        else:\n            # Items of the form phrase(I, X/[Y|Ys], K)\n            item = (I, X, Ys)\n            was = col.i_chart.get(item)\n            if was is None:\n                col.waiting_for[self.first_Ys[Ys]].append(item)\n                col.i_chart[item] = value\n            else:\n                col.i_chart[item] = was + value\n\n    # We have derived the `next_token_weights` algorithm by backpropagation on\n    # the program with respect to the item `phrase(0, s, K)`.\n    #\n    # ATTACH: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * phrase(J, Y/[], K)\n    #\n    # Directly applying the gradient transformation, we get\n    #\n    # \u2207phrase(0, s/[], K) += 1\n    # \u2207phrase(J, Y/[], K) += phrase(I, X/[Y|Ys], J) * \u2207phrase(I, X/Ys, K)\n    #\n    # Some quick analysis reveals that the `Ys` list must always be [], and\n    # that K is always equal to the final column.  We specialize the program\n    # below:\n    #\n    # \u2207phrase(0, s/[], K) += 1\n    # \u2207phrase(J, Y/[], K) += phrase(I, X/[Y], J) * \u2207phrase(I, X/[], K)\n    #\n    # We can abbreviate the names:\n    #\n    # q(0, s) += 1\n    # q(J, Y) += phrase(I, X/[Y], J) * q(I, X)\n    #\n    # These items satisfy (I &gt; J) and (X &gt; Y) where the latter is the\n    # nonterminal ordering.\n\n    def next_token_weights(self, cols):\n        \"An O(N\u00b2) time algorithm to the total weight of a each next-token extension.\"\n        # XXX: the rescaling coefficient will cancel out when we normalized the next-token weights\n        # C = self.rescale(chart, 0, N-1)\n\n        is_terminal = self.cfg.is_terminal\n        zero = self.cfg.R.zero\n\n        q = {}\n        q[0, self.cfg.S] = self.cfg.R.one\n\n        col = cols[-1]\n        col_waiting_for = col.waiting_for\n        col_i_chart = col.i_chart\n\n        # SCAN: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * word(J, Y, K)\n        p = self.cfg.R.chart()\n\n        for Y in col_waiting_for:\n            if is_terminal(Y):\n                total = zero\n                for I, X, Ys in col_waiting_for[Y]:\n                    if self.unit_Ys[Ys]:\n                        node = (I, X)\n                        value = self._helper(node, cols, q)\n                        total += col_i_chart[I, X, Ys] * value\n                p[Y] = total\n\n        p = p.trim()\n        return p.normalize() if p else p\n\n    def _helper(self, top, cols, q):\n        value = q.get(top)\n        if value is not None:\n            return value\n\n        zero = self.cfg.R.zero\n        stack = [Node(top, None, zero)]\n\n        while stack:\n            node = stack[-1]  # \ud83d\udc40\n\n            # place neighbors above the node on the stack\n            (J, Y) = node.node\n\n            t = node.cursor\n\n            if node.edges is None:\n                node.edges = [x for x in cols[J].waiting_for[Y] if self.unit_Ys[x[2]]]\n\n            # cursor is at the end, all neighbors are done\n            elif t == len(node.edges):\n                # clear the node from the stack\n                stack.pop()\n                # promote the incomplete value node.value to a complete value (q)\n                q[node.node] = node.value\n\n            else:\n                (I, X, _) = arc = node.edges[t]\n                neighbor = (I, X)\n                neighbor_value = q.get(neighbor)\n                if neighbor_value is None:\n                    stack.append(Node(neighbor, None, zero))\n                else:\n                    # neighbor value is ready, advance the cursor, add the\n                    # neighbors contribution to the nodes value\n                    node.cursor += 1\n                    node.value += cols[J].i_chart[arc] * neighbor_value\n\n        return q[top]\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.Earley.log_rescale","title":"<code>log_rescale(cols, I, K)</code>","text":"<p>returns the product of the rescaling coefficients for <code>cols[I:K]</code>.</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>def log_rescale(self, cols, I, K):\n    \"returns the product of the rescaling coefficients for `cols[I:K]`.\"\n    return sum(np.log(c.rescale) for c in cols[I:K])\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.Earley.next_token_weights","title":"<code>next_token_weights(cols)</code>","text":"<p>An O(N\u00b2) time algorithm to the total weight of a each next-token extension.</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>def next_token_weights(self, cols):\n    \"An O(N\u00b2) time algorithm to the total weight of a each next-token extension.\"\n    # XXX: the rescaling coefficient will cancel out when we normalized the next-token weights\n    # C = self.rescale(chart, 0, N-1)\n\n    is_terminal = self.cfg.is_terminal\n    zero = self.cfg.R.zero\n\n    q = {}\n    q[0, self.cfg.S] = self.cfg.R.one\n\n    col = cols[-1]\n    col_waiting_for = col.waiting_for\n    col_i_chart = col.i_chart\n\n    # SCAN: phrase(I, X/Ys, K) += phrase(I, X/[Y|Ys], J) * word(J, Y, K)\n    p = self.cfg.R.chart()\n\n    for Y in col_waiting_for:\n        if is_terminal(Y):\n            total = zero\n            for I, X, Ys in col_waiting_for[Y]:\n                if self.unit_Ys[Ys]:\n                    node = (I, X)\n                    value = self._helper(node, cols, q)\n                    total += col_i_chart[I, X, Ys] * value\n            p[Y] = total\n\n    p = p.trim()\n    return p.normalize() if p else p\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.Earley.rescale","title":"<code>rescale(cols, I, K)</code>","text":"<p>returns the product of the rescaling coefficients for <code>cols[I:K]</code>.</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>def rescale(self, cols, I, K):\n    \"returns the product of the rescaling coefficients for `cols[I:K]`.\"\n    C = self.cfg.R.one\n    for c in cols[I:K]:\n        C *= c.rescale\n    return C\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.EarleyLM","title":"<code>EarleyLM</code>","text":"<p>               Bases: <code>LM</code></p> <p>Language model using Earley parsing for context-free grammars.</p> <p>Implements a language model using Earley's algorithm for incremental parsing of context-free grammars. The grammar is automatically converted to prefix form for efficient left-to-right processing.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use as the language model</p> required <p>Attributes:</p> Name Type Description <code>cfg</code> <code>CFG</code> <p>The original context-free grammar before prefix transformation</p> <code>model</code> <code>Earley</code> <p>The Earley parser for computing probabilities</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>class EarleyLM(LM):\n    \"\"\"Language model using Earley parsing for context-free grammars.\n\n    Implements a language model using Earley's algorithm for incremental parsing of\n    context-free grammars. The grammar is automatically converted to prefix form for\n    efficient left-to-right processing.\n\n    Args:\n        cfg (CFG): The context-free grammar to use as the language model\n\n    Attributes:\n        cfg (CFG): The original context-free grammar before prefix transformation\n        model (Earley): The Earley parser for computing probabilities\n    \"\"\"\n\n    def __init__(self, cfg):\n        \"\"\"Initialize an Earley-based language model.\n\n        Args:\n            cfg (CFG): The context-free grammar to use as the language model. Will be\n                converted to prefix form for incremental parsing.\n\n        Raises:\n            AssertionError: If EOS token not in grammar vocabulary after transformation\n        \"\"\"\n        if EOS not in cfg.V:\n            cfg = add_EOS(cfg)\n        self.cfg = cfg  # Note: &lt;- cfg before prefix transform &amp; normalization!\n        self.model = Earley(cfg.prefix_grammar)\n        super().__init__(V=cfg.V, eos=EOS)\n\n    def p_next(self, context):\n        \"\"\"Compute probability distribution over next tokens given a context.\n\n        Args:\n            context: Sequence of tokens representing the prefix\n\n        Returns:\n            Normalized probability distribution over possible next tokens\n\n        Raises:\n            AssertionError: If context contains tokens not in vocabulary\n        \"\"\"\n        assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n        return self.model.next_token_weights(self.model.chart(context)).normalize()\n\n    def clear_cache(self):\n        \"\"\"Clear the parser's chart cache.\"\"\"\n        self.model.clear_cache()\n\n    @classmethod\n    def from_string(cls, x, semiring=Float, **kwargs):\n        \"\"\"Create an EarleyLM from a grammar string representation.\n\n        Args:\n            x (str): String representation of the grammar\n            semiring: Semiring to use for weights (default: Float)\n            **kwargs: Additional arguments for grammar normalization\n\n        Returns:\n            EarleyLM: A new language model instance\n        \"\"\"\n        return cls(locally_normalize(CFG.from_string(x, semiring), **kwargs))\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.EarleyLM.__init__","title":"<code>__init__(cfg)</code>","text":"<p>Initialize an Earley-based language model.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>CFG</code> <p>The context-free grammar to use as the language model. Will be converted to prefix form for incremental parsing.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If EOS token not in grammar vocabulary after transformation</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>def __init__(self, cfg):\n    \"\"\"Initialize an Earley-based language model.\n\n    Args:\n        cfg (CFG): The context-free grammar to use as the language model. Will be\n            converted to prefix form for incremental parsing.\n\n    Raises:\n        AssertionError: If EOS token not in grammar vocabulary after transformation\n    \"\"\"\n    if EOS not in cfg.V:\n        cfg = add_EOS(cfg)\n    self.cfg = cfg  # Note: &lt;- cfg before prefix transform &amp; normalization!\n    self.model = Earley(cfg.prefix_grammar)\n    super().__init__(V=cfg.V, eos=EOS)\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.EarleyLM.clear_cache","title":"<code>clear_cache()</code>","text":"<p>Clear the parser's chart cache.</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>def clear_cache(self):\n    \"\"\"Clear the parser's chart cache.\"\"\"\n    self.model.clear_cache()\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.EarleyLM.from_string","title":"<code>from_string(x, semiring=Float, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create an EarleyLM from a grammar string representation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>String representation of the grammar</p> required <code>semiring</code> <p>Semiring to use for weights (default: Float)</p> <code>Float</code> <code>**kwargs</code> <p>Additional arguments for grammar normalization</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>EarleyLM</code> <p>A new language model instance</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>@classmethod\ndef from_string(cls, x, semiring=Float, **kwargs):\n    \"\"\"Create an EarleyLM from a grammar string representation.\n\n    Args:\n        x (str): String representation of the grammar\n        semiring: Semiring to use for weights (default: Float)\n        **kwargs: Additional arguments for grammar normalization\n\n    Returns:\n        EarleyLM: A new language model instance\n    \"\"\"\n    return cls(locally_normalize(CFG.from_string(x, semiring), **kwargs))\n</code></pre>"},{"location":"reference/genlm/grammar/parse/earley_rescaled/#genlm.grammar.parse.earley_rescaled.EarleyLM.p_next","title":"<code>p_next(context)</code>","text":"<p>Compute probability distribution over next tokens given a context.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <p>Sequence of tokens representing the prefix</p> required <p>Returns:</p> Type Description <p>Normalized probability distribution over possible next tokens</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If context contains tokens not in vocabulary</p> Source code in <code>genlm/grammar/parse/earley_rescaled.py</code> <pre><code>def p_next(self, context):\n    \"\"\"Compute probability distribution over next tokens given a context.\n\n    Args:\n        context: Sequence of tokens representing the prefix\n\n    Returns:\n        Normalized probability distribution over possible next tokens\n\n    Raises:\n        AssertionError: If context contains tokens not in vocabulary\n    \"\"\"\n    assert set(context) &lt;= self.V, f\"OOVs detected: {set(context) - self.V}\"\n    return self.model.next_token_weights(self.model.chart(context)).normalize()\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/__init__/","title":"wfsa","text":""},{"location":"reference/genlm/grammar/wfsa/__init__/#genlm.grammar.wfsa.WFSA","title":"<code>WFSA</code>","text":"<p>               Bases: <code>WFSA</code></p> <p>Weighted finite-state automata where weights are a field (e.g., real-valued).</p> Source code in <code>genlm/grammar/wfsa/field_wfsa.py</code> <pre><code>class WFSA(base.WFSA):\n    \"\"\"\n    Weighted finite-state automata where weights are a field (e.g., real-valued).\n    \"\"\"\n\n    def __init__(self, R=Float):\n        super().__init__(R=R)\n\n    def __hash__(self):\n        return hash(self.simple)\n\n    def threshold(self, threshold):\n        \"Drop init, arcs, final below a given abs-threshold.\"\n        m = self.__class__(self.R)\n        for q, w in self.I:\n            if abs(w) &gt;= threshold:\n                m.add_I(q, w)\n        for i, a, j, w in self.arcs():\n            if abs(w) &gt;= threshold:\n                m.add_arc(i, a, j, w)\n        for q, w in self.F:\n            if abs(w) &gt;= threshold:\n                m.add_F(q, w)\n        return m\n\n    def graphviz(\n        self,\n        fmt=lambda x: f\"{round(x, 3):g}\" if isinstance(x, (float, int)) else str(x),\n        **kwargs,\n    ):  # pylint: disable=arguments-differ\n        return super().graphviz(fmt=fmt, **kwargs)\n\n    @cached_property\n    def simple(self):\n        self = self.epsremove.renumber\n\n        S = self.dim\n        start = np.full(S, self.R.zero)\n        arcs = {a: np.full((S, S), self.R.zero) for a in self.alphabet}\n        stop = np.full(S, self.R.zero)\n\n        for i, w in self.I:\n            start[i] += w\n        for i, a, j, w in self.arcs():\n            arcs[a][i, j] += w\n        for i, w in self.F:\n            stop[i] += w\n\n        assert EPSILON not in arcs\n\n        return Simple(start, arcs, stop)\n\n    def __eq__(self, other):\n        return self.simple == other.simple\n\n    def counterexample(self, other):\n        return self.simple.counterexample(other.simple)\n\n    @cached_property\n    def min(self):\n        return self.simple.min.to_wfsa()\n\n    #    @cached_property\n    #    def epsremove(self):\n    #        return self.simple.to_wfsa()\n\n    def multiplicity(self, m):\n        return WFSA.lift(EPSILON, m) * self\n\n    @classmethod\n    def lift(cls, x, w, R=None):\n        if R is None:\n            R = Float\n        m = cls(R=R)\n        m.add_I(0, R.one)\n        m.add_arc(0, x, 1, w)\n        m.add_F(1, R.one)\n        return m\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/__init__/#genlm.grammar.wfsa.WFSA.threshold","title":"<code>threshold(threshold)</code>","text":"<p>Drop init, arcs, final below a given abs-threshold.</p> Source code in <code>genlm/grammar/wfsa/field_wfsa.py</code> <pre><code>def threshold(self, threshold):\n    \"Drop init, arcs, final below a given abs-threshold.\"\n    m = self.__class__(self.R)\n    for q, w in self.I:\n        if abs(w) &gt;= threshold:\n            m.add_I(q, w)\n    for i, a, j, w in self.arcs():\n        if abs(w) &gt;= threshold:\n            m.add_arc(i, a, j, w)\n    for q, w in self.F:\n        if abs(w) &gt;= threshold:\n            m.add_F(q, w)\n    return m\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/base/","title":"base","text":""},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA","title":"<code>WFSA</code>","text":"<p>Weighted finite-state automata</p> Source code in <code>genlm/grammar/wfsa/base.py</code> <pre><code>class WFSA:\n    \"\"\"\n    Weighted finite-state automata\n    \"\"\"\n\n    def __init__(self, R):\n        self.R = R\n        self.alphabet = set()\n        self.states = set()\n        self.delta = defaultdict(lambda: defaultdict(R.chart))\n        self.start = R.chart()\n        self.stop = R.chart()\n\n    def __repr__(self):\n        return f\"{__class__.__name__}({self.dim} states)\"\n\n    def __str__(self):\n        output = []\n        output.append(\"{\")\n        for p in self.states:\n            output.append(f\"  {p} \\t\\t({self.start[p]}, {self.stop[p]})\")\n            for a, q, w in self.arcs(p):\n                output.append(f\"    {a}: {q}\\t[{w}]\")\n        output.append(\"}\")\n        return \"\\n\".join(output)\n\n    @property\n    def dim(self):\n        return len(self.states)\n\n    def add_state(self, q):\n        self.states.add(q)\n\n    def add_arc(self, i, a, j, w):\n        self.add_state(i)\n        self.add_state(j)\n        self.alphabet.add(a)\n        self.delta[i][a][j] += w\n\n    def add_I(self, q, w):\n        self.add_state(q)\n        self.start[q] += w\n\n    def add_F(self, q, w):\n        self.add_state(q)\n        self.stop[q] += w\n\n    def set_arc(self, i, a, j, w):\n        self.add_state(i)\n        self.add_state(j)\n        self.alphabet.add(a)\n        self.delta[i][a][j] = w\n\n    def set_I(self, q, w):\n        self.add_state(q)\n        self.start[q] = w\n\n    def set_F(self, q, w):\n        self.add_state(q)\n        self.stop[q] = w\n\n    @property\n    def I(self):\n        for q, w in self.start.items():\n            if w != self.R.zero:\n                yield q, w\n\n    @property\n    def F(self):\n        for q, w in self.stop.items():\n            if w != self.R.zero:\n                yield q, w\n\n    def arcs(self, i=None, a=None):\n        if i is not None:\n            if a is not None:\n                for j, w in self.delta[i][a].items():\n                    yield j, w\n            else:\n                for a, T in self.delta[i].items():\n                    for j, w in T.items():\n                        yield a, j, w\n        else:\n            if a is None:\n                for i in self.delta:\n                    for a, T in self.delta[i].items():\n                        for j, w in T.items():\n                            yield i, a, j, w\n            else:\n                raise NotImplementedError\n\n    def rename(self, f):\n        \"Note: If `f` is not bijective, states may merge.\"\n        m = self.spawn()\n        for i, w in self.I:\n            m.add_I(f(i), w)\n        for i, w in self.F:\n            m.add_F(f(i), w)\n        for i, a, j, w in self.arcs():\n            m.add_arc(f(i), a, f(j), w)\n        return m\n\n    def to_fst(self):\n        from genlm.grammar.fst import FST\n\n        return FST.diag(self)\n\n    def rename_apart(self, other):\n        f = Integerizer()\n        return (self.rename(lambda i: f((0, i))), other.rename(lambda i: f((1, i))))\n\n    @cached_property\n    def renumber(self):\n        return self.rename(Integerizer())\n\n    def spawn(self, *, keep_init=False, keep_arcs=False, keep_stop=False):\n        \"Returns a new WFSA in the same semiring.\"\n        m = self.__class__(self.R)\n        if keep_init:\n            for q, w in self.I:\n                m.add_I(q, w)\n        if keep_arcs:\n            for i, a, j, w in self.arcs():\n                m.add_arc(i, a, j, w)\n        if keep_stop:\n            for q, w in self.F:\n                m.add_F(q, w)\n        return m\n\n    def __call__(self, xs):\n        self = self.epsremove\n        prev = self.start\n        for x in xs:\n            curr = self.R.chart()\n            for i in prev:\n                for j, w in self.arcs(i, x):\n                    curr[j] += prev[i] * w\n            prev = curr\n        total = self.R.zero\n        for j, w in self.F:\n            total += prev[j] * w\n        return total\n\n    @cached_property\n    def E(self):\n        \"Weighted graph of epsilon arcs\"\n        E = WeightedGraph(self.R)\n        for i, a, j, w in self.arcs():\n            if a == EPSILON:\n                E[i, j] += w\n        E.N |= self.states\n        return E\n\n    @cached_property\n    def epsremove(self):\n        \"Return an equivalent machine with no epsilon arcs.\"\n        E = self.E\n        S = E.closure()\n        new = self.spawn(keep_stop=True)\n        for i, w_i in self.I:\n            for k in S.outgoing[i]:\n                new.add_I(k, w_i * S[i, k])\n        for i, a, j, w_ij in self.arcs():\n            if a == EPSILON:\n                continue\n            for k in S.outgoing[j]:\n                new.add_arc(i, a, k, w_ij * S[j, k])\n        return new\n\n    @cached_property\n    def reverse(self):\n        \"creates a reversed machine\"\n        # create the new machine\n        R = self.spawn()\n        # reverse each arc\n        for i, a, j, w in self.arcs():\n            R.add_arc(j, a, i, w)  # pylint: disable=arguments-out-of-order\n        # reverse initial and final states\n        for i, w in self.F:\n            R.add_I(i, w)\n        for i, w in self.I:\n            R.add_F(i, w)\n        return R\n\n    def __add__(self, other):\n        self, other = self.rename_apart(other)\n        U = self.spawn(keep_init=True, keep_arcs=True, keep_stop=True)\n        # add arcs, initial and final states from argument\n        for i, a, j, w in other.arcs():\n            U.add_arc(i, a, j, w)\n        for q, w in other.I:\n            U.add_I(q, w)\n        for q, w in other.F:\n            U.add_F(q, w)\n        return U\n\n    #    def __sub__(self, other):\n    #        \"Assumes -w exists for all weights.\"\n    #        self, other = self.rename_apart(other)\n    #        U = self.spawn(keep_init=True, keep_arcs=True, keep_stop=True)\n    #        # add arcs, initial and final states from argument\n    #        for q, w in other.I:            U.add_I(q, -w)\n    #        for i, a, j, w in other.arcs(): U.add_arc(i, a, j, w)\n    #        for q, w in other.F:            U.add_F(q, w)\n    #        return U\n\n    def __mul__(self, other):\n        #        if not isinstance(other, self.__class__): return other.__rmul__(self)\n\n        self, other = self.rename_apart(other)\n        C = self.spawn(keep_init=True, keep_arcs=True)\n        # add arcs, initial and final states from argument\n        for i, a, j, w in other.arcs():\n            C.add_arc(i, a, j, w)\n        for q, w in other.F:\n            C.add_F(q, w)\n        # connect the final states from `self` to initial states from `other`\n        for i1, w1 in self.F:\n            for i2, w2 in other.I:\n                C.add_arc(i1, EPSILON, i2, w1 * w2)\n        return C\n\n    @property\n    def zero(self):\n        return self.__class__(self.R)\n\n    @property\n    def one(self):\n        return self.__class__.lift(EPSILON, self.R.one)\n\n    def star(self):\n        return self.one + self.kleene_plus()\n\n    def kleene_plus(self):\n        \"self^+\"\n        m = self.spawn(keep_init=True, keep_arcs=True, keep_stop=True)\n        for i, w1 in self.F:\n            for j, w2 in self.I:\n                m.add_arc(i, EPSILON, j, w1 * w2)\n        return m\n\n    def _repr_svg_(self):\n        return self.graphviz()._repr_image_svg_xml()\n\n    def graphviz(\n        self,\n        fmt=str,\n        fmt_node=lambda x: \" \",\n        fmt_edge=lambda i,\n        a,\n        j,\n        w: f\"{html.escape(str(':'.join(str(A or '\u03b5') for A in a)) if isinstance(a, tuple) else str(a))}/{w}\",\n    ):\n        if len(self.states) == 0:\n            import warnings\n\n            warnings.warn(\"empty visualization\")\n        g = Digraph(\n            graph_attr=dict(rankdir=\"LR\"),\n            node_attr=dict(\n                fontname=\"Monospace\",\n                fontsize=\"10\",\n                height=\".05\",\n                width=\".05\",\n                # margin=\"0.055,0.042\"\n                margin=\"0,0\",\n            ),\n            edge_attr=dict(\n                # arrowhead='vee',\n                arrowsize=\"0.3\",\n                fontname=\"Monospace\",\n                fontsize=\"9\",\n            ),\n        )\n        f = Integerizer()\n        for i, w in self.I:\n            start = f\"&lt;start_{i}&gt;\"\n            g.node(start, label=\"\", shape=\"point\", height=\"0\", width=\"0\")\n            g.edge(start, str(f(i)), label=f\"{fmt(w)}\")\n        for i in self.states:\n            g.node(str(f(i)), label=str(fmt_node(i)), shape=\"circle\")\n        for i, w in self.F:\n            stop = f\"&lt;stop_{i}&gt;\"\n            g.node(stop, label=\"\", shape=\"point\", height=\"0\", width=\"0\")\n            g.edge(str(f(i)), stop, label=f\"{fmt(w)}\")\n        # for i, a, j, w in sorted(self.arcs()):\n        for i, a, j, w in self.arcs():\n            g.edge(str(f(i)), str(f(j)), label=f\"{fmt_edge(i, a, j, w)}\")\n        return g\n\n    @classmethod\n    def lift(cls, x, w, R=None):\n        if R is None:\n            R = w.__class__\n        m = cls(R=R)\n        m.add_I(0, R.one)\n        m.add_arc(0, x, 1, w)\n        m.add_F(1, R.one)\n        return m\n\n    @classmethod\n    def from_string(cls, xs, R, w=None):\n        m = cls(R)\n        m.add_I(xs[:0], R.one)\n        for i in range(len(xs)):\n            m.add_arc(xs[:i], xs[i], xs[: i + 1], R.one)\n        m.add_F(xs, (R.one if w is None else w))\n        return m\n\n    @classmethod\n    def from_strings(cls, Xs, R):\n        m = cls(R)\n        for xs in Xs:\n            m.set_I(xs[:0], R.one)\n            for i in range(len(xs)):\n                m.set_arc(xs[:i], xs[i], xs[: i + 1], R.one)\n            m.set_F(xs, R.one)\n        return m\n\n    def total_weight(self):\n        b = self.backward\n        return sum(self.start[i] * b[i] for i in self.start)\n\n    @cached_property\n    def G(self):\n        G = WeightedGraph(self.R)\n        for i, _, j, w in self.arcs():\n            G[i, j] += w\n        G.N |= self.states\n        return G\n\n    @cached_property\n    def K(self):\n        return self.G.closure_scc_based()\n\n    @cached_property\n    def forward(self):\n        return self.G.solve_left(self.start)\n\n    @cached_property\n    def backward(self):\n        return self.G.solve_right(self.stop)\n\n    @cached_property\n    def push(self):\n        \"Weight pushing algorithm (Mohri, 2001); assumes v**-1 possible for weights.\"\n        V = self.backward\n        new = self.spawn()\n        for i in self.states:\n            if V[i] == self.R.zero:\n                continue\n            new.add_I(i, self.start[i] * V[i])\n            new.add_F(i, V[i] ** (-1) * self.stop[i])\n            for a, j, w in self.arcs(i):\n                new.add_arc(i, a, j, V[i] ** (-1) * w * V[j])\n        return new\n\n    @cached_property\n    def trim_vals(self):\n        \"\"\"\n        This method provides fine-grained trimming based on semiring values rather\n        than the coarser-grained boolean approximation provided by `trim`.\n        However, it is generally slower to evaluation.\n        \"\"\"\n        forward = self.forward\n        backward = self.backward\n        # determine the set of active state, (i.e., those with nonzero forward and backward weights)\n        return self._trim(\n            {\n                i\n                for i in self.states\n                if forward[i] != self.R.zero and backward[i] != self.R.zero\n            }\n        )\n\n    def accessible(self):\n        stack = list(self.start)\n        visited = set(self.start)\n        while stack:\n            P = stack.pop()\n            for _, Q, _ in self.arcs(P):\n                if Q not in visited:\n                    stack.append(Q)\n                    visited.add(Q)\n        return visited\n\n    def co_accessible(self):\n        return self.reverse.accessible()\n\n    @cached_property\n    def trim(self):\n        return self._trim(self.accessible() &amp; self.co_accessible())\n\n    def _trim(self, active):\n        new = self.spawn()\n        for i in active:\n            new.add_I(i, self.start[i])\n            new.add_F(i, self.stop[i])\n            for a, j, w in self.arcs(i):\n                if j in active:\n                    new.add_arc(i, a, j, w)\n        return new\n\n    @cached_property\n    def min_det(self):\n        \"\"\"\n        Implements Brzozowski's_minimization algorithm.\n        See https://ralphs16.github.io/src/CatLectures/HW_Brzozowski.pdf and\n        https://link.springer.com/chapter/10.1007/978-3-642-39274-0_17.\n        \"\"\"\n        return self.reverse.determinize.trim.reverse.determinize.trim\n\n    @cached_property\n    def determinize(self):\n        \"\"\"\n        Mohri (2009)'s \"on-the-fly\" determinization semi-algorithm.\n        https://link.springer.com/chapter/10.1007/978-3-642-01492-5_6\n\n        Use with caution as this method may not terminate.\n        \"\"\"\n\n        self = self.epsremove.push\n\n        def _powerarcs(Q):\n            U = {a: self.R.chart() for a in self.alphabet}\n\n            for i, u in Q.items():\n                for a, j, v in self.arcs(i):\n                    U[a][j] += u * v\n\n            for a in U:\n                R = U[a]\n                W = sum(R.values(), start=self.R.zero)\n\n                if 0:\n                    # If we cannot extract a common factor, then all of the arcs will have weight one\n                    yield a, frozendict(R), self.R.one\n\n                else:\n                    yield a, frozendict({p: W ** (-1) * R[p] for p in R}), W\n\n        D = self.spawn()\n\n        stack = []\n        visited = set()\n\n        Q = frozendict({i: w for i, w in self.I})\n        D.add_I(Q, self.R.one)\n        stack.append(Q)\n        visited.add(Q)\n\n        while stack:\n            P = stack.pop()\n            for a, Q, w in _powerarcs(P):\n                if Q not in visited:\n                    stack.append(Q)\n                    visited.add(Q)\n                D.add_arc(P, a, Q, w)\n\n        for Q in D.states:\n            for q in Q:\n                D.add_F(Q, Q[q] * self.stop[q])\n\n        return D\n\n    def to_cfg(self, S=None, recursion=\"right\"):\n        \"\"\"\n        Convert the WFSA to a WCFG with the same weighted language.\n\n        The option `recursion` in {\"left\", \"right\"} specifies whether the WCFG\n        should be left or right recursive.\n\n        \"\"\"\n        from genlm.grammar.cfg import CFG, _gen_nt\n\n        if S is None:\n            S = _gen_nt()\n        cfg = CFG(R=self.R, V=self.alphabet - {EPSILON}, S=S)\n\n        if recursion == \"right\":\n            # add production rule for initial states\n            for i, w in self.I:\n                cfg.add(w, S, i)\n\n            # add production rule for final states\n            for i, w in self.F:\n                cfg.add(w, i)\n\n            # add other production rules\n            for i, a, j, w in self.arcs():\n                if a == EPSILON:\n                    cfg.add(w, i, j)\n                else:\n                    cfg.add(w, i, a, j)\n\n        else:\n            assert recursion == \"left\"\n\n            # add production rule for final states\n            for i, w in self.F:\n                cfg.add(w, S, i)\n\n            # add production rule for initial states\n            for i, w in self.I:\n                cfg.add(w, i)\n\n            # add other production rules\n            for i, a, j, w in self.arcs():\n                if a == EPSILON:\n                    cfg.add(w, j, i)\n                else:\n                    cfg.add(w, j, i, a)\n\n        return cfg\n\n    def to_bytes(self):\n        # Can be optimized, currently creates more states than necessary\n        # when multiple characters emanating from the same state share a byte prefix.\n        byte_wfsa = self.spawn(keep_init=True, keep_stop=True)\n\n        state_counter = 0\n\n        def get_new_state():\n            nonlocal state_counter\n            state = f\"_bytes{state_counter}\"\n            state_counter += 1\n            return state\n\n        for i, a, j, w in self.arcs():\n            if a == EPSILON:\n                byte_wfsa.add_arc(i, a, j, w)\n            elif isinstance(a, str):\n                bs = a.encode(\"utf-8\")\n                if len(bs) == 1:\n                    byte_wfsa.add_arc(i, bs[0], j, w)\n                else:  # Multi-byte transition\n                    curr = get_new_state()\n                    byte_wfsa.add_arc(i, bs[0], curr, self.R.one)\n                    for b in bs[1:-1]:\n                        next_state = get_new_state()\n                        byte_wfsa.add_arc(curr, b, next_state, self.R.one)\n                        curr = next_state\n                    byte_wfsa.add_arc(curr, bs[-1], j, w)\n            else:\n                raise ValueError(f\"Invalid arc label {a} for byte conversion\")\n\n        return byte_wfsa\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.E","title":"<code>E</code>  <code>cached</code> <code>property</code>","text":"<p>Weighted graph of epsilon arcs</p>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.determinize","title":"<code>determinize</code>  <code>cached</code> <code>property</code>","text":"<p>Mohri (2009)'s \"on-the-fly\" determinization semi-algorithm. https://link.springer.com/chapter/10.1007/978-3-642-01492-5_6</p> <p>Use with caution as this method may not terminate.</p>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.epsremove","title":"<code>epsremove</code>  <code>cached</code> <code>property</code>","text":"<p>Return an equivalent machine with no epsilon arcs.</p>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.min_det","title":"<code>min_det</code>  <code>cached</code> <code>property</code>","text":"<p>Implements Brzozowski's_minimization algorithm. See https://ralphs16.github.io/src/CatLectures/HW_Brzozowski.pdf and https://link.springer.com/chapter/10.1007/978-3-642-39274-0_17.</p>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.push","title":"<code>push</code>  <code>cached</code> <code>property</code>","text":"<p>Weight pushing algorithm (Mohri, 2001); assumes v**-1 possible for weights.</p>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.reverse","title":"<code>reverse</code>  <code>cached</code> <code>property</code>","text":"<p>creates a reversed machine</p>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.trim_vals","title":"<code>trim_vals</code>  <code>cached</code> <code>property</code>","text":"<p>This method provides fine-grained trimming based on semiring values rather than the coarser-grained boolean approximation provided by <code>trim</code>. However, it is generally slower to evaluation.</p>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.kleene_plus","title":"<code>kleene_plus()</code>","text":"<p>self^+</p> Source code in <code>genlm/grammar/wfsa/base.py</code> <pre><code>def kleene_plus(self):\n    \"self^+\"\n    m = self.spawn(keep_init=True, keep_arcs=True, keep_stop=True)\n    for i, w1 in self.F:\n        for j, w2 in self.I:\n            m.add_arc(i, EPSILON, j, w1 * w2)\n    return m\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.rename","title":"<code>rename(f)</code>","text":"<p>Note: If <code>f</code> is not bijective, states may merge.</p> Source code in <code>genlm/grammar/wfsa/base.py</code> <pre><code>def rename(self, f):\n    \"Note: If `f` is not bijective, states may merge.\"\n    m = self.spawn()\n    for i, w in self.I:\n        m.add_I(f(i), w)\n    for i, w in self.F:\n        m.add_F(f(i), w)\n    for i, a, j, w in self.arcs():\n        m.add_arc(f(i), a, f(j), w)\n    return m\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.spawn","title":"<code>spawn(*, keep_init=False, keep_arcs=False, keep_stop=False)</code>","text":"<p>Returns a new WFSA in the same semiring.</p> Source code in <code>genlm/grammar/wfsa/base.py</code> <pre><code>def spawn(self, *, keep_init=False, keep_arcs=False, keep_stop=False):\n    \"Returns a new WFSA in the same semiring.\"\n    m = self.__class__(self.R)\n    if keep_init:\n        for q, w in self.I:\n            m.add_I(q, w)\n    if keep_arcs:\n        for i, a, j, w in self.arcs():\n            m.add_arc(i, a, j, w)\n    if keep_stop:\n        for q, w in self.F:\n            m.add_F(q, w)\n    return m\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/base/#genlm.grammar.wfsa.base.WFSA.to_cfg","title":"<code>to_cfg(S=None, recursion='right')</code>","text":"<p>Convert the WFSA to a WCFG with the same weighted language.</p> <p>The option <code>recursion</code> in {\"left\", \"right\"} specifies whether the WCFG should be left or right recursive.</p> Source code in <code>genlm/grammar/wfsa/base.py</code> <pre><code>def to_cfg(self, S=None, recursion=\"right\"):\n    \"\"\"\n    Convert the WFSA to a WCFG with the same weighted language.\n\n    The option `recursion` in {\"left\", \"right\"} specifies whether the WCFG\n    should be left or right recursive.\n\n    \"\"\"\n    from genlm.grammar.cfg import CFG, _gen_nt\n\n    if S is None:\n        S = _gen_nt()\n    cfg = CFG(R=self.R, V=self.alphabet - {EPSILON}, S=S)\n\n    if recursion == \"right\":\n        # add production rule for initial states\n        for i, w in self.I:\n            cfg.add(w, S, i)\n\n        # add production rule for final states\n        for i, w in self.F:\n            cfg.add(w, i)\n\n        # add other production rules\n        for i, a, j, w in self.arcs():\n            if a == EPSILON:\n                cfg.add(w, i, j)\n            else:\n                cfg.add(w, i, a, j)\n\n    else:\n        assert recursion == \"left\"\n\n        # add production rule for final states\n        for i, w in self.F:\n            cfg.add(w, S, i)\n\n        # add production rule for initial states\n        for i, w in self.I:\n            cfg.add(w, i)\n\n        # add other production rules\n        for i, a, j, w in self.arcs():\n            if a == EPSILON:\n                cfg.add(w, j, i)\n            else:\n                cfg.add(w, j, i, a)\n\n    return cfg\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/field_wfsa/","title":"field_wfsa","text":"<p>Implementation of weighted finite-state automata over fields.</p> <p>This implementation of equivalence and minimization follows Kiefer (2020) very closely</p> <p>References</p> <ul> <li>Stefan Kiefer (2020) \"Notes on Equivalence and Minimization of Weighted Automata\"    arXiv:2009.01217v1 [cs.FL]</li> </ul>"},{"location":"reference/genlm/grammar/wfsa/field_wfsa/#genlm.grammar.wfsa.field_wfsa.WFSA","title":"<code>WFSA</code>","text":"<p>               Bases: <code>WFSA</code></p> <p>Weighted finite-state automata where weights are a field (e.g., real-valued).</p> Source code in <code>genlm/grammar/wfsa/field_wfsa.py</code> <pre><code>class WFSA(base.WFSA):\n    \"\"\"\n    Weighted finite-state automata where weights are a field (e.g., real-valued).\n    \"\"\"\n\n    def __init__(self, R=Float):\n        super().__init__(R=R)\n\n    def __hash__(self):\n        return hash(self.simple)\n\n    def threshold(self, threshold):\n        \"Drop init, arcs, final below a given abs-threshold.\"\n        m = self.__class__(self.R)\n        for q, w in self.I:\n            if abs(w) &gt;= threshold:\n                m.add_I(q, w)\n        for i, a, j, w in self.arcs():\n            if abs(w) &gt;= threshold:\n                m.add_arc(i, a, j, w)\n        for q, w in self.F:\n            if abs(w) &gt;= threshold:\n                m.add_F(q, w)\n        return m\n\n    def graphviz(\n        self,\n        fmt=lambda x: f\"{round(x, 3):g}\" if isinstance(x, (float, int)) else str(x),\n        **kwargs,\n    ):  # pylint: disable=arguments-differ\n        return super().graphviz(fmt=fmt, **kwargs)\n\n    @cached_property\n    def simple(self):\n        self = self.epsremove.renumber\n\n        S = self.dim\n        start = np.full(S, self.R.zero)\n        arcs = {a: np.full((S, S), self.R.zero) for a in self.alphabet}\n        stop = np.full(S, self.R.zero)\n\n        for i, w in self.I:\n            start[i] += w\n        for i, a, j, w in self.arcs():\n            arcs[a][i, j] += w\n        for i, w in self.F:\n            stop[i] += w\n\n        assert EPSILON not in arcs\n\n        return Simple(start, arcs, stop)\n\n    def __eq__(self, other):\n        return self.simple == other.simple\n\n    def counterexample(self, other):\n        return self.simple.counterexample(other.simple)\n\n    @cached_property\n    def min(self):\n        return self.simple.min.to_wfsa()\n\n    #    @cached_property\n    #    def epsremove(self):\n    #        return self.simple.to_wfsa()\n\n    def multiplicity(self, m):\n        return WFSA.lift(EPSILON, m) * self\n\n    @classmethod\n    def lift(cls, x, w, R=None):\n        if R is None:\n            R = Float\n        m = cls(R=R)\n        m.add_I(0, R.one)\n        m.add_arc(0, x, 1, w)\n        m.add_F(1, R.one)\n        return m\n</code></pre>"},{"location":"reference/genlm/grammar/wfsa/field_wfsa/#genlm.grammar.wfsa.field_wfsa.WFSA.threshold","title":"<code>threshold(threshold)</code>","text":"<p>Drop init, arcs, final below a given abs-threshold.</p> Source code in <code>genlm/grammar/wfsa/field_wfsa.py</code> <pre><code>def threshold(self, threshold):\n    \"Drop init, arcs, final below a given abs-threshold.\"\n    m = self.__class__(self.R)\n    for q, w in self.I:\n        if abs(w) &gt;= threshold:\n            m.add_I(q, w)\n    for i, a, j, w in self.arcs():\n        if abs(w) &gt;= threshold:\n            m.add_arc(i, a, j, w)\n    for q, w in self.F:\n        if abs(w) &gt;= threshold:\n            m.add_F(q, w)\n    return m\n</code></pre>"}]}